---
title: "R Notebook"
output: html_notebook
---

```{r}
set.seed(2)
x = matrix(rnorm(50 * 2), ncol = 2)
x[1:25, 1] = x[1:25, 1] + 3
x[1:25, 2] = x[1:25, 2] - 4

# Performing KMeans clustering with K = 2, nstat - number of times the algorithm is run with random initialization
# only the best result is reported (based on WCSS).
# Running KMeans with high nstat helps us find the global optimum of the KMeans optimization problem.
km.out = kmeans(x, 2, nstart = 20)
# cluster assignments 
print(km.out$cluster)
```
```{r}
plot(x, col = (km.out$cluster + 1), main = "KMeans results K=2", xlab = "", ylab = "", pch = 20, cex = 2)
```

Hierarchical Clustering

```{r}
# using different linkage methods - a way to compute distance between 2 clusters
hc.complete = hclust(dist(x), method = "complete") # use the largest distance between 2 clusters 
hc.average = hclust(dist(x), method = "average") # use the agerage distance between 2 clusters
hc.single = hclust(dist(x), method = "single") # use the smallest distance between 2 clusters

par(mfrow = c(1, 3))
plot(hc.complete, main = "Complete Linkage", xlab = "", ylab = "", sub = "", cex = 0.9)
plot(hc.average, main = "Average Linkage", xlab = "", ylab = "", sub = "", cex = 0.9)
plot(hc.single, main = "Single Linkage", xlab = "", ylab = "", sub = "", cex = 0.9)
```
```{r}
# determining the cluster labels
print(cutree(hc.complete, 2))
print(cutree(hc.average, 2))
print(cutree(hc.single, 2))
```


