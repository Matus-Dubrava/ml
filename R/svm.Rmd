---
title: "R Notebook"
output: html_notebook
---

```{r}
library(e1071)

set.seed(1)

x = matrix(rnorm(20 * 2), ncol = 2)
y = c(rep(-1, 10), rep(1, 10))
x[y == 1,] = x[y == 1,] + 1
plot(x, col=(3 - y))
```
```{r}
dat = data.frame(x=x, y=as.factor(y))
dat
```
```{r}
svmfit = svm(y~., data=dat, kernel="linear", cost=10, scale=FALSE)
plot(svmfit, dat)
```
```{r}
# indices of support vectors
svmfit$index
```
```{r}
summary(svmfit)
```
```{r}
# using smaller value of the cost parameter
svmfit = svm(y~., data=dat, kernel="linear", scale=FALSE, cost=0.1)
plot(svmfit, dat)
```
```{r}
svmfit$index
```
```{r}
# tuning the cost parameter using cross-validation
tune.out = tune(svm, y~., data=dat, kernel="linear",
                ranges=list(cost=c(0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100)))
summary(tune.out)
```
```{r}
bestmod = tune.out$best.model
summary(bestmod)
```
```{r}
# generating a test data set
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep=TRUE)
xtest[y == 1,] = xtest[y == 1,] + 1
testdat = data.frame(x=xtest, y=as.factor(ytest))
testdat
```
```{r}
ypred = predict(bestmod, testdat)
table(predict=ypred, truth=testdat$y)
```
```{r}
# generating linearly separable data
x[y == 1,] = x[y == 1,] + 0.5
plot(x, col=(y+5)/2, pch=19)
```
```{r}
dat = data.frame(x=x, y=as.factor(y))
svmfit = svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
```
```{r}
plot(svmfit, dat)
```
```{r}
# using non-linear kernels
x = matrix(rnorm(200 * 2), ncol = 2)
x[1:100,] = x[1:100] + 2
x[101:150,] = x[101:150,] - 2
y = c(rep(1, 150), rep(2, 50))
dat = data.frame(x, y=as.factor(y))
plot(x, col=y)
```
```{r}
train = sample(200, 100)
svmfit = svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat)
```
```{r}
summary(svmfit)
```
```{r}
tune.out = tune(svm, y~., data=dat[train,], kernel="radial",
                ranges=list(cost=c(0.1, 1, 10, 100, 1000),
                            gamma=c(0.5, 1, 2, 3, 4)))
summary(tune.out)
```
```{r}
get_accuracy = function(ypred, ytrue) {
  return(mean(ypred == ytrue))
}

bestmod = tune.out$best.model
ypred = predict(bestmod, dat[-train,])
table(predict=ypred, truth=dat[-train, "y"])
get_accuracy(ypred, dat[-train, "y"])
plot(bestmod, dat[train,])
```
```{r}
# ROC curves
library(ROCR)

rocplot = function(pred, truth, ...) {
  predob = prediction(pred, truth)
  perf = performance(predob, "fpr", "tpr")
  plot(perf, ...)
}

fitted = attributes(predict(bestmod, dat[train,], 
                            decision.values = TRUE))$decision.values
par(mfrow=c(1, 2))
rocplot(fitted, dat[train, "y"], main="Training Data")
```

