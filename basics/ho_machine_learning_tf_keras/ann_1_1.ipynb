{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "class_names = ['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', \n",
    "               'Sneakers', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(class_names[y_train[0]])\n",
    "plt.imshow(X_train[0], cmap='binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.04231605, -0.0349601 , -0.06844484, ..., -0.05330376,\n",
       "          0.03134373, -0.0720479 ],\n",
       "        [ 0.04030094, -0.00265555, -0.02427752, ..., -0.03197094,\n",
       "         -0.04404435, -0.01043578],\n",
       "        [-0.06215933, -0.01716026, -0.01916364, ...,  0.0625461 ,\n",
       "         -0.00102974, -0.01948775],\n",
       "        ...,\n",
       "        [-0.06201993, -0.03224373,  0.04832414, ...,  0.03204634,\n",
       "          0.04887621, -0.04802778],\n",
       "        [ 0.02472623,  0.04221936, -0.00705812, ...,  0.01078632,\n",
       "          0.02404517, -0.02756626],\n",
       "        [-0.00310828, -0.07201134, -0.00791426, ...,  0.04247774,\n",
       "          0.02383696, -0.03749859]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.05305739, -0.02468739, -0.10609037, ..., -0.07197955,\n",
       "          0.03421874,  0.03832539],\n",
       "        [-0.05845344, -0.01961803, -0.03944671, ..., -0.07271937,\n",
       "          0.07955811, -0.07304455],\n",
       "        [ 0.03398813,  0.02656286,  0.0963228 , ..., -0.07668753,\n",
       "          0.11637106, -0.0157349 ],\n",
       "        ...,\n",
       "        [-0.12232235,  0.01934475, -0.06581517, ..., -0.01691377,\n",
       "          0.06643499, -0.0320944 ],\n",
       "        [ 0.00119035, -0.00869512, -0.04100408, ...,  0.01764827,\n",
       "         -0.10005473, -0.09701872],\n",
       "        [-0.00483783, -0.00679436, -0.08874744, ..., -0.06544301,\n",
       "         -0.10392687,  0.09422479]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-1.26159474e-01, -1.91042766e-01,  1.13549709e-01,\n",
       "          1.09671205e-01,  1.39716953e-01,  1.67042077e-01,\n",
       "          6.98345304e-02,  8.02360475e-02,  1.89499021e-01,\n",
       "          2.31612325e-02],\n",
       "        [-1.51920184e-01,  8.28380287e-02, -2.02643901e-01,\n",
       "         -1.93509907e-01, -1.89986140e-01, -2.15381846e-01,\n",
       "          6.10916317e-02,  2.21898228e-01,  1.08638346e-01,\n",
       "          1.55150115e-01],\n",
       "        [-1.81408405e-01, -1.38863847e-01, -5.42980433e-02,\n",
       "         -1.48917004e-01, -1.27514005e-01, -1.44852161e-01,\n",
       "         -1.53926700e-01, -3.87579799e-02, -1.77130133e-01,\n",
       "          2.24067390e-01],\n",
       "        [ 3.97116542e-02,  2.31414437e-01, -1.46164268e-01,\n",
       "          1.92413390e-01,  1.55919701e-01, -1.47050917e-01,\n",
       "         -1.41870484e-01, -1.20601803e-02,  1.24152154e-02,\n",
       "          8.96347463e-02],\n",
       "        [ 1.46185875e-01,  1.16632581e-01,  1.52634382e-01,\n",
       "         -1.99056268e-02,  9.90418196e-02,  1.35285288e-01,\n",
       "          1.18932128e-03, -6.73445165e-02,  1.47685528e-01,\n",
       "          1.14210606e-01],\n",
       "        [-4.54264134e-02, -1.84587240e-02,  1.47886872e-01,\n",
       "          2.16141909e-01,  2.19942629e-01, -7.26437271e-02,\n",
       "         -1.61706835e-01, -1.66185886e-01, -8.83302838e-02,\n",
       "          1.90429389e-03],\n",
       "        [ 1.32562637e-01,  6.47392869e-02, -2.11347863e-01,\n",
       "          1.10953391e-01,  2.01780111e-01,  1.07542962e-01,\n",
       "         -6.92700297e-02, -5.56772947e-02,  1.76369548e-02,\n",
       "          1.26548529e-01],\n",
       "        [-9.23456699e-02,  2.31557965e-01, -8.95463377e-02,\n",
       "          1.29545361e-01,  1.32149875e-01, -1.63424656e-01,\n",
       "         -1.97947681e-01,  1.20552897e-01,  1.17308229e-01,\n",
       "         -1.20033443e-01],\n",
       "        [ 2.23933160e-03, -1.88261360e-01, -9.27084386e-02,\n",
       "         -1.27889246e-01, -1.54497787e-01, -3.49657089e-02,\n",
       "         -1.20497726e-01, -1.28102183e-01,  7.95175135e-03,\n",
       "         -1.39638156e-01],\n",
       "        [ 1.25015259e-01, -9.66585577e-02, -3.08561176e-02,\n",
       "          3.65106165e-02, -1.65230662e-01, -2.03938022e-01,\n",
       "          2.14208335e-01, -6.53509796e-02,  2.29937941e-01,\n",
       "         -2.00953484e-01],\n",
       "        [-1.91996440e-01,  2.59217322e-02,  9.89033580e-02,\n",
       "          1.37901992e-01, -1.10371955e-01, -2.04998255e-02,\n",
       "         -1.09730661e-01,  2.18870699e-01,  1.55713499e-01,\n",
       "         -4.61591929e-02],\n",
       "        [-9.90210623e-02, -1.78154975e-01,  1.62122279e-01,\n",
       "         -5.20108193e-02, -2.33096421e-01, -7.50388503e-02,\n",
       "         -2.17233747e-01,  9.22547281e-02, -3.79653275e-02,\n",
       "          7.72541165e-02],\n",
       "        [-2.29376271e-01, -2.17128053e-01,  6.00321293e-02,\n",
       "          1.42514616e-01,  1.36972696e-01, -1.46331772e-01,\n",
       "         -1.24142706e-01,  9.32651460e-02, -7.35879242e-02,\n",
       "          1.53158635e-01],\n",
       "        [-9.39943790e-02, -1.44849062e-01,  4.60449755e-02,\n",
       "         -1.66467756e-01,  2.04778939e-01,  1.31401420e-01,\n",
       "         -1.44842759e-01,  8.57559144e-02, -1.43171057e-01,\n",
       "          4.37321067e-02],\n",
       "        [-2.28655800e-01,  1.04956001e-01, -1.62532568e-01,\n",
       "          1.55981004e-01,  2.20850199e-01, -1.87390491e-01,\n",
       "          8.01045299e-02,  1.55952930e-01, -9.87753868e-02,\n",
       "         -1.64873734e-01],\n",
       "        [ 7.03001618e-02, -1.06953323e-01,  8.43230188e-02,\n",
       "         -1.19155437e-01,  6.09939694e-02,  7.77785480e-03,\n",
       "          1.49428993e-01, -1.84318274e-02, -2.39080340e-02,\n",
       "          1.72127783e-01],\n",
       "        [ 1.55487537e-01,  1.37870520e-01,  1.51616991e-01,\n",
       "          1.74654871e-01,  5.85183203e-02,  2.06103742e-01,\n",
       "          1.75112158e-01, -2.31337085e-01, -1.20399222e-01,\n",
       "          1.33399725e-01],\n",
       "        [-8.57784599e-02, -2.12740093e-01,  1.64975822e-02,\n",
       "          1.67134613e-01, -1.72870204e-01, -2.16132730e-01,\n",
       "         -2.19290704e-01,  5.89037240e-02,  1.52774423e-01,\n",
       "          2.30852246e-01],\n",
       "        [-1.03655696e-01,  2.10281312e-02,  6.91394508e-03,\n",
       "          1.10268593e-05, -7.57886767e-02, -3.37258279e-02,\n",
       "         -5.81468791e-02,  9.40465331e-02,  1.45947933e-02,\n",
       "          1.76230967e-02],\n",
       "        [-1.23542562e-01,  2.77906656e-02,  7.78020322e-02,\n",
       "         -1.83232620e-01,  1.10231638e-01, -1.84940457e-01,\n",
       "          1.63856000e-02, -2.29184225e-01, -1.25104845e-01,\n",
       "          6.79312944e-02],\n",
       "        [ 7.04774559e-02,  2.28059381e-01, -5.78882247e-02,\n",
       "          1.59823328e-01,  1.36585712e-01, -4.98807430e-02,\n",
       "          4.39541638e-02, -6.48563504e-02,  1.66685104e-01,\n",
       "         -4.01278138e-02],\n",
       "        [-2.29153097e-01, -1.51538551e-02, -1.90537721e-01,\n",
       "         -2.20526189e-01, -9.65593904e-02,  1.45705104e-01,\n",
       "         -1.68828309e-01,  4.53090966e-02,  1.82887912e-02,\n",
       "         -2.45020688e-02],\n",
       "        [ 1.43039256e-01,  1.20928138e-01, -1.81214288e-01,\n",
       "         -5.08762896e-02, -1.59830570e-01, -2.25701034e-02,\n",
       "         -2.30937168e-01,  1.78675264e-01,  1.27624273e-01,\n",
       "          1.16435021e-01],\n",
       "        [ 1.71903938e-01, -1.00363910e-01, -3.68007272e-02,\n",
       "          7.28350580e-02,  2.08753943e-01,  1.32962763e-01,\n",
       "         -9.85684246e-02,  1.97179109e-01,  1.03673398e-01,\n",
       "          1.23986065e-01],\n",
       "        [-3.03273499e-02,  1.84170604e-01, -1.53987736e-01,\n",
       "         -1.26835287e-01, -1.01783872e-02, -2.24032640e-01,\n",
       "          1.90827876e-01, -2.69145072e-02,  2.06598639e-03,\n",
       "         -2.15703130e-01],\n",
       "        [-1.98604688e-01,  2.08867371e-01,  1.39688224e-01,\n",
       "         -1.42492846e-01, -2.19250455e-01,  9.55742002e-02,\n",
       "          2.15340644e-01,  1.74662054e-01,  1.23079181e-01,\n",
       "          1.66230768e-01],\n",
       "        [-9.45583880e-02, -6.63288683e-02, -1.57587171e-01,\n",
       "         -1.50119305e-01, -2.10047290e-01, -2.03549802e-01,\n",
       "          2.06644028e-01, -1.49603069e-01,  2.31058121e-01,\n",
       "         -8.23676884e-02],\n",
       "        [-1.19870462e-01, -6.83043748e-02, -1.44608453e-01,\n",
       "          6.41790330e-02,  2.15588987e-01, -1.39802426e-01,\n",
       "          6.25409484e-02,  1.32899225e-01,  8.79223645e-02,\n",
       "         -1.73852950e-01],\n",
       "        [-9.48776156e-02, -1.08217314e-01,  1.32063478e-02,\n",
       "         -1.09883234e-01, -1.85342371e-01,  1.13633722e-02,\n",
       "         -1.86959788e-01,  2.01118529e-01, -2.13935167e-01,\n",
       "          1.99079156e-01],\n",
       "        [ 1.20738328e-01,  7.37729073e-02,  1.47017211e-01,\n",
       "          3.32562029e-02,  2.03415155e-02,  1.25584781e-01,\n",
       "         -1.35433465e-01, -6.50678277e-02, -6.96590841e-02,\n",
       "          3.40425968e-02],\n",
       "        [-1.37286365e-01,  1.82785869e-01,  2.10079640e-01,\n",
       "          9.22514498e-02,  1.59746885e-01, -2.20838070e-01,\n",
       "         -2.06191435e-01, -1.57677531e-02, -2.16212794e-01,\n",
       "          1.20675355e-01],\n",
       "        [-1.30586237e-01, -9.12038982e-02,  1.12548590e-01,\n",
       "          1.13207430e-01,  6.94422424e-02, -2.25900069e-01,\n",
       "         -1.32343739e-01,  2.05227792e-01, -1.02449164e-01,\n",
       "          5.22427857e-02],\n",
       "        [-3.59103084e-04, -3.60845476e-02, -9.04990137e-02,\n",
       "         -1.91391349e-01, -4.03484404e-02,  1.95351809e-01,\n",
       "          1.55469567e-01,  1.10022724e-03,  9.07391608e-02,\n",
       "         -2.24589139e-01],\n",
       "        [-1.92236766e-01, -2.16117144e-01,  2.28157341e-01,\n",
       "          1.90883636e-01, -5.33496439e-02, -2.24734679e-01,\n",
       "          1.23274714e-01, -1.95735082e-01, -8.86497945e-02,\n",
       "         -8.37995559e-02],\n",
       "        [ 6.01516068e-02, -2.33360201e-01, -5.13276458e-03,\n",
       "          1.02193743e-01, -8.46635252e-02,  1.40099555e-01,\n",
       "          1.83598399e-01,  2.03661919e-02,  1.13946557e-01,\n",
       "         -9.30032283e-02],\n",
       "        [ 1.33809149e-02,  5.95810413e-02,  5.41391075e-02,\n",
       "         -7.47385025e-02, -1.62524581e-02, -2.30193689e-01,\n",
       "         -1.34465426e-01, -4.14808542e-02,  1.82924300e-01,\n",
       "         -2.64278948e-02],\n",
       "        [ 1.66865230e-01,  1.64087266e-01, -7.05610812e-02,\n",
       "         -7.78879076e-02, -1.79781303e-01,  1.59435898e-01,\n",
       "          2.16459543e-01,  1.72461271e-02,  4.43494022e-02,\n",
       "          5.14504910e-02],\n",
       "        [-3.46882492e-02, -2.20084354e-01, -1.83983609e-01,\n",
       "          1.41841412e-01,  5.25021553e-02, -4.35487926e-03,\n",
       "          1.32710189e-01,  1.91162884e-01,  9.02521014e-02,\n",
       "         -9.59953815e-02],\n",
       "        [ 2.02844739e-01,  1.09459937e-01,  2.28518605e-01,\n",
       "         -1.15326151e-01, -1.28008366e-01,  5.46007752e-02,\n",
       "          7.49772191e-02, -1.88530147e-01,  1.09645844e-01,\n",
       "          2.22995490e-01],\n",
       "        [ 5.18558025e-02, -9.78903174e-02,  9.92405117e-02,\n",
       "         -2.23028854e-01, -2.81636417e-02, -1.72058731e-01,\n",
       "          2.07948178e-01,  1.76129371e-01,  2.04553306e-02,\n",
       "         -7.19618350e-02],\n",
       "        [-1.67080611e-01, -9.23745632e-02,  1.43269628e-01,\n",
       "         -1.54294044e-01, -1.70136511e-01, -1.70073539e-01,\n",
       "          1.11377478e-01, -8.81587267e-02, -3.31687778e-02,\n",
       "         -1.72614560e-01],\n",
       "        [ 1.82955652e-01, -9.48821157e-02, -1.47219956e-01,\n",
       "          1.61140233e-01, -1.74012423e-01, -1.16610132e-01,\n",
       "          8.17441046e-02, -1.63543075e-02, -3.77725661e-02,\n",
       "         -1.09763347e-01],\n",
       "        [-2.24831358e-01, -1.13448918e-01,  9.59641933e-02,\n",
       "         -1.24305524e-01,  2.04096735e-02,  1.93007141e-01,\n",
       "          8.65344107e-02,  1.90092921e-01, -2.09685802e-01,\n",
       "          1.06080949e-01],\n",
       "        [-1.01591870e-01, -1.88704163e-01,  9.06724036e-02,\n",
       "         -1.04487926e-01,  1.83887511e-01,  1.73704535e-01,\n",
       "         -1.21182732e-01, -8.20293576e-02, -1.65027976e-01,\n",
       "         -2.53836811e-02],\n",
       "        [-1.16138779e-01, -1.16321199e-01, -1.57806128e-02,\n",
       "         -2.18494952e-01, -2.14292526e-01,  5.73104024e-02,\n",
       "         -8.04622173e-02,  1.99161738e-01,  1.28276527e-01,\n",
       "          6.35160208e-02],\n",
       "        [-1.00117505e-01,  1.48179263e-01,  2.64610350e-02,\n",
       "          1.51502132e-01,  4.17300761e-02,  4.46999669e-02,\n",
       "         -6.77188188e-02,  1.18425786e-02, -1.67998582e-01,\n",
       "          6.94676936e-02],\n",
       "        [-5.57482243e-03,  1.77883744e-01, -6.32517934e-02,\n",
       "          1.70967519e-01,  9.27805901e-03,  7.86135197e-02,\n",
       "          1.22384459e-01,  9.68546271e-02,  1.00099593e-01,\n",
       "          1.16263568e-01],\n",
       "        [-7.09380507e-02, -2.16293037e-01, -1.78918615e-01,\n",
       "          1.01907253e-01,  2.28594035e-01, -2.32842565e-01,\n",
       "         -1.15546763e-01,  6.22689426e-02,  1.02834761e-01,\n",
       "          8.28629136e-02],\n",
       "        [-2.07395688e-01, -4.08490747e-02, -1.11915141e-01,\n",
       "          1.16937935e-01, -1.23997875e-01,  1.63115770e-01,\n",
       "         -4.36936766e-02, -1.91649377e-01,  1.20876580e-01,\n",
       "          8.60396028e-03],\n",
       "        [ 2.76261270e-02,  1.31066114e-01, -9.71258432e-02,\n",
       "          1.38830334e-01,  9.73299742e-02,  3.58183682e-03,\n",
       "          5.23692369e-02,  6.91958070e-02, -1.04119524e-01,\n",
       "          2.18755484e-01],\n",
       "        [ 1.20596796e-01, -9.82495248e-02, -2.53913105e-02,\n",
       "         -2.31297210e-01, -2.32051045e-01, -1.66364133e-01,\n",
       "          1.14345849e-01,  1.72913253e-01,  4.73251343e-02,\n",
       "         -5.26401401e-03],\n",
       "        [-2.00562879e-01,  4.03758883e-02,  1.93833202e-01,\n",
       "          1.83204055e-01,  1.58079028e-01, -6.62275255e-02,\n",
       "          6.92317784e-02, -1.84643775e-01, -1.95025802e-01,\n",
       "         -1.97716057e-02],\n",
       "        [-2.23078400e-01, -4.40594554e-03, -7.08677322e-02,\n",
       "          4.20233011e-02, -1.27376750e-01, -4.56762612e-02,\n",
       "         -9.70757306e-02, -1.58182308e-01, -9.80459005e-02,\n",
       "          6.57857955e-02],\n",
       "        [ 1.67599469e-01, -1.88672245e-01, -1.32966891e-01,\n",
       "         -1.83466762e-01, -2.17025772e-01,  2.01969415e-01,\n",
       "         -1.63387060e-01, -1.16644375e-01,  2.07744718e-01,\n",
       "         -2.02705324e-01],\n",
       "        [-1.61592513e-02, -3.84523869e-02, -8.48707855e-02,\n",
       "          2.09702492e-01,  6.64199591e-02, -1.50518924e-01,\n",
       "          5.64767420e-02, -9.36414301e-03,  2.06220686e-01,\n",
       "         -1.35119647e-01],\n",
       "        [-4.57164049e-02, -2.01387197e-01,  1.38977885e-01,\n",
       "          1.48820013e-01,  1.07939363e-01, -1.71949983e-01,\n",
       "          9.73431766e-03, -1.09604985e-01, -1.75449640e-01,\n",
       "         -4.93958592e-02],\n",
       "        [-7.51488805e-02, -2.31797412e-01,  1.55515552e-01,\n",
       "         -1.86984390e-02,  1.75907284e-01, -1.90981910e-01,\n",
       "          2.12370455e-02, -1.19914837e-01, -9.65479165e-02,\n",
       "          1.06134862e-02],\n",
       "        [ 1.18771404e-01, -1.53801367e-01, -7.22635835e-02,\n",
       "         -7.95077682e-02,  1.81462288e-01,  1.80655062e-01,\n",
       "          7.97720253e-03, -2.31907666e-01, -1.85254678e-01,\n",
       "          6.81653917e-02],\n",
       "        [-8.04390013e-03, -1.14637688e-01, -1.16383336e-01,\n",
       "         -1.16868332e-01,  9.67287719e-02, -8.67107511e-02,\n",
       "          2.06062078e-01, -1.49808422e-01, -1.29288882e-02,\n",
       "          2.19875425e-01],\n",
       "        [ 7.38120675e-02,  1.31000578e-01,  4.39056754e-03,\n",
       "         -1.35797173e-01,  2.20647126e-01,  7.50461519e-02,\n",
       "         -9.18203592e-02, -8.25210810e-02, -2.17379406e-01,\n",
       "         -1.13507107e-01],\n",
       "        [ 2.17503905e-01,  1.61306322e-01, -4.19867784e-02,\n",
       "          3.34790945e-02, -1.52189791e-01, -1.81033105e-01,\n",
       "         -2.07667366e-01, -1.64234608e-01, -6.65835589e-02,\n",
       "          3.17158103e-02],\n",
       "        [ 1.68465048e-01,  2.22554386e-01,  1.25882387e-01,\n",
       "         -1.19237512e-01,  1.70025319e-01, -2.06906289e-01,\n",
       "         -8.33259225e-02,  1.79650545e-01,  9.00196433e-02,\n",
       "          8.99162889e-03],\n",
       "        [-1.13291293e-02,  1.28867209e-01,  5.74385822e-02,\n",
       "          9.75663066e-02,  2.30235845e-01,  7.16752410e-02,\n",
       "          1.76327527e-01, -5.40416688e-02, -6.50469512e-02,\n",
       "          2.23055124e-01],\n",
       "        [-3.73985320e-02, -1.31267637e-01, -2.32511148e-01,\n",
       "          5.39979637e-02,  1.38437927e-01,  2.13312030e-01,\n",
       "         -2.05730170e-01,  6.12408221e-02,  3.86399925e-02,\n",
       "         -1.81951821e-02],\n",
       "        [-3.94011140e-02, -7.03538358e-02, -2.50108391e-02,\n",
       "         -4.46420014e-02, -8.20592046e-04,  7.56071508e-02,\n",
       "         -3.31461132e-02, -9.17987525e-02, -1.41805440e-01,\n",
       "          1.27551556e-02],\n",
       "        [ 1.76985860e-01,  1.39009804e-01,  8.61454606e-02,\n",
       "          7.99689889e-02,  4.33768034e-02,  4.45680618e-02,\n",
       "          4.58111763e-02,  7.87181258e-02,  1.52960122e-02,\n",
       "         -7.03626871e-03],\n",
       "        [ 1.88965857e-01,  8.01085234e-02,  1.50418818e-01,\n",
       "         -3.92407477e-02, -1.44623548e-01,  1.34060383e-01,\n",
       "          4.68255877e-02,  1.40832603e-01,  1.33536130e-01,\n",
       "          1.08701646e-01],\n",
       "        [-1.65640652e-01,  1.92415893e-01, -2.15009779e-01,\n",
       "         -1.82364017e-01, -8.83354247e-03, -1.32440582e-01,\n",
       "         -7.29475766e-02,  7.27521777e-02, -1.82609811e-01,\n",
       "         -1.09772682e-02],\n",
       "        [ 7.90757835e-02,  1.13972008e-01, -7.87639618e-02,\n",
       "          1.83791161e-01, -1.24758556e-01,  2.18910217e-01,\n",
       "         -1.30564466e-01,  1.12268448e-01,  1.74418956e-01,\n",
       "         -2.28022635e-01],\n",
       "        [-9.24598724e-02,  2.43549049e-02, -1.44082010e-02,\n",
       "         -4.03896421e-02,  8.42354298e-02, -1.26851052e-01,\n",
       "         -7.38727450e-02,  1.83291078e-01, -1.75827667e-01,\n",
       "          3.10363173e-02],\n",
       "        [-2.15282798e-01, -3.13912183e-02,  8.50482285e-02,\n",
       "          2.32420862e-02, -1.97013497e-01, -2.04931796e-01,\n",
       "          2.28453279e-02, -1.43173963e-01,  1.69575572e-01,\n",
       "         -9.86443162e-02],\n",
       "        [ 4.73580956e-02, -7.31602907e-02,  1.46989763e-01,\n",
       "          2.29458898e-01, -1.52914792e-01,  5.73250949e-02,\n",
       "         -2.23236993e-01,  1.64787531e-01, -2.11443976e-01,\n",
       "          1.32390231e-01],\n",
       "        [-3.99297625e-02, -1.63643420e-01,  1.23524010e-01,\n",
       "          1.21408522e-01,  6.90274835e-02,  2.15816498e-01,\n",
       "         -2.10630625e-01, -1.39246330e-01, -4.88408059e-02,\n",
       "          1.26377404e-01],\n",
       "        [ 2.21294343e-01, -1.50879204e-01,  7.27013648e-02,\n",
       "          1.13442302e-01,  1.42219454e-01,  2.01029062e-01,\n",
       "         -1.25244215e-01, -1.10033967e-01, -1.81637317e-01,\n",
       "         -2.09188774e-01],\n",
       "        [-2.25452155e-01,  8.67281854e-02, -1.01057544e-01,\n",
       "          1.44059539e-01,  1.32924408e-01,  1.50235504e-01,\n",
       "          1.67491823e-01,  9.42501128e-02,  9.76796150e-02,\n",
       "         -2.08834246e-01],\n",
       "        [ 1.22228742e-01,  1.89075053e-01, -2.19706774e-01,\n",
       "         -2.10950181e-01, -7.30366707e-02,  1.84031606e-01,\n",
       "         -1.99224651e-01, -1.30009472e-01,  1.93428546e-01,\n",
       "         -2.09781572e-01],\n",
       "        [ 9.87624824e-02,  4.56503034e-03, -8.72508287e-02,\n",
       "          1.98862612e-01, -2.11215958e-01,  1.98158443e-01,\n",
       "          1.58605099e-01,  1.45825058e-01,  2.23936796e-01,\n",
       "          1.44309700e-02],\n",
       "        [-9.24215615e-02, -1.84562206e-01, -9.75343436e-02,\n",
       "         -2.21485347e-02,  1.65071458e-01, -1.81711644e-01,\n",
       "          1.87948555e-01, -3.61499637e-02,  9.94051099e-02,\n",
       "          9.77773964e-02],\n",
       "        [-3.38225514e-02,  6.15697503e-02, -1.65816218e-01,\n",
       "         -1.18275933e-01,  1.38358593e-01, -1.70192763e-01,\n",
       "          1.07290864e-01, -1.39140487e-01, -1.10996328e-01,\n",
       "         -1.80285126e-02],\n",
       "        [ 3.83463800e-02, -2.04261363e-01, -5.42533845e-02,\n",
       "         -1.22398786e-01, -1.64806962e-01,  1.50100142e-01,\n",
       "         -2.46514082e-02, -1.58168823e-01, -9.44826007e-02,\n",
       "          1.21651441e-02],\n",
       "        [ 4.58634496e-02,  1.96895123e-01, -2.05692530e-01,\n",
       "         -3.13997418e-02,  1.97011769e-01,  2.32338428e-01,\n",
       "         -1.82877809e-01,  4.32728827e-02,  9.18874443e-02,\n",
       "          1.78855568e-01],\n",
       "        [ 5.97009659e-02,  2.23404437e-01,  2.03291833e-01,\n",
       "         -1.09589398e-02, -6.23083115e-02,  1.80065393e-01,\n",
       "          1.36466920e-02, -1.99391752e-01, -3.67751122e-02,\n",
       "          1.84206724e-01],\n",
       "        [ 9.47476327e-02, -1.62139446e-01,  6.43780231e-02,\n",
       "          1.33225620e-02,  9.49811935e-02,  7.02100098e-02,\n",
       "         -2.01624572e-01,  8.80038738e-02,  3.43506932e-02,\n",
       "         -1.73964977e-01],\n",
       "        [-1.25009120e-01, -7.75166154e-02,  1.69418037e-01,\n",
       "          5.00547886e-03, -9.40779597e-02, -2.15891898e-01,\n",
       "          1.84450239e-01, -1.80142909e-01,  1.69896752e-01,\n",
       "          1.62188709e-01],\n",
       "        [ 4.26459610e-02, -8.92366916e-02, -7.40166306e-02,\n",
       "          2.86149383e-02,  7.16061890e-03,  2.39215195e-02,\n",
       "          1.32470101e-01, -4.79131937e-03, -4.92289662e-03,\n",
       "          1.32467151e-01],\n",
       "        [ 1.46272421e-01, -1.31552219e-01,  9.08922851e-02,\n",
       "          1.92126691e-01,  1.88761055e-01, -2.26702958e-01,\n",
       "         -5.06893098e-02, -1.42947271e-01,  3.36710215e-02,\n",
       "         -2.11982757e-01],\n",
       "        [-9.18041021e-02, -2.05798537e-01, -1.57879680e-01,\n",
       "         -3.58718336e-02, -2.27388799e-01,  2.85142660e-02,\n",
       "         -1.56391606e-01, -1.63770556e-01,  1.78075343e-01,\n",
       "          1.40048325e-01],\n",
       "        [ 8.35169852e-02, -1.88743800e-01, -2.23897278e-01,\n",
       "         -2.00565100e-01,  1.51903689e-01, -8.52742046e-02,\n",
       "         -7.84993023e-02, -1.19215742e-01, -6.10702038e-02,\n",
       "          7.00635612e-02],\n",
       "        [-1.21171817e-01, -1.70089915e-01, -1.02413684e-01,\n",
       "          2.15963960e-01,  1.68371320e-01,  7.46979117e-02,\n",
       "          2.30860651e-01,  2.14315414e-01, -9.87550169e-02,\n",
       "         -7.42352456e-02],\n",
       "        [-5.03514707e-03, -1.33807585e-01,  1.09441489e-01,\n",
       "          5.42121828e-02, -2.11715266e-01, -1.05215922e-01,\n",
       "          5.32347858e-02,  6.65779412e-03,  1.02341354e-01,\n",
       "         -6.96349740e-02],\n",
       "        [-1.52601853e-01,  2.19240665e-01, -4.46866155e-02,\n",
       "         -2.65757889e-02, -2.80962139e-02, -1.50912941e-01,\n",
       "         -1.98515311e-01,  8.33677948e-02, -1.39247000e-01,\n",
       "          1.71860337e-01],\n",
       "        [-1.30539075e-01,  2.08918005e-01, -9.86375809e-02,\n",
       "         -3.88299674e-02,  8.13634396e-02, -2.26089388e-01,\n",
       "         -9.34925079e-02,  1.53119266e-01,  3.29391956e-02,\n",
       "         -1.79080367e-01],\n",
       "        [-1.50875688e-01,  1.38978660e-03, -2.08871663e-01,\n",
       "         -2.26663977e-01,  7.01648295e-02, -2.15491652e-02,\n",
       "         -1.37241647e-01,  7.76819289e-02, -5.60254753e-02,\n",
       "          1.90018088e-01],\n",
       "        [ 2.64033973e-02,  8.17246735e-02,  4.43124771e-02,\n",
       "         -1.74856901e-01,  2.03290761e-01,  2.17561424e-02,\n",
       "          2.08861649e-01, -4.27393913e-02,  1.38665825e-01,\n",
       "          2.33227283e-01],\n",
       "        [ 9.56013799e-03, -2.12604403e-02,  1.76320076e-01,\n",
       "          2.10925788e-01, -1.79135054e-01,  1.38317496e-01,\n",
       "         -1.73846707e-01,  6.52830899e-02, -7.19290972e-02,\n",
       "          6.36952519e-02],\n",
       "        [-5.17800748e-02,  1.79512590e-01,  1.59637898e-01,\n",
       "         -1.14588857e-01, -1.82016119e-01,  6.65570498e-02,\n",
       "          9.30196941e-02,  1.73036307e-01, -2.98094451e-02,\n",
       "         -1.81992948e-02],\n",
       "        [-1.21488705e-01, -1.85786054e-01, -1.97939619e-01,\n",
       "          1.82951808e-01,  2.14913398e-01, -4.99008894e-02,\n",
       "         -2.06131518e-01, -5.79772890e-03,  9.68217254e-02,\n",
       "         -2.21501812e-01],\n",
       "        [-1.22421555e-01,  1.01898223e-01, -2.00116023e-01,\n",
       "          1.24941081e-01,  1.30843610e-01, -2.28485748e-01,\n",
       "         -2.18800321e-01,  2.27724493e-01, -6.08337224e-02,\n",
       "         -4.98404205e-02],\n",
       "        [ 2.18978882e-01,  1.87645018e-01,  8.73731077e-02,\n",
       "          1.82221144e-01,  6.90990686e-02, -3.92400771e-02,\n",
       "         -2.07871765e-01,  1.51887000e-01,  1.10087126e-01,\n",
       "         -2.03150228e-01],\n",
       "        [ 1.44754499e-01,  4.16888297e-02, -2.11177364e-01,\n",
       "         -8.66599232e-02, -1.69968858e-01, -3.08458656e-02,\n",
       "          1.57819867e-01, -1.58026785e-01,  7.59940445e-02,\n",
       "          1.70825541e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10000\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.4705 - accuracy: 0.8303 - val_loss: 0.3942 - val_accuracy: 0.8546\n",
      "Epoch 2/10000\n",
      "55000/55000 [==============================] - 11s 195us/sample - loss: 0.3508 - accuracy: 0.8699 - val_loss: 0.3463 - val_accuracy: 0.8736\n",
      "Epoch 3/10000\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.3143 - accuracy: 0.8838 - val_loss: 0.3562 - val_accuracy: 0.8724\n",
      "Epoch 4/10000\n",
      "55000/55000 [==============================] - 11s 195us/sample - loss: 0.2928 - accuracy: 0.8919 - val_loss: 0.3055 - val_accuracy: 0.8912\n",
      "Epoch 5/10000\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.2751 - accuracy: 0.8974 - val_loss: 0.3148 - val_accuracy: 0.8776\n",
      "Epoch 6/10000\n",
      "55000/55000 [==============================] - 11s 194us/sample - loss: 0.2611 - accuracy: 0.9017 - val_loss: 0.3033 - val_accuracy: 0.8918\n",
      "Epoch 7/10000\n",
      "55000/55000 [==============================] - 11s 194us/sample - loss: 0.2493 - accuracy: 0.9052 - val_loss: 0.3178 - val_accuracy: 0.8824\n",
      "Epoch 8/10000\n",
      "55000/55000 [==============================] - 10s 188us/sample - loss: 0.2386 - accuracy: 0.9105 - val_loss: 0.3071 - val_accuracy: 0.8926\n",
      "Epoch 9/10000\n",
      "55000/55000 [==============================] - 11s 192us/sample - loss: 0.2276 - accuracy: 0.9143 - val_loss: 0.3207 - val_accuracy: 0.8828\n",
      "Epoch 10/10000\n",
      "55000/55000 [==============================] - 10s 186us/sample - loss: 0.2193 - accuracy: 0.9166 - val_loss: 0.3075 - val_accuracy: 0.8958\n",
      "Epoch 11/10000\n",
      "55000/55000 [==============================] - 10s 189us/sample - loss: 0.2119 - accuracy: 0.9212 - val_loss: 0.3070 - val_accuracy: 0.8994\n",
      "Epoch 12/10000\n",
      "55000/55000 [==============================] - 11s 191us/sample - loss: 0.2042 - accuracy: 0.9233 - val_loss: 0.3113 - val_accuracy: 0.8976\n",
      "Epoch 13/10000\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.1938 - accuracy: 0.9267 - val_loss: 0.3536 - val_accuracy: 0.8938\n",
      "Epoch 14/10000\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.1896 - accuracy: 0.9283 - val_loss: 0.3158 - val_accuracy: 0.8942\n",
      "Epoch 15/10000\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.1826 - accuracy: 0.9297 - val_loss: 0.3192 - val_accuracy: 0.8972\n",
      "Epoch 16/10000\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.1776 - accuracy: 0.9328 - val_loss: 0.3503 - val_accuracy: 0.8946\n",
      "Epoch 17/10000\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 0.1724 - accuracy: 0.9347 - val_loss: 0.3897 - val_accuracy: 0.8800\n",
      "Epoch 18/10000\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.1683 - accuracy: 0.9368 - val_loss: 0.3374 - val_accuracy: 0.8954\n",
      "Epoch 19/10000\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.1610 - accuracy: 0.9382 - val_loss: 0.3950 - val_accuracy: 0.8924\n",
      "Epoch 20/10000\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.1569 - accuracy: 0.9398 - val_loss: 0.3739 - val_accuracy: 0.8960\n",
      "Epoch 21/10000\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.1537 - accuracy: 0.9416 - val_loss: 0.3441 - val_accuracy: 0.8960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10000,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAGbCAYAAAAV7J4cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hcxaH+8e/sqnfbknGXZLlbMrYxJaHYJrQEArlAEkJIQvlBGjWhkxASSCCUBEJIaCHc5Kbf3HtDEnoxphoLF0nusixZlpts9bLaNr8/zmq1smVbtle7kv1+nmefPWX2nFlZXr07M2eOsdYiIiIiIgPPFe8KiIiIiBwtFLxEREREYkTBS0RERCRGFLxEREREYkTBS0RERCRGEuJ14tzcXFtQUBCv04uIiIj028cff7zLWpt3uMeJW/AqKCigtLQ0XqcXERER6TdjTE00jqOuRhEREZEYUfASERERiREFLxEREZEYUfASERERiREFLxEREZEYUfASERERiREFLxEREZEYUfASERERiREFLxEREZEYUfASERERiREFLxEREZEYUfASERERiREFLxEREZEYUfASERERiZGEeFdAREREZNAI+CHQBf7uhwcC3qgdXsFLRERE4sNaCPicYNPr4XNCz57b/Xuue5xt3eHI7+kJTL3CU/d6d9m+9oUeNjCgb1nBS0RE5EhibSiEdPWEmqAvIuD49tjuDbXyhMJMMGK5e/t+Xx+5r7/ByeeEnSi2JAFgXJCQAgnJ4E52nrsf7mRnX0qW8+xOCpVN2mM9ee/Xu5Pgh5+PShUVvERERKLNWifA9GpR8YDPE9Eq0+k8+zp7urS6Hz5P7/Ve5frxOuzAvC/jdkKIOzH0SAJXYu91d5ITVpLSwD2sZ3tCckSZ0HJf23qVTe45X5+v3yMouQd/rBn8NRQRETkcAT/42qGrDbzt4G0LPdp7d01FBqTIbX11Y/WnrA0eXr3dSZCQ6oSKxJRQyEjpCRsZI0OhI1QmIWWPchFhpFdAOlBwSgxt66OcS9fkHS4FLxERGTysDYWjPQKStx26Wvfe3leY2rOs33MIFTG9u6Eiu6q6tyVnQlpuT+jZX9nubX0FqMTU3gEqMdUpq5BzRFLwEhE5GgSDvcffdI+v6R6bEzkeaM+xOn0972vMT8AXMW6or/17jiHa47W+DvrdTeZKhOQMSMqApPSe57Tc0Pb00CPTed6rbFpEa1HyHq1EiWDMgP6TyNFJwUtEJF6sdcbpdLU6LTNdLc5yV6vTktO97m3r2e7rjAgqe4Ql/55hKXJwtX9g3kP3mB5XQs+yO3I5otsqKR3cOfvvzkpMiwhNewSlPbcnJA3MexIZQApeIiL9ZW1oAHPEIGdvR08o8rZGBKc9wtOeAar70Z9L143b6dZKzgx1QyX1DjZJ6REBZl+Dkfd4JPSxLfyapD1et+dYoO6w5VarkMhBUvASkaHP3wWdjdDR4ISZ8BVeEQEp8iqxPq8Oi7wqbB/bA10HV6+kUFhKzugJTul5kJzVsx7elxVq1cnc+5GQooAjcoRQ8BKRwSPgcwJUd4jqbITOhn2sN/as+zoO7jzdV4slpuw9qDkhBVKyQ/v22B6+aixie2LqHkGqu2UqXYOjRWQvCl4iEh3WRrQudfa0FnW19YSpA4Uob+u+j+9KgNRhkDrcec4ZD6NnhbaFHmnDQy1Eqb2vHosMTgkpCkQiEjcKXiJHA5/HGWvkaXGefZ29u9/CQamzp6vN53FaksJdc57egSr83HFwkzYaV0RYGg4Zo2DkjIhQleMEqMgyqcOcQKXuNhEZ4hS8RAa7YCAUmpp7glP3sqc5Yr153+UOdmySK7GnGy2yxSgxLXS7jWOcFqXE1IjWpdS9X5OY6nS5pUWEqOQstTiJyFFLwUskVvxd0L4L2uuhY1doeRd07N47NIXXW/bf/dYtMc0JNCnZTjBKHQbDCpzllOyIfdnOAO7EyJDUR3ByuQf8xyEicjRS8BI5VH6vE5r2DFJ9ru92glRfXAkR4SgUkEYUQUqOsx4ZqPYslxza7k6M7XsXEZFDouAlAs693LrnYPK07NEiFQpPewYrT3PfxzJuSM91Zs9Oz4WxxznP4W15ofU8SBvhBCiNXRIROSr0K3gZY84BHgPcwLPW2gf22J8PPAfkAQ3AZdbaLVGuq0hv3ZNZhiejbNl7cso+H33NBr6f6QiMyxmb1B2YRs8KhabcnkAVuZ6SozFMIiLSpwMGL2OMG3gCOBPYAiw1xrxgrV0dUexh4HfW2v80xpwO3A98ZSAqLEeQ7pvhepqgs8mZTsATeu5s6r3cV3jytvXvNiiuhIj5lUKTVKbnwfCJvbdHTnIZ2TKVOkxjnkREJCr60+J1AlBpra0CMMb8GbgAiAxeM4DvhJbfAv4vmpWUQc7ftXdQilzeX6AK+vZ9XOMOXQmX0xOM0gv3nqgyKaPvCSw16/cRwVqL7ewk0NZGMPQItLYSbGsn2NYaWg9tb2sFnx+TnIxJSgo9EjFJSbiSkzGJST3bk51nV1LEtqTk8GtcSUl7HCcJo5ZMETlM/QleY4HaiPUtwIl7lFkJXIjTHfkfQKYxZoS1dndkIWPMNcA1ABMmTDjUOstAstZpUQqPadoZsVwPbTud5e4JMT1NB541PDnbCU+pOU6QyhrTs5yS0xOuwuuh5aQMBaYhzlpLoKmJYGtEQGpvI9ja6gSp0Ho4SLW2EmgPbW9rC4ctAge+n6FJS8OdkYFJSCDo82K9PmxXF9brhWAwOm8oMRFXYmKvMOZKS8OVmYk7IwNXVhbuzAxcGZm4szJxZWTiyszAnZWFKyMDd2amUzYzE5OaijlCf79tIECws5NgewfBjnaCHR3Yjg6CkY/2PdY7Ogh2dmASEnGlpOBKS8WkpOJKTcWVmoJJ7V7u3p7Ss5yWiislBZOWhklMPGJ/rgI2GHR+V9rasB5PvKtzSKI1uP5m4JfGmMuBxUAdsNcnpbX2aeBpgHnz5vVjpkWJioCv5+q79npoq+9Z7itc+ffxy5yS09P9NrwQUub0BKo+A9QwZ+C4uumOCtZa/Fu30lmxCk9FOZ0VFXhWrSbYso+rOUNMYiKuzEwnmGRk4MrIIHHcONwZ6U5wycgIhZmM0Hq6E2AiyrvS0zEJ+/44s34/1usl2NXlBDKfF+v1hoOZ9XoJer3YrtD20P5geL+vd3lfT/lgZwfBllZ89TsJVlURbGkh0J+w6HaHw5orMwN3RiaurEznORTOnOeIIJeZ6bxPa7FBCzbofFkKBrHWhpd79jtlbDDozG1rgz1lgxYIvTZyv7XOemh/sLMzHIzs/kJTxMN2dvb/FychAVd6uhNgU1JCoa0D2+kh2NnZr9Ddi8vlBLLuoJaS0ns5LRVXd6BLTydl+jRS584lcdSogzvPIGT9fjxr1tCxtJSO0lK6NmzAlZKMSUtzfr5poZ/zno/0vbeZtDTc6enOa9PTDzvQWmuxXV17tViHv4CFWqy7v4A5X8i6W7lbCYS3tzu/10NYf4JXHTA+Yn1caFuYtXYrTosXxpgM4CJrbVO0Kin70NUKjTXYhmpo34HZV7jqbOj79a5EyBjZMzg8b1ooWIUeGRHLabmQkBTTtwfgb2iga9063MNHkJQ/AVdKSszrEG3B9na6qjbhrdpI18Yq/PX1JI4bS/LEiSQVFpJUUDAk3qdv5048kSGrYhWBhtDvWkICKVOmkPXpT5NcVOQEisxMXOkZoZCREQ5brqSB/70yCQmYhARcaWkDfi6I6B5tbXVa8bpb/FpaQn9kWgm0tDrPrW3hMr7NtXjaWgm2OOUHm3ALX+iPcfcfbfeI4RF/tNP7/qOe3vcffbOff39rLfh8TvjzeJxQ53ECWbCzE9vZSbDTQ9ATsRwR2npv78RfXx8+lu3oINDRAT5nuEPC6NGkzZlD6ty5pM2dQ/KUKfsN84NBsKsLT3k5HaWlTthavhzb4fRAJBUUkFpS4gTZUCD2Ndb1DsgdB3GP09D/n30+0tMgISEUqEK/0+3tPa3d7e3hn/X+mJQU5zMivfszIp2k3Fzns6L7syP0BcyVEuNhJOefH5XDGHuA5GiMSQDWA5/CCVxLgUuttasiyuQCDdbaoDHmx0DAWnv3/o47b948W1paerj1P7L5OqFps/NorIammtByDb66GtqqumjbmkL7jiRciZbUEV5Sj3GTOj6LlIKRuIePDAWoiHCVPrKn1WqQTWNg/X66Nmygc8UKOpYvp3PFSnybN/cUMIaE0aNILiggKfKRn0/i2LGD7kPS39iId+NGuio30lW1Ee/GKrqqqvBv29ZTKCGBhGHD8O/a1fMtzhgSR48mKRTEkicWOoGscCIJI/Pi0o3ib2x0QtaqCjrLK/BUVODfscPZ6XKRPGkSKcXFpBTPJLWkhOQpU3AlJ8e8nkcSGwwSbG8Pt6B1hzPr9ztjzYwLDKFl46y7jPP74XIBxlmP2G9cxlnex/7w8br3G5yWobQ0pxUp8ciaL876/XjWrqNz2TI6li+jc9ny8O+1Ky2NlGNnkTZnLqlz55I6+1jcGRlxrW+wvZ2OFSvoKC2lc2kpnWVlTlc6kDx1Kmnz5pF2/DzSjjuOhLy8Ax7PBoNOMO2r5bK9fR8tm+09wa09omxHB9bnCwWkTNzp6T0t2ZkZoS9dES3W6REt2ZmZuNLTnaECg/h3zBjzsbV23mEf50DBK3SyzwCP4kwn8Zy19sfGmB8BpdbaF4wxF+NcyWhxuhq/ba3d7z1KFLxwugCba6GxpleoCi+37QgXtUHwNKfRujuXtlo3XTucH2/iyGGknzgX63fRuWY93uoa5wXGkFQ0kdRZx5I6axapx84iefLkQRVO/I2NdK5cSeeKFXQuX0FneXn4G5g7L5e02bNJnT2blOnTnRBTU4O3uhpvdQ3eTZsItkbM6J6YSNK4cb0DWegxkGHFWot/2za6NlaFW7C6Q1agsTFczqSmklxYSNKkIpInFpFUNJHkoiKSxo/HJCYS7Ox03t+mTXRVVeHdVI23qoqu6upe30pd6emhENY7kCUV5Ect6ARaW/GsWh1qyVqFp6IC35ae2WGSCgtJKS4mtXgmKSUlpEybFrOWJJGB1P3/uWPZ8lAYW07XunVO963LRfKUKaTNnUPqnDmkzplL4tgxA/pFKNDcTMfHy5wWrdJSPKtWOV2vbjcpM2b0BK25c3Hn5AxYPcQR0+A1EI6K4BUMQMvWUKtVTShURSy3bnUSVTfjhuxxMCwfciYQSB5D+2YvbeV1tJWuItDYBG43aXPmkLFgPhkLFpBUVNTrP36guZnOsnI6y8vwrCyjs6wsHABMSgopM2eGg1jqrFkkjB4dkxYUGwjQVbkxFLKW07liBd7qamen203KtGmkhoJW6pw5B/xAs9YSaGx0gtim6ohQ5izbrp7cb9LSSMrPJ6kgn6SCgp4Ws/z8fn9YWZ8Pb20tXRu7W65Cz5s29QpG7pwckoqKnG7DULhKnjjR+TkfwhVx1lr8O3Y4gWzTJrxVm0LLVfi3RrScGUPi2LF7B7LCAhLy9h08gx0deNauxVPeE7K8mzaF9yeOG9cTsopLSJk5A3dm5kG/D5GhKtDW5nxBXL6CzmXL6Fy50hlnBCSMHBnumkydM5eUaVMPq8XGX19Px8cf94zRWr8erMUkJjqtb/PmkTbveFJnz8adkR6ttyj9pOA12HQ2Qd3HsKUU6kph1wZo3rLHdAkGMkeHglV+OGCFlzPH4K3dQuuiRbQtepuO0lLw+3FlZ5Nx6qlkLFhAxiknH9Q3G2stvi1b6FxZhqe8zHlevTrcPO3OzXWCWCiMpZSURKU53QmAZeGQ1bmyLPxh5R4+PByy0ubMJqW4GFdq6mGfs5sNBvFv3463upqu6mp8NTV0hUKZb0tdr8G67pycPlrIRuKrq+sJVxs34t28udf4hIRRo0Lhqojk7taroiIShg+P2vs4kGBHR0QrWU8g826q7jW42ZWR0SuQuTIy8axejaeigq7KyvAVfwnHHOOErJJiUmY63YYJw4bF7P2IDAU2EKBr/Xo6li0LhzHf1q2A07KdWlJC6tw5pM2d6wSkrKx9HstXVxduzepYWhr+MmrS0kibPdtpzZo3j5RZs9R1PwgoeMVTMAA718CWpU7Q2rIUdq0L7TTOIPWR03sCVs4E54bF2eMgofd/Huv10rFsGW1vLaJt0SK8NU5XYfLkSU7QWrCA1GOPjWoXofV68axbT2fZSjxl5XSWlfW0chhD0sSJvVrFkidP3u+3OBsM4q2q6jU2y7txo7PT5SJ56lRSZx/rDFydPZvE8ePjdrm39Xrxbqnr1TrWvRwes9TN5SJpwoS9WrCSCicO6m+bNhjsaSULBTLvpiq6NlWHx5e5hw0jpaSY1OJipyWreCaJI0fGueYiQ5Nvxw6nazLURelZu9b5gmcMyZMmOV2Tc+eQXDQJz9o1dCxdSkdpabjV2pWVRdpxx4W7DlOmTx/UY52OVgpesdS2sydgbVkKdcvA57TekDYCxh0P4+bB2Hkwdq4zaH0//Lt307b4Hdrefpv2d98l2NaGSUwk7aSTnC7E+QtIGjc2Bm+sR6C5mc7yil5hrPsKNZOSQsqMGT2tYtOn462rc77trVhBZ1lZeMoAd3Z2uLswdfZsUkuKcaUP3pASKdjejnfzZnw7dpA4ZoxzdWEMrriLpWBHB4HWtrgN0hc5GgQ7OpwhH8tDYWzFil5jUt0jRoS6DZ2glTx5MsataXcGOwWvgeLvgu3lvYNWU2jAuisBRpWEglYobA0rPOCVgdZautaupe3tt2l7axGdZWVgLQl5eaFWrfmkn3TSoAoo1lp8dXV0rlyJp6yMzrJyp4syYuwUxpA8eXJPyJp9LEkFBfqDLiISwQaDdFVW4t24keSp00gq1OfkUKTg1U82GMSzZg3+HTsxCW6nyy4hAZOQ6Kx37oLdazH1qzH1FZhdazDWCy4w2aMw4+ZiJhwP+SdixsyGxP6NRQp2dtL+wYdO2Hr7bfzbtwOQMmsWGfNPI2PBAlJmzBhS//msz4dn3Xq61q4hccwYUmbNivvl1SIiIrGg4LUfwY4O2j/8kLa33qJt0dv46+ujc+CEBIzbHZ6MkcREZzm0jcRQoHO56Nq4EdvVhSstjfSTT3Zatk47tV9zq4iIiMjgEq3gNXgmdTpMvm3baFu0iNZFi+j4cIkTejIySD/5E2SO8ZDkKYNdm7CBoHMXjfQx2OGTYVgRNrsQmz7KuVuG3weBANbnd24z4veB39+zHvD3Xo8s4w+E13OOO47MhQtInTfviBsnJCIiIodmyAYvGwziKS8PT73QtWYNAIkTJjDski+SsXAhaTktmFduhcZNUHAqnPpZZ2zW2OMgfUSc34GIiIgcbYZU8Aq2t9P2/vu0LVpE29uLCezaBS4XaXPnMvKWm8lYuJCkwkJMez28cie8/DcYXgRffQEmzo939UVEROQoN+iDl6+uzmnVemsRHUuWOPeCysx0JhRduJCMU0/pmVA0GISPn4fXf+Dc53D+7XDKTZA4+G84LCIiIke+QRe8bCBAZ1lZeELRrvXrAedO68Muu4yMBQtImztn78nldqyCf90EtUucbsXzfg65k+PwDkRERET6NiiCV6Ctjfb33neuQly82Jm40+0m7bjjGHnbbWQsmE9yYWHfL/Z2wNs/hQ9+CclZ8Lkn4dhLDji3loiIiEisxS14Wa+Xht/9nrZFi2hfuhR8PueehKed5szefuqp+73HFQAbXoN/f8e58fScy+DMeyEtdvfKExERETkYcZvHqzgl1f6toICkoiIyFswnc+FCUmfP7t89CVu2wcu3w+r/g9wpcN6jUHDywFdaREREjkpDfh6vhNGjKHr1FZImTOj/i4IBKH0O3viRc2ufhd+Dk6/f68bTIiIiIoNR/ILXiBEHF7q2lcG/boS6j2HiAjj3ZzCiaKCqJyIiIhJ1g2Jw/X51tcGi++HDXzvjty58Fkou1uB5ERERGXIGd/Ba+yK8eAu0bIHjLocz7oHUYXGulIiIiMihGZzBq3kLvHQbrP0XjJwBF78CE06Kd61EREREDsvgCl4BP3z0NLz1Y2cg/Rn3wCeuBXfigV4pIiIiMugNnuBVt8wZPL9tJUw6A859BIYVxLtWIiIiIlET/+DlaXFauD56GtLz4OLfwsz/0OB5EREROeLEN3itfgFeuhVat8PxV8Gn7oaU7LhWSURERGSgxC94NVTBX78Cx5TAF/8Lxh32ZLAiIiIig1r8gldXK5z1Mzjxm+COf4+niIiIyECLX+IZOR0+eV3cTi8iIiISa664ndmdFLdTi4iIiMRD/IKXiIiIyFFGwUtEREQkRhS8RERERGJEwUtEREQkRhS8RERERGJEwUtEREQkRhS8RERERGJEwUtEREQkRvoVvIwx5xhj1hljKo0xt/exf4Ix5i1jzHJjTJkx5jPRr6qIiIjI0HbA4GWMcQNPAJ8GZgBfMsbM2KPY94C/WmvnAJcAv4p2RUVERESGuv60eJ0AVFprq6y1XuDPwAV7lLFAVmg5G9gavSqKiIiIHBn6E7zGArUR61tC2yLdA1xmjNkCvAj0efdrY8w1xphSY0xpfX39IVRXREREZOiK1uD6LwHPW2vHAZ8Bfm+M2evY1tqnrbXzrLXz8vLyonRqERERkaGhP8GrDhgfsT4utC3SVcBfAay1HwApQG40KigiIiJypOhP8FoKTDbGFBpjknAGz7+wR5nNwKcAjDHTcYKX+hJFREREIhwweFlr/cC1wCvAGpyrF1cZY35kjDk/VOy7wNXGmJXAn4DLrbV2oCotIiIiMhQl9KeQtfZFnEHzkdvujlheDZwc3aqJiIiIHFk0c72IiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjPQreBljzjHGrDPGVBpjbu9j/8+NMStCj/XGmKboV1VERERkaEs4UAFjjBt4AjgT2AIsNca8YK1d3V3GWntTRPnrgDkDUFcRERGRIa0/LV4nAJXW2iprrRf4M3DBfsp/CfhTNConIiIiciTpT/AaC9RGrG8JbduLMSYfKATe3Mf+a4wxpcaY0vr6+oOtq4iIiMiQFu3B9ZcA/22tDfS101r7tLV2nrV2Xl5eXpRPLSIiIjK49Sd41QHjI9bHhbb15RLUzSgiIiLSp/4Er6XAZGNMoTEmCSdcvbBnIWPMNGAY8EF0qygiIiJyZDhg8LLW+oFrgVeANcBfrbWrjDE/MsacH1H0EuDP1lo7MFUVERERGdoOOJ0EgLX2ReDFPbbdvcf6PdGrloiIiMiRRzPXi4iIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjPQreBljzjHGrDPGVBpjbt9HmS8YY1YbY1YZY/4Y3WqKiIiIDH0JBypgjHEDTwBnAluApcaYF6y1qyPKTAbuAE621jYaY0YOVIVFREREhqr+tHidAFRaa6ustV7gz8AFe5S5GnjCWtsIYK3dGd1qioiIiAx9/QleY4HaiPUtoW2RpgBTjDHvGWM+NMacE60KioiIiBwpDtjVeBDHmQwsAMYBi40xJdbapshCxphrgGsAJkyYEKVTi4iIiAwN/WnxqgPGR6yPC22LtAV4wVrrs9ZuAtbjBLFerLVPW2vnWWvn5eXlHWqdRURERIak/gSvpcBkY0yhMSYJuAR4YY8y/4fT2oUxJhen67EqivUUERERGfIOGLystX7gWuAVYA3wV2vtKmPMj4wx54eKvQLsNsasBt4CbrHW7h6oSouIiIgMRcZaG5cTz5s3z5aWlsbl3CIiIiIHwxjzsbV23uEeRzPXi4iIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMSIgpeIiIhIjCh4iYiIiMRIv4KXMeYcY8w6Y0ylMeb2PvZfboypN8asCD3+X/SrKiIiIjK0JRyogDHGDTwBnAlsAZYaY16w1q7eo+hfrLXXDkAdRURERI4I/WnxOgGotNZWWWu9wJ+BCwa2WiIiIiJHnv4Er7FAbcT6ltC2PV1kjCkzxvy3MWZ8XwcyxlxjjCk1xpTW19cfQnVFREREhq5oDa7/J1BgrZ0FvAb8Z1+FrLVPW2vnWWvn5eXlRenUIiIiIkNDf4JXHRDZgjUutC3MWrvbWtsVWn0WOC461RMRERE5cvQneC0FJhtjCo0xScAlwAuRBYwxoyNWzwfWRK+KIiIiIkeGAzdkzuEAACAASURBVF7VaK31G2OuBV4B3MBz1tpVxpgfAaXW2heA640x5wN+oAG4fADrLCIiIjIkGWttXE48b948W1paGpdzi4iIiBwMY8zH1tp5h3sczVwvIiIiEiMKXiIiIiIxouAlIiIiEiMKXiIiIiIxouAlIiIiEiMKXiIiIiIxErfg1ebxx+vUIiIiInERt+BV29hBW5fCl4iIiBw94ha8/EHLc+9uitfpRURERGIubsErKyWRpxdX0dDujVcVRERERGIqbsFrVFYKHV4/v3qrMl5VEBEREYmpuAWv5EQXF80dx+8+rGFrU2e8qiEiIiISM3GdTuLGM6eAhcde3xDPaoiIiIjERFyD19icVC47KZ+/fVxL5c62eFZFREREZMDFfQLVby8sIjXRzSOvrot3VUREREQGVNyD14iMZK4+bSIvVWxnZW1TvKsjIiIiMmDiHrwA/t+pExmensSDr6yNd1VEREREBsygCF4ZyQlcu3AS71Xu5t0Nu+JdHREREZEBMSiCF8CXT5rA2JxUfvryWqy18a6OiIiISNQNmuCVnODmpjOnUF7XzEsV2+NdHREREZGoGzTBC+A/5oxl8sgMHn51Hf5AMN7VEREREYmqQRW83C7DzWdPpaq+nb8v2xLv6oiIiIhE1aAKXgBnzTiG2eNzePT1DXh8gXhXR0RERCRqBl3wMsZw2znT2Nbs4fcf1MS7OiIiIiJRM+iCF8AnikZw2pQ8nlhUSYvHF+/qiIiIiETFoAxeALeePZWmDh/PLK6Kd1VEREREomLQBq/isdmcN2s0z76zifrWrnhXR0REROSwDdrgBfDds6biDQT55Zsb4l0VERERkcM2qINXYW46Xzx+PH/8aDO1DR3xro6IiIjIYRnUwQvghk9NxmUMP39tfbyrIiIiInJYBn3wOiYrhctPLuB/V9SxdntLvKsjIiIicsgGffAC+Ob8IjKSE3j4lXXxroqIiIjIIRsSwSsnLYlvzC/i9TU7Ka1uiHd1RERERA7JkAheAFecXEBeZjI/fXkt1tp4V0dERETkoA2Z4JWWlMD1n5rM0upGFq2rj3d1RERERA5av4KXMeYcY8w6Y0ylMeb2/ZS7yBhjjTHzolfFHpccP578EWn89OW1BINq9RIREZGh5YDByxjjBp4APg3MAL5kjJnRR7lM4AZgSbQr2S3R7eI7Z05h7fZW/lm2daBOIyIiIjIg+tPidQJQaa2tstZ6gT8DF/RR7l7gp4AnivXby2dnjWH66CweeXU9Xn9wIE8lIiIiElX9CV5jgdqI9S2hbWHGmLnAeGvtv/d3IGPMNcaYUmNMaX39oY3TcrkMt54zlc0NHfyltPbALxAREREZJA57cL0xxgX8DPjugcpaa5+21s6z1s7Ly8s75HMumJLHCQXD+cUbG+jw+g/5OCIiInL4rLU0ehrjXY0hoT/Bqw4YH7E+LrStWyZQDCwyxlQDJwEvHGiAfW1rLS3eQ5uJ3hin1au+tYvfvld9SMcQERGRw9fh6+Abr3+D0/5yGhe9cBFPrXyKTc2b4l2tQas/wWspMNkYU2iMSQIuAV7o3mmtbbbW5lprC6y1BcCHwPnW2tL9HbTV28oX/vkFVu1adUgVn1cwnDOmj+TJtzfS1OE9pGOIiIjIoWvwNHDVK1exZNsSvjz9y6QlpPHLFb/k/P87nwtfuJAnVz5JVXNVvKs5qBwweFlr/cC1wCvAGuCv1tpVxpgfGWPOP9QTF2QXELABvvLSV/jjmj8e0qSoN589lbYuP79+e+OhVkNERGRAWWt5YeMLXP7y5ZRu32+bxJBS11bHV1/6KhuaNvDowke5/YTb+f1nfs9rF7/GbcffRkZiBk+seIIL/u8C/uMf/8GvV/yajU36e23iNQv8vHnz7Ovvvs6d797JO3XvcFb+WdzzyXvITMo8qON85y8r+Hf5Nt6+ZSGjslMGqLYiIiIHr6q5ivs+vI+l25eS7E4mYAN878TvcdGUi+JdtcOyrmEd33z9m3gCHp741BPMGTmnz3I72nfw+ubXebX6VZbvXI7FUpRdxFkFZ3FW/llMGjYpxjU/dMaYj621hz1PaVyDV2lpKUEb5PlVz/OLZb9gTMYYHp7/MDNG7DVN2D7VNnRw+iOLuPi48dx/YckA1lhERKR/PH4Pz5Y/y28qfkNqQio3HXcTZ+WfxW2Lb+O9re9x6bRLueX4W0hwJcS7qgetdHsp1795PamJqTx1xlP9Dk87O3byes3rvFrzKst2LMNimZg9kTPzz+SsgrOYnDMZY8wA1/7QHTHBq9uyHcu4ZfEtNHoaue342/jC1C/0+x/gnhdW8fsPa3jtptOYmJcxUFUWERE5oPfr3ue+JfdR21rLeRPP47vzvktuai4A/qCfn3/8c363+necNPokHp7/MNnJ2XGucf+9UfMGty6+lbGZY3nqjKcYnTH6kI5T31HPG5vf4NWaV/l4x8cEbZCCrIJwS9iUYVMGXQg74oIXOIP07nz3Tt6re49zCs7hB5/4ARlJBw5S9a1dzH/oLU6fNpJfXjp3oKosIiKyT7s6d/HgRw/yUvVL5Gfl872TvsdJo0/qs+z/bvhf7v3wXkanj+bx0x9nYs7EGNf24P1t/d+478P7KB5RzBOfeoKclJyoHHdX5y7eqHFCWOmO0nAIOzP/TM4uOHvQhLAjMngBBG2Q5yqe4/HljzM+czyPzH+EqcOnHvB4P3t1Hb94s5J/XXcKxWOHzrcHEREZ2gLBAH9b/zd+sewXeAIeri65mitLriTZnbzf163YuYIb3roBb8DLT0/7KaeNOy1GNT441lqeKnuKJ1Y8wSljT+GR+Y+Qlpg2IOfa1bmLNze/yas1r7J0+1KCNkh+Vr7THZl/FtOGT4tbCDtig1e30u2l3Lr4Vpq7mrn9xNu5ePLF+/1ht3h8nPbgW8wal8PvrjxhIKosIiLSy5rda7j3w3sp31XOiaNP5Hsnfo+C7IJ+v35b2zauf+t61jWs46bjbuLymZcPitadboFggAc+eoA/r/sz5xedzz2fvIdEV2JMzt3gaXC6I6udEBawASZkTgiPCZs+fHpMf1ZHfPAC2N25mzveuYMPtn3AZwo/ww8+8YP9puxnFlfx4xfX8MerT+STRbnRrrKIiAgA7b52nljxBH9Y8wdyknO49fhb+UzhZw4pCHT4Ovj+e9/n1ZpX+ezEz/KDT/7ggK1lseANeLn9ndt5reY1rph5BTcdd1PcQmGjpzEcwj7a/hEBG6Awu5ArZl7BeRPPI9E98GHwqAhe4HQ9PlP2DL9a+SsmZE7gkQWPMGXYlD7LenwBFj68iGOyUvjfb31yUH1rEBGRoc9ay5ub3+T+j+5nZ8dOPj/l81w/9/rDHiBvreXJsif51YpfMSt3Fo8ufJS8tEO/td7havO2ccNbN/DR9o+4ed7NfG3m1+JWlz01eZp4Y/Mb/GXdX1jTsIaRaSP56oyvcvGUi0lPTB+w8x41wavbR9s+4rZ3bqPV28pdJ97F5yZ9rs9g9Zelm7nt7+U89ZXjOHvmqGhWWUREjmJb27bykyU/4e0tbzNl2BTu/sTdHJt3bFTP8VrNa9z17l1kJmXyi4W/YGbuzKgevz92de7im69/k8rGSn508o/4bNFnY16H/rDW8sG2D3iu/DmWbF9CVlIWX5r2JS6dfinDU4ZH/XxHXfAC55fh9nduZ8m2JZxfdD53nXjXXl2P/kCQsx5djMsYXrnxNNwutXqJiMih8wV9/H7173ly5ZMAfHv2t/ny9C8P2Bxc6xrWcd2b19HgaeDek+/l04WfHpDz9KW2pZZrXruG3Z7d/GzBzzhl7CkxO/fhKKsv47mK53hj8xukuFO4cPKFfG3m1xiTMSZq5zgqgxc4A/2eLnuaX6/8NYXZhTwy/5G9Jm97qXwb3/zDMh66eBafnzd+H0cSERHZvxU7V/DDD35IZVMlC8cv5I4T7jjkuasOxu7O3Xxn0XdYtnMZV5dczbVzrsVl+nN75UO3evdqvvn6NwnaIE986glm5c0a0PMNhKqmKn676rf8a+O/APjMxM9wxcwrojJD/lEbvLp9uO1Dblt8G53+Tu468S4umHRBeJ+1lgueeI/dbV7evHk+yQnuaFRZRESOEs1dzfz845/z9w1/Z1T6KO444Q5On3B6TOvgC/i4b8l9/M+G/2Hh+IXcf+r9AzaG6cNtH3LDmzeQnZzNk2c+ycTswT+v2P5sb9/O71b/jv9e/990+jtZMH4BVxVfxeyRsw/5mEd98AJn5tvb3rmNpduX8rlJn+POE+8kNSEVgPcqd/HlZ5dw93kzuPKUwmhUWUREjnDWWv5V9S8eLn2Y5q5mvjLjK3zz2G8O2LxV/anPH9f+kYeWPkRhdiGPn/444zLHRfUcL1e/zJ3v3El+Vj5PnvEkx6QfE9Xjx1OTp4k/rf0Tf1j7B5q7mjnumOO4qvgqThl7ykFfgKfgFRIIBvj1yl/zdNnTFOUU8cj8R8IzAF/27BJWb2th8a0LyUiOzf2wrLU0eBrISc7B7VJLm4jIULGpeRP3fXgfH23/iFl5s7j7pLv7NYF3LHyw9QO++/Z3cRs3P1vwM44fdXxUjvvHNX/kgY8eYM7IOfzi9F8MqdsXHYwOXwf/s+F/eH7V8+zo2MHUYVO5svhKzio4q99j9RS89vB+3fvc8e4ddPo7+f5J3+ezRZ9lZW0TFzzxHjeeMZkbz+h7CopD5Qv42Ny6mU3Nm3o9qluqafO1MWXYFB5d+CjjMzXGTESiw1qraXIGQFegy7mhdflvSElI4ca5N3LxlIsHfEzVwappqeG6N6+jtqWWO068gy9M/cIhH8tayy9X/JKny55mwfgFPHTaQ6QkpESxtoOTL+DjxU0v8lzFc1Q1VzEuYxxXFF/BBZMuOODcaQpefdjRvoNbF9/Ksp3LuGjyRdx+wu3c9OdVLF5fz+JbFzIi4+AnpGvyNLGpJSJYNVezqWUTW1q3ELCBcLmRaSMpzC6kMKuQvLQ8nl/1PAbDQ6c9xCfHfjKab1NEjkIfbP2AH37wQ0amjeSOE+5g+ojp8a7SEeH9re/z4w9/zObWzZw78Vxunndz+IbWg1Grt5VbF9/Ku3XvcsnUS7j1hFsPeiZ5f9DPfR/ex983/J0LJ1/I90/6/oBdoTlYBW2Qt2rf4jflv6F8VzkjUkZw2YzL+OLUL5KZlNnnaxS89sEf9PPEiid4tvxZJg+bzA3F93LFM9WcNWMUD1xUQk5aUp+v2dq2NdxiFdmC1djVGC6X6EokPyvfCVgRj4Ksgr0GPNa21HL9W9dT1VzFDXNv4IqZV+ibqogctDZvG498/Aj/vf6/yc/Kp9XbSlNXE5+f8nmum3PdEds1NNBqW2p5fMXjvLTpwDe0HmwCwQCPLnuU51c9z4mjTuTh+Q/3+4bVHr+H2xbfxpu1b3J1ydVcN+e6o/pvk7WW0h2l/Kb8N7y39T0yEjP4wtQv8JUZX9krgCt4HcA7W97hznfvxBvw8omsr/PC+8eQmRbg0pNTmTa+k5rW6nDIqmmpwRf0hV87PGU4BVkFewWsMeljDmrcVoevg7vfv5tXql/h7IKz+dEnfxS3AZoiMvR8sPUDfvD+D9jevp2vzfwa3579bbxBL79a8Sv+tPZPZCVlccPcG7hw8oWDrltssNrUvIlnyp7hxU0v4jZuriq5iqtKrhoUt+g5WP+o/Ac//OCHHJN2DI+f/vgBp0xo8bZw3RvXsXzncm474Ta+PP3LMarp0LBm9xp+U/EbXqt5jQSTwAWTLuCKmVcwPssZMqTg1Q/b27dz6+JbWb5zOdlJw2n2NoT3uXAxIWsCBdkF4S7C7oAVzW+Q1lp+u+q3PLbsMYpyinhswWPhf0QRkb5EtnIVZBVw78n37nUZ/LqGdfxkyU9YtnMZxSOKueukuyjOLY5TjQe/DY0beKbsGV6ufpmUhBQ+P+XzXD7z8rjelicaVtav5IY3b8AT8PDTU3/K/PHz+yy3s2MnX3/t61S3VHP/KfdzTuE5Ma7p0FHTUsPzq57nH5X/IGADnJ1/NleWXMn0EdMVvPrDF/TxfMXzVLdUU5hVSHPLMP5niZe6+jTOmD6Gu86dQWHuwN3bqdv7de9zy+JbsFgePO3BITMbsIjEVl+tXPsa9Gyt5d+b/s0jpY+wu3M3F06+kBvm3sCwlGExrvXgtbZhLU+tfIrXN79OWkIaX5r2Jb4686sDckuZeNnevp3r37yetQ1ruWHuDVxZfGWv7sNNzZv4xmvfoKmriUcXPsonxnwijrUdOuo76vn9mt/z13V/pd3XTsXlFQpeh6rLH+C371Xz+Bsb8AaCXP7JAq49fTLZqQN7d/Pa1lpufOtGNjRu4Pq513NV8VVHdd+6iPToTyvX/l775Mon+cOaP5CWmMZ1c67j81M+f1RPaVOxq4KnVj7Foi2LyEzM5NLpl3LZ9Mv6PRZqqOn0d3L3e3fzcvXLnDvxXO75xD2kJKRQXl/Ot974Fi7j4ldn/IqZI2J/78ehrsXbwl/W/oVrjr1Gwetw7Wz18PAr6/jbx1sYnpbEd8+ayhePHz+g93fs8HVwz/v38FL1S5yZfyb3nXyfxn2JHOUOppVrfzY2beT+JfezZPsSpg2fxl0n3nVYM3UPRSt2ruDJsid5r+49spKy+MqMr3Dp9EvJSsqKd9UGnLWWZ8qf4fHlj1M8ophLp1/KvR/ey4iUETx15lNMyJoQ7yoOaRrjFUUVdc388J+rWFrdyPTRWdx93gw+UTRiwM5nreV3q3/Hzz7+GROzJ/LowkfJz8ofsPOJyOB0OK1c+2Kt5dWaV3lo6UPs6NjB+UXnc9NxNw3qKRKiYen2pTxV9hRLti1hWPIwvjbza1wy7ZIBu8XOYPbG5je44x1nXsupw6by5JlPHvH//rGg4BVl1lpeLN/OT15cQ11TJ+fMHMWdn5nOhBED1xr1wdYPuHXxrQSCAX562k85ddypA3YuERlcotXKtS8dvg6eKX+G51c9T4o7hW/P/jaXTLvkiJqvyVrLh9s+5MmVT7Js5zJGpIzgiuIr+PyUzx/1PQnrG9fz0qaXuLL4yn3OSyUHR8FrgHh8AZ5ZXMWvFm0kELRcdWoh3144acBuOVTXVseNb93IuoZ1XDvnWq4uuVrjvkSOYO2+dh4ufTiqrVz7U91czQMfPcB7W99jUs4k7jzxzqjdbiZerLW8U/cOT5U9RVl9GSPTRnJl8ZVcNPmio2L2dYkPBa8Btr3Zw4Mvr+V/lteRl5nMLWdP5eK543ANwPivTn8n97x/Dy9uepEzJpzBfafcd1Q2j4sc6Qa6lWtfrLW8VfsWDy59kLq2Oj5d+GlunnczI9NGDvi5o6n7fTxV9hSrd69mTPoYriq5is9N+hxJ7r0nxxaJJgWvGFm+uZEf/Ws1yzc3UTI2m7s/O4PjC6J/GbK1lt+v/j0/+/hn5Gfl89jCxyjILoj6eUQk9tp97TxS+gh/W/+3mLRy7YvH7+G5iuf4TflvSHAl8I1jv8Fl0y8j0T2wV3QfrqAN8lrNazxd9jTrG9czLmMc18y6hvOKzjvo2+WIHCoFrxiy1vKPFVt54KW1bG/xcN6s0dzxmemMzUmN+rmWbFvCLW/fgi/o44FTH9jnZHgiMjTEq5Vrf2pba3lw6YMsql1EYXYhd5xwx6Cc2ykQDPBy9cs8U/YMG5s3UpBVwDWzruHThZ8+osaqydCg4BUHHV4/T75dxVNvbwTg66dN5BsLikhLiu4HwNa2rdz41o2sbVjLt2Z/i2tmXaPbgYgMMYOllWt/Fm9ZzAMfPUBtay1n5p/JLfNuYXTG6HhXC1/Qx4tVL/JM+TPUtNQwKWcSX5/1dc7MP/OonptM4kvBK47qmjp54KW1/HPlVkZlpXDbp6dywbFjozr+y+P38MMPfsi/qv7FwvEL+ckpPyEjKSNqx5ejiz/op7KpkvJd5ezq2MXU4VMpyS0Z8rdLGawGYyvXvnQFuvjPVf/JM2XPYIzh6pKr+drMr8VlzJQv4OMfG//Bs+XPUtdWx7Th0/j6rK9z+oTT9eVT4k7BaxAorW7gh/9cTXldM3Mm5PCDz85k9vjozYpsreWPa//IQ0sfYkLWBB5b+BiF2YVRO77srb6jnsqmSsZkjGFcxrgh+e3aWsu29m2U7Sqjor6C8l3lrN69Gk/As1fZkWkjKR5RTHFuMTNzZzJzxMyo3qv0aDMUWrn2ZVvbNh4qfYjXal5jQuYEbj/h9oOa4sZaS1egizZfG+2+9vCjzdtGm6+NDl9Hr33dy5H7dnfupsXbQvGIYr5+7NeZP26+rvKWQUPBa5AIBi1/X7aFB19ZR31rFxfOGcut50xjVHb0vt0u3b6Um9++GW/Ay09O+QkLJyyM2rGPZoFggMqmSlbsXMHy+uWs2LmCura68P5kdzKF2YUU5RQxKWcSk3ImUZRTxNiMsYPq23eLt4WKXRWU15c7z7vK2e3ZDUCSK4npI6ZTkltCcW4xs3JnkZuWy7qGdVTsqqBidwUVuyqoaakJHy8/K5+ZI2ZSnOsEsmnDp5GaEP3xjEeaodTKtT/vb32f+5fcT3VLNQvGL2DeMfP2Cki9gpS3Z5/f+g94fLdxk56YTkZiBulJ6aQnpJOe5KxnJGZwRv4ZnDzmZAUuGXQUvAaZti4/v3qrkmff3YTbGC45YTznzRrDnPE5UemC3Na2jRsX3cjq3av51rHf4uvHfn3A//g3dzWzuWUzNa011LT0PLa2bSU3NZepw6cyZdgUpg5znnNTcwf1h2W7r52y+jJW1K9gxc4VlNWX0eZrAyAvNY/ZI2czZ+QcJg+bzLa2bWxs2khlcyUbmzayvX17+DipCakUZheGg1j38+j00QP+b+IL+FjXuI7yXeWU15dTvquc6pbq8P7C7EJKckucR14JU3Km9OuKteauZlbvXs2q3avC4W1nx07A+UM5KWdSuFWseEQxk4ZN0tVkIUO5lWtffAEf/7Xmv/j1yl/T6e8EIC0hrc+wlJ6Y3hOkQs9piU7ZjKSe5e59ye7kQf05IbIvCl6DVG1DBw++so5XKrbjDQQZk53CubNGc+6sMRw7LvuwPnA8fg/3fngvL2x8gQXjFvCTU39y2DMSd/g62Ny6uVewqmmpYXPLZhq7GsPlDIYxGWPIz8pnTMYYdrTvYH3jenZ07AiXGZ4ynMnDJvcKY0U5RXGbX2db2zaW71weDlrrGtcRtEEMhsnDJjNn5Bxmj5zN7LzZjM0Yu99/m1ZvKxubNjphrKkyvLyzc2e4TFpCGkU5Rb3C2KScSRyTdswh/btba6ltrXW6DEMtWmsa1uAL+gAYkTKCkrwSZuXOCrdORXOG6vqO+nCr2KpdqyjfVU6LtwVwWgO7x4l1t47lZ+UPqpbAaLLW0uZro8XbQktXC83eZlq6Wtjt2c3zFc+zrX3bkG7l2heP34M/6CctMe2I/bcV6S8Fr0GuxePj9dU7+HfZNhZvqMcXsIwblsq5s0ZzXskYisdmHfIf4z+t/RMPLX2IcZnjeOz0x5iYPXG/r/EGvNS21vYZriKDA8DI1JHkZ+czIXMCBVkFTMhynsdljuszQDV5mtjQtIH1jetZ17CO9Y3rqWyqpCvQBTitJYXZhUweNjkcxqYOn0peal5Uv/X6g37WNa5jxU4nZC3fuTwcClMTUpmVN4s5I+cwJ28OJXklUQsozV3NVDVXUdlUSWVjZTiYdXf1AWQkZjAxZ2Kv7spJOZP2+hk0ehqdlqzQo2JXBc1dzeH3MGPEjJ7WrNwSRqWPimnLgbWWLa1bwt2TFbsqWNOwJtwikpmYyYwRM8IhsDi3+JBD50Cw1tLh76Clq4UWbwvNXc1OkAqFqX1u8zbT6m0laIN9HvdIaeUSkf1T8BpCmjt9vLpqO/8u38a7G3bhD1ryR6Rxbslozp01mhmjDz6ElW4v5btvf5euQBc/PuXHzB83n21t26huqWZz62aqm6vDLVnb2rf1+qMxLHkY+Vn54VA1IWuCs545ISr3N/MH/Wxu3cz6xvWsb1jvhLLGdb2663KSc5g6bGpPC9nwqRTlFJHsTu7XOVq9raysX8nynctZuXMlZbvKwgFgVPoo5uTN6dV1GOs5f5o8TeGWscqmSjY2Oy1kDZ6GcJnMpEwm5UxiRMoI1jasZUvbFgBcxkVRTlG4Jaskt4SinKJBOW+RP+inqrmKVbtWhVvH1jesD4/1GZEygoLsAhJMAsYYDAaXcWGM8+zCtf/txoSXXcbllGH/270Bbzg8tXa1hgNVq7d1v2OQ3MZNZlIm2cnZZCVl9TySnede2yO25aXmDcmLMETk4MQ0eBljzgEeA9zAs9baB/bY/w3g20AAaAOusdau3t8xj6bgFampw8urq3bwz7KtvL9xN4GgZWJueqg7cjRTj8nsdwjb3r6dm966iYrdFSS4EvAHe/6oZCRmhMNVfla+88h01uN11VpzVzMbGjewrnGd89ywjsqmyvDVdm7jpiCrgCnDpjBl+BTnedgUjkk7hi1tW8ItWct3Lmdj00YsFrdxM2XYFKc1K9R1OCp9VFzeX380eBrCYayysTLcOjZl2JTwAPiZI2YO6Rv8dgW6woP3V+1exZZWJ1AGbZAgQay1WGvDy5HbgzYY/pLQvWzp2W6tDa/vub37GAmuhHA4yk7KDoekXuGpjzCVnpg+aFrnRGTwiVnwMsa4gfXAmcAWYCnwpchgZYzJsta2hJbPB75lrT1nf8c9WoNXpIZ2Ly9XbOff5Vv5YONughYmjczg3JLRnDdrNJOPOXB3WFegi99W/BaP39MTsLLyGZ4yfEj8EQkEA9S21rKucV2vFrKt7VvDZZLdyeGuy4zEDI7NOzbcmlWSWzKkQ4qIiAwNsQxenwDusdaeHVq/A8Bae/8+yn8J+Kq19tP7O66CV2+72rp4qWI7/y7bypJNDVgLU4/JDLeEB59zSQAAIABJREFUFeUdXZOntnhb2NDojB3b3LKZwuxCjs07lkk5k9StIyIiMRfL4HUxcI619v+F1r8CnGitvXaPct8GvgMkAadbazf0caxrgGsAJkyYcFxNTc2eRQTY2erhpfLt/LtsG0trnBA2bVQmnz12DOeWjKYgNz3eVRQRETmqDLrgFVH+UuBsa+3X9ndctXj1z/ZmDy+Wb+Pf5dv4uMaZ3mHmmCzOm+WEsAkj1M0mIiIy0AZzV6MLaLTW7ncEt4LXwdva1MmL5dv4V9k2VtQ2ATBrXDbnzRrNGdOPoTBXg4NFREQGQiyDVwLO4PpPAXU4g+svtdauiigzubtr0RjzWeAHB6qcgtfhqW3o4KUKJ4SVbXHmeho/PJXTJuf9//buNLyt6t73+HdpsCRLHuR5ykicxAQTkpixJwkkhFIa5hsMDS0ESJ8yNSTnHuAJFHJ7aE9bTnsK96FMvSmkB05KQ+nAUA4pAZfDUJwBEjLYIYOHeJBnO7YsW1r3xZYV2ZYTh9iWY/8/z6NHW3tvbS0tb0k/r7322iycnspF01Jw2Ubf8ANCCCHE6Wikh5O4AvglxnAS67XWP1JK/RAo1lr/WSn1BHAp0AU0AveEB7NIJHgNnfKGdt4r8fD+Pg8ffVnHUZ8fi0kxb5KbBdONIHZmZvyQXLpICCGEGI9kAFURka87wNbDjbxf4qGoxMPuKuMSLymuGBbkprJgeirzc1NIdg1uoFIhhBBCSPASg1Tb6uXvJXW8X+Lh76UeGtu7UArOykpg4XQjiM2ZmIjVLNdhE0IIIQYiwUucNH9As6uymaISD++XeNhe3oQ/oImzWbhoWjILp6exYHoKOW45U1IIIYQIJ8FLnLLmji4+3F9HUanRP+xIs3HpnjNSnaG+YRdMTcZulQFLhRBCjG8SvMSQ0lrzpaeN9/Z5KCqt45MD9XR2B7BZTJw3JYmFwSA2Lc0lQ1YIIYQYdyR4iWHl7fLzycEG3t/noajUw/7aNgAyE+wsnJ7KeVOSmDPRzeTkWAliQgghxjwJXmJEVTZ1GH3D9nn4ny/raPV2A+COtXLOhETmTnQzZ6KbsyckEG+3Rrm0QgghxNAak8Grq6uLiooKvF5vVMokerPb7eTk5GC19g5S/oBmf20b28sa2VbWyPayJkqDLWJKQW6aizkT3MyZmMjcSW6mpbpkDDEhhBCntTEZvA4ePEhcXBzJycly+CrKtNbU19fT2trKlClTTrh+c0cXn1c0sb2sie1ljWwvb6KpvQuAOJuF2RMSmTMxeJvgxu2MGe63IIQQQgyZoQpeo+qaMl6vl8mTJ0voGgWUUiQnJ+PxeAa1foLDyvzcVObnpgJGcDtYd9QIYuVGq9iv3vsSf8AI+lNSnMwJhTE3MzPisMhYYkIIIca4URW8AAldo8ip/C2UUkxNdTE11cX183IAaPd183lFc6hVrKi0jj9srwTAYTWTn5MQahGbOzGRtHj7kLwPIYQQYrQYdcFLjF2xMRYumJrMBVOTAaNVrLKpg209hyfLmlj/wUG6/AcAyE50MGdiIudMSOSs7ATyMuNJcEjHfSGEEKcvCV59uFwu2traol2McUEpRY47lhx3LFfNzgKMYSx2V7Uc6ytW1sTrn1eFnpPjdpCXGc+ZmfHkZcYzKyueHLdDWkqFEEKcFiR4iVHFbjUzd6KbuRPdgNGpv7bVy+4jLeypamV3VQu7jzTztz01BLuLEWezGGEsK568zDjOzEwgN90lI+4LIYQYdUZt8Po/f/mC3UdahnSbZ2bF8+iVswa1rtaa+++/n7feegulFA8//DCFhYVUVVVRWFhIS0sL3d3dPP3001x00UXcfvvtFBcXo5TitttuY/Xq1UNa9vEsLc5O2gw7F89IC83r8PnZV9MaDGQt7K5q4ffF5Rz1+QEwmxRnpDpDLWNGKIsnxWWL1tsQQgghRm/wirY//OEP7Nixg88++4y6ujrOPfdcFixYwMsvv8zXv/51HnroIfx+P+3t7ezYsYPKykp27doFQFNTU5RLP/Y5YsycM8Ho/9UjENCUNbSzuyoYxo608I+DDfxxx5HQOmlxtlAI6wllU1KcmGWcMSGEECNg1AavwbZMDZcPPviAm266CbPZTHp6OgsXLuTTTz/l3HPP5bbbbqOrq4trrrmGc845h6lTp3LgwAHuvfdevvnNb3LZZZdFtezjlcmkmJziZHKKkyvyM0PzG4/6Qq1iRihr5YPSA3QHj1XarSZmZhxrGTszM47c9DgZgV8IIcSQG7XBa7RasGABRUVFvPHGG9x6662sWbOG73znO3z22We8/fbbPPPMM7zyyiusX78+2kUVQW5nDBdNS+GiaSmheZ3dfvbXthn9xoKHK9/cWcV//aMstE5mgp3c9Dimp7mYnh5HbrqL3PQ4XDb52AghhPhq5BdkAPPnz+fZZ5/llltuoaGhgaKiIh5//HEOHz5MTk4OK1eupLOzk23btnHFFVcQExPD9ddfz4wZM7j55pujXXxxAjaLmVlZCczKSoB5xjytNUeavew50kJJbSulNW2U1LTy2wP1dHYHQs/NTnSQmx4MY2GhLDZGPk5CCCGOT34pBnDttdfy0UcfMXv2bJRS/OxnPyMjI4MXX3yRxx9/HKvVisvlYsOGDVRWVrJixQoCAePH+d/+7d+iXHrxVSilyE50kJ3o4NIz00Pz/QFNeUM7JTWtlNYaYaykpo0Pv6zHFxbIctyOUAibkR7H9PQ4zkh14YiRsyuFEEIYRtW1Gvfs2UNeXl5UyiMik7/JwLr9Acoa2impaaO0ppWSWuP+S08bXX7jc6UUTEyKJTctjunpx1rHzkiV4S6EEOJ0Miav1SjE6cRiNoUui3T5WRmh+d3+AIfq24MtY8cOWb63rzbUod+kYFKyk9w0FzMyjNaxGRlxTElxYpVrVgohxJglwUuIIWYxm5iW5mJamqvX2ZW+7gCH6o+GDlWWBoPZ3/bWhi4ebjUrzkgNC2PBQJad6MAkQ14IIcRpT4KXECMkxmJierDvV7jObj8HPEfZV93KvppW9lW3UnyokT+FjT/mjDEzPeNYEJuRHsf0jDgZEFYIIU4zEryEiDKbxUxecDDXcK3eLkpq2thXbbSM7a1u4e0vqtn4aXlonRRXTOgwZU8okyEvhBBi9JJvZyFGqTi7lXmT3Myb5A7N01rjaeukpLot2DrWwr6aNjb+o5yOLn9ovRy3g5lhfcdmZMQxNcVFjEX6jwkhRDRJ8BLiNKKUMq5dGWfnn3KPDQgbCGgqGjvYW90SbB1rDXbo94Q69FtMiqmpTnLT4piYHMsEdywTk2KZkOQgK9EhnfqFEGIESPASYgwwmRQTk2OZmBzLZbOOnWHp6w5woM44XNlzyHLXkWbe/qI6FMjAOMsyM8ERCmLGvXGbmBRLsjMGpaRzvxBCnCoJXlHS3d2NxSLVL4ZXjMW4DuXMjN79x/wBTXWLl7L6dsob2ylvMG5lDe1s2efB09rZa32H1RwKZROSwlvLjHkyar8QQgzO6P22fOtBqN45tNvMyIdv/OSEq11zzTWUl5fj9XpZtWoV3/3ud/nrX//K2rVr8fv9pKSk8Le//Y22tjbuvfdeiouLUUrx6KOPcv311+NyuWhrawNg06ZNvP7667zwwgvceuut2O12tm/fzte+9jVuvPFGVq1ahdfrxeFw8Jvf/IYZM2bg9/t54IEH+Otf/4rJZGLlypXMmjWLJ598kj/+8Y8AvPPOO/zqV7/itddeG9o6EuOC2XRslP4LSe63vMPnp6LRCGJGIOugrKGdisZ2Pvyynnafv9f6Ka6YXoFsYlIsOcGWs8wEB2YZCkMIIYDRHLyiaP369SQlJdHR0cG5557L1VdfzcqVKykqKmLKlCk0NDQA8K//+q8kJCSwc6cREBsbG0+47YqKCj788EPMZjMtLS38/e9/x2KxsHnzZtauXcurr77Kc889x6FDh9ixYwcWi4WGhgbcbjd33XUXHo+H1NRUfvOb33DbbbcNaz2I8csRYyY33ThDsi+tNQ1HfUYoa+zo1Vq2vbyRN3ZWhcYlAyPkZcTbyUq0k5lg9CfLTrSTleggM8EIf/EOixzKFEKMC6M3eA2iZWq4PPnkk6GWpPLycp577jkWLFjAlClTAEhKSgJg8+bNbNy4MfQ8t9vdf2N9LFu2DLPZuFRMc3Mzt9xyC6WlpSil6OrqCm33e9/7XuhQZM/rffvb3+Y///M/WbFiBR999BEbNmwYoncsxOAppUh22Uh22Zgzsf8+3+0PUNXsDbWWlTe2U9XkpbKpgx3lTby1qyp0SaUezhizEcR6QlmCMZ2VaCc70UFGgh2bRS6xJIQ4/Y3e4BUl7733Hps3b+ajjz4iNjaWiy++mHPOOYe9e/cOehvh/7l7vd5ey5xOZ2j6Bz/4AZdccgmvvfYahw4d4uKLLz7udlesWMGVV16J3W5n2bJl0kdMjEoWsynUMT+SQEBT19bJkWYvR5o6grfgdHMHu480U9fm6/e8FJetV0tZTygzApudFKdNRvcXQox68svdR3NzM263m9jYWPbu3cvHH3+M1+ulqKiIgwcPhg41JiUlsWTJEp566il++ctfAsahRrfbTXp6Onv27GHGjBm89tprxMX1P1zT81rZ2dkAvPDCC6H5S5Ys4dlnn+WSSy4JHWpMSkoiKyuLrKwsHnvsMTZv3jzsdSHEcDCZFGnxdtLi7ZwzITHiOt4uP9U9wSwsoFU2dVBa28b7JZ5+/cxizCYyg61lWYkOst0OcoL32cFwJq1mQohok+DVx+WXX84zzzxDXl4eM2bM4IILLiA1NZXnnnuO6667jkAgQFpaGu+88w4PP/wwd999N2eddRZms5lHH32U6667jp/85CcsXbqU1NRUCgoKQh3t+7r//vu55ZZbeOyxx/jmN78Zmn/HHXdQUlLC2WefjdVqZeXKldxzzz0ALF++HI/HQ15e3ojUhxDRYLeamZziZHKKM+JyrTXNHV29WsqOBA9nHmnq4H/211HT6kWHHdFUClJdtlAQ6x3MYsl2O2TEfyHEsFNa6xOvNQwKCgp0cXFxr3l79uyRQHEC99xzD3PmzOH2228fkdeTv4k4Xfm6A1Q3e6loaqey0Wgt67nvObzp8wd6PSfBYQ2Fsp6zPsODmoxnJsT4pZTaqrUuONXtDOrfO6XU5cATgBn4tdb6J32WrwHuALoBD3Cb1vrwqRZO9DZv3jycTic///nPo10UIUa9GIspNKhsJD19zSrCAlnPfVl9Ox99WU9bZ3ev59itpuBZmQ5ygoFsUrKT3HQXU1KccihTCHFCJwxeSikz8BSwBKgAPlVK/VlrvTtste1Agda6XSl1J/AzoHA4Cjyebd26NdpFEGLMCO9rNjfC2Zlaa1o6uiO2mFU2dbD7SAv1R4+dBGBSMDnZybQ0F7npLuM+LY4zUl04YiSQCSEMg2nxOg/Yr7U+AKCU2ghcDYSCl9Z6S9j6HwM3D2UhhRBipCmlSIi1khCbwKyshIjrdPj8HKo/SmltG/trWimtbaO0to1399aGLsmklHHR8ty0OHLTgoEsPY5paS7pUybEODSYT302UB72uAI4/zjr3w68FWmBUuq7wHcBJk6cOMgiCiHE6OSIMZOXGU9eZu9LMnX5AxyuP0ppTVsojJXWtPJBaV2vfmWZCfZQy1huuovc4HRCrHWk34oQYoQM6b9bSqmbgQJgYaTlWuvngOfA6Fw/lK8thBCjhdVsYlpaHNPS4vhG2Pxuf4Dyxg5Kg61j+2vbKK1t5eV/HMbbdSyQpcbZgiHMxbT0OKalGocvpXO/EKe/wQSvSmBC2OOc4LxelFKXAg8BC7XWnX2XCyHEeGcxm5iS4mRKipPLZh2bHwjo4BhlrUYYC7aUvbqtslcHf3eslYwEBwkOCwkOa79bvMNKYmxM73l2CxazKQrvVggRyWCC16dArlJqCkbguhH4VvgKSqk5wLPA5Vrr2iEvpRBCjGEmkwqN9r9oZnpovtaa6hZvKIjtr23F09pJc0cXB+uO0tzRRVN7F53dgeNsHVw2SyiYHS+0RZovoU2IoXXC4KW17lZK3QO8jTGcxHqt9RdKqR8CxVrrPwOPAy7g98Fm8DKt9VXDWO5RweVyDTg46qFDh1i6dCm7du0a4VIJIcYKpRSZCcYlkhZMTx1wPW+XnxZvFy0dXTSH39q7aO7o7jWvpaOLQ3XtoccdXf4BtwuQ5IwhI95OZoKdjISee0evx7ExcpKAEIM1qE+L1vpN4M0+8x4Jm750iMvFT//xU/Y2DP76iIMxM2kmD5z3wJBuUwghos1uNWO3mkmLs5/0czu7/bSEhbPw8NbU3kVtq5fqZi9VzV62lzfRcLT/dTTj7RYyExxhwax/QIuzWaR/mhDIJYN6efDBB5kwYQJ33303AOvWrcNisbBlyxYaGxvp6uriscce4+qrrz6p7Xq9Xu68806Ki4uxWCz84he/4JJLLuGLL75gxYoV+Hw+AoEAr776KllZWdxwww1UVFTg9/v5wQ9+QGGhDIkmhBgeNouZ1DgzqXG2Qa3v7fJT02IEsZ5AVt3cYdy3eNld1UJdWyd9L4rijDEHA1mEgBZvBLTEWKuEMzHmjdrgFY2WqcLCQu67775Q8HrllVd4++23+f73v098fDx1dXVccMEFXHXVVSf15fDUU0+hlGLnzp3s3buXyy67jJKSEp555hlWrVrF8uXL8fl8+P1+3nzzTbKysnjjjTcA40LaQggxWtitZiYlO5mUHPk6mmBcrim8pSx032IEtP/ZX0dNi5dAn3Bms5hIcdlwO624Y2NIcsYcu3fGkBScNh4b61ilD5o4zYza4BUNc+bMoba2liNHjuDxeHC73WRkZLB69WqKioowmUxUVlZSU1NDRkbGoLf7wQcfcO+99wIwc+ZMJk2aRElJCRdeeCE/+tGPqKio4LrrriM3N5f8/Hz++Z//mQceeIClS5cyf/784Xq7QggxLGIsJnLcseS4I1+uCYyhNerafFQ1d4QFMy/1bT4a2300HPVR1tBOw1Efrd7uAbcTZ7f0DmixMSS7eh5b+wW3BIcVk0la1UT0SPDqY9myZWzatInq6moKCwt56aWX8Hg8bN26FavVyuTJk/F6vUPyWt/61rc4//zzeeONN7jiiit49tlnWbRoEdu2bePNN9/k4YcfZvHixTzyyCMn3pgQQpxGLGYTGcHDjSfi6w7Q1GGEsYajPhqPdtHQ7qOx53EwqNW0eNlbZVzKaaAzPU0K3LF9WtBcMSQ7jVuSy2ZMu4LLYmPkzE4xpCR49VFYWMjKlSupq6vj/fff55VXXiEtLQ2r1cqWLVs4fPjkr/09f/58XnrpJRYtWkRJSQllZWXMmDGDAwcOMHXqVL7//e9TVlbG559/zsyZM0lKSuLmm28mMTGRX//618PwLoUQ4vQRYzGRFmc/qZMHOnz+XuGsoU9Ia2z3Ud/m40tPG58e8tHQ7uvXL61HYqyVJGdPOLNJUBOnRIJXH7NmzaK1tZXs7GwyMzNZvnw5V155Jfn5+RQUFDBz5syT3uZdd93FnXfeSX5+PhaLhRdeeAGbzcYrr7zCb3/7W6xWKxkZGaxdu5ZPP/2Uf/mXf8FkMmG1Wnn66aeH4V0KIcTY5ogxkx3jIDvRMaj1/QFNUzCU1R81QlnD0c6waR/1RztDQa2x3devj1qPgYJakjOm37hp8XYr8Q4LDqtZTiwYJ5QeKOIPs4KCAl1cXNxr3p49e8jLy4tKeURk8jcRQoj+BhvUeqaPF9QArGZFvN0IY3FhVx3oCWk9y+KDA+AeeyxXJxgpSqmtWuuCU92OtHgJIYQQJ8lsUiS7bCS7bOQOYn1/QPcaK63F2zNtjKF27PGxcdTKG9pDj7uPl9owhuvo3YpmJTHWSmaCnaxER+g+K9GByyY//dEktX+Kdu7cybe//e1e82w2G5988kmUSiSEEGK0MZtUaCiMk6W1pqPL3zuktR8/vFU2dbCrspna1v7DdsTZLWQlOMhKtJOZ6CArFM6MQ7PpCTZsFvMQvXPRlwSvU5Sfn8+OHTuiXQwhhBBjlFKK2BgLsTGWQZ0FGq7LH6C2tZMjTR0caTLGUTOmvVQ1d7CjvInG9q5+z0tx2chONAa8zUy0kx0MZj3TKS4bZhmW4yuR4CWEEEKMUVaziezE459k0OHzU9VshLEjzcGAFpwurW2lqNRDu6/3NT0tJkV6fDCQBQNaRryNhFhrvz5oCQ4rNotJTh4IkuAlhBBCjGOOGDNTU11MTXVFXK61pqWjm8qmDiOgBVvNqpqM6a2HG6lurjpuP7QYs8k4ESDs5AAjlFn6hbS+JxLE2a1jqnVNgpcQQgghBqSUMlqyYq2cmRUfcZ1AQNPQ7gueONDd60SB8L5oLV5jflO7j8P1R0Pr+k9w8kCczRIMbsZZnD1nejptZpw2Cy6bBWeMMd1zcwWXOWN65plHRd81CV5CCCGEOCUmkyLFZSPFNbiLrYfTWtPu84dCWuhkgQGCW88Zn63ebo76ujna2U2Xf3BDY1nNKiyMhYc2C7E2szEdnBcbE7Z8CM8EleB1ClwuF21tbdEuhhBCCHHaUkqFWqmyGNyAt311dvs52unnaOexMNbW87jn5vPT1tlNe/gyXzdtnd3UtnTS1nnyQe6rGLXBq/rHP6Zzz94h3aYtbyYZa9cO6TZHg+7ubiyWUfunFEIIIYaVzWIcRvwqw3VE4usOBMPbsTBW8NMh2TQy1G2YBx98kKeeeir0eN26dTz22GMsXryYuXPnkp+fz5/+9KdBbautrW3A523YsIGzzz6b2bNnh8YAq6mp4dprr2X27NnMnj2bDz/8kEOHDnHWWWeFnvfv//7vrFu3DoCLL76Y++67j4KCAp544gn+8pe/cP755zNnzhwuvfRSampqQuVYsWIF+fn5nH322bz66qusX7+e++67L7Td559/ntWrV3/lehNCCCHGkhiLCbczhglJsczMiGfepKSh27jWOiq3efPm6b52797db95I2rZtm16wYEHocV5eni4rK9PNzc1aa609Ho8+44wzdCAQ0Fpr7XQ6B9xWV1dXxOft2rVL5+bmao/Ho7XWur6+Xmut9Q033KD/4z/+Q2utdXd3t25qatIHDx7Us2bNCm3z8ccf148++qjWWuuFCxfqO++8M7SsoaEhVK7nn39er1mzRmut9f33369XrVrVa73W1lY9depU7fP5tNZaX3jhhfrzzz+P+D6i/TcRQgghRgOgWA9B/pHjU2HmzJlDbW0tR44cwePx4Ha7ycjIYPXq1RQVFWEymaisrKSmpoaMjIzjbktrzdq1a/s9791332XZsmWkpKQAkJRkpOh3332XDRs2AGA2m0lISKCxsfG4r1FYWBiarqiooLCwkKqqKnw+H1OmTAFg8+bNbNy4MbSe2+0GYNGiRbz++uvk5eXR1dVFfn7+SdaWEEIIIU6WBK8+li1bxqZNm6iurqawsJCXXnoJj8fD1q1bsVqtTJ48Ga/Xe8LtfNXnhbNYLAQCgdDjvs93Op2h6XvvvZc1a9Zw1VVX8d5774UOSQ7kjjvu4Mc//jEzZ85kxYoVJ1UuIYQQQnw10serj8LCQjZu3MimTZtYtmwZzc3NpKWlYbVa2bJlC4cPHx7UdgZ63qJFi/j9739PfX09AA0NDQAsXryYp59+GgC/309zczPp6enU1tZSX19PZ2cnr7/++nFfLzs7G4AXX3wxNH/JkiW9+q31tKKdf/75lJeX8/LLL3PTTTcNtnqEEEIIcQokePUxa9YsWltbyc7OJjMzk+XLl1NcXEx+fj4bNmxg5syZg9rOQM+bNWsWDz30EAsXLmT27NmsWbMGgCeeeIItW7aQn5/PvHnz2L17N1arlUceeYTzzjuPJUuWHPe1161bx7Jly5g3b17oMCbAww8/TGNjI2eddRazZ89my5YtoWU33HADX/va10KHH4UQQggxvJTRX2zkFRQU6OLi4l7z9uzZQ15eXlTKMx4tXbqU1atXs3jx4gHXkb+JEEIIAUqprVrrglPdjrR4jUNNTU1Mnz4dh8Nx3NAlhBBCiKElnetP0c6dO0NjcfWw2Wx88sknUSrRiSUmJlJSUhLtYgghhBDjzqgLXlprlDp9rkKen5/Pjh07ol2MYRGtw9BCCCHEWDWqDjXa7Xbq6+vlB38U0FpTX1+P3W6PdlGEEEKIMWNUtXjl5ORQUVGBx+OJdlEERhDOycmJdjGEEEKIMWNUBS+r1RoacV0IIYQQYqwZVYcahRBCCCHGMgleQgghhBAjRIKXEEIIIcQIidrI9UqpVmBfVF58dEsB6qJdiFFI6qU/qZPIpF4ik3qJTOqlP6mTyGZoreNOdSPR7Fy/byiG3h9rlFLFUi/9Sb30J3USmdRLZFIvkUm99Cd1EplSqvjEa52YHGoUQgghhBghEryEEEIIIUZINIPXc1F87dFM6iUyqZf+pE4ik3qJTOolMqmX/qROIhuSeola53ohhBBCiPFGDjUKIYQQQowQCV5CCCGEECNk2IOXUupypdQ+pdR+pdSDEZbblFK/Cy7/RCk1ebjLFG1KqQlKqS1Kqd1KqS+UUqsirHOxUqpZKbUjeHskGmUdSUqpQ0qpncH32++0XWV4MrivfK6UmhuNco4kpdSMsH1gh1KqRSl1X591xsW+opRar5SqVUrtCpuXpJR6RylVGrx3D/DcW4LrlCqlbhm5Ug+/AerlcaXU3uDn5DWlVOIAzz3uZ+50NkC9rFNKVYZ9Vq4Y4LnH/d06XQ1QJ78Lq49DSqkdAzx3LO8rEX+Th+37RWs9bDfADHwJTAVigM+AM/uscxfwTHD6RuB3w1mm0XADMoG5wek4oCRCvVwMvB7tso5wvRwCUo6z/ArgLUABFwCfRLvMI1w/ZqAamDQe9xVgATAX2BU272fAg8HpB4GfRnifsmeKAAAEIElEQVReEnAgeO8OTruj/X6GuV4uAyzB6Z9GqpfgsuN+5k7n2wD1sg743yd43gl/t07XW6Q66bP858Aj43BfifibPFzfL8Pd4nUesF9rfUBr7QM2Alf3Wedq4MXg9CZgsVJKDXO5okprXaW13hacbgX2ANnRLdVp4WpggzZ8DCQqpTKjXagRtBj4Umt9ONoFiQatdRHQ0Gd2+PfHi8A1EZ76deAdrXWD1roReAe4fNgKOsIi1YvW+r+11t3Bhx8DOSNesCgbYH8ZjMH8bp2Wjlcnwd/dG4D/GtFCjQLH+U0elu+X4Q5e2UB52OMK+geM0DrBL4pmIHmYyzVqBA+tzgE+ibD4QqXUZ0qpt5RSs0a0YNGhgf9WSm1VSn03wvLB7E9j2Y0M/KU43vaVHula66rgdDWQHmGd8b7f3IbRUhzJiT5zY9E9wUOw6wc4dDRe95f5QI3WunSA5eNiX+nzmzws3y/SuT6KlFIu4FXgPq11S5/F2zAOKc0G/i/wx5EuXxT8k9Z6LvAN4G6l1IJoF2i0UErFAFcBv4+weDzuK/1oo91fxscJo5R6COgGXhpglfH2mXsaOAM4B6jCOLQmDDdx/NauMb+vHO83eSi/X4Y7eFUCE8Ie5wTnRVxHKWUBEoD6YS5X1CmlrBh/4Je01n/ou1xr3aK1bgtOvwlYlVIpI1zMEaW1rgze1wKvYTT5hxvM/jRWfQPYprWu6btgPO4rYWp6DjcH72sjrDMu9xul1K3AUmB58Eejn0F85sYUrXWN1tqvtQ4AzxP5/Y67/SX423sd8LuB1hnr+8oAv8nD8v0y3MHrUyBXKTUl+B/7jcCf+6zzZ6DnLID/Bbw70JfEWBE8lv7/gD1a618MsE5GT183pdR5GH+rMRtIlVJOpVRczzRG5+BdfVb7M/AdZbgAaA5rBh7rBvxvdLztK32Ef3/cAvwpwjpvA5cppdzBQ0uXBeeNWUqpy4H7gau01u0DrDOYz9yY0qdP6LVEfr+D+d0aay4F9mqtKyItHOv7ynF+k4fn+2UEzha4AuMMgS+Bh4LzfojxhQBgxzh8sh/4BzB1uMsU7RvwTxhNlp8DO4K3K4DvAd8LrnMP8AXGGTUfAxdFu9zDXCdTg+/1s+D77tlXwutEAU8F96WdQEG0yz1CdePECFIJYfPG3b6CETyrgC6MfhS3Y/QH/RtQCmwGkoLrFgC/DnvubcHvmP3Aimi/lxGol/0Y/U56vl96zhzPAt4MTkf8zI2V2wD18tvgd8fnGD+qmX3rJfi43+/WWLhFqpPg/Bd6vk/C1h1P+8pAv8nD8v0ilwwSQgghhBgh0rleCCGEEGKESPASQgghhBghEryEEEIIIUaIBC8hhBBCiBEiwUsIIYQQYoRI8BJCCCGEGCESvIQQQgghRsj/By3g8jD7Ty5LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 69us/sample - loss: 68.3206 - accuracy: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[68.32055840232336, 0.8737]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 2, 1]), ['Ankle boot', 'Pullover', 'Trousers'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred, [class_names[x] for x in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target'].astype(np.uint8)\n",
    "X_train, X_valid, X_test = X[:50000] / 255.0, X[50000:60000] / 255.0, X[60000:] / 255.0\n",
    "y_train, y_valid, y_test = y[:50000], y[50000:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10000\n",
      "50000/50000 [==============================] - 11s 215us/sample - loss: 0.2185 - accuracy: 0.9345 - val_loss: 0.1063 - val_accuracy: 0.9681\n",
      "Epoch 2/10000\n",
      "50000/50000 [==============================] - 10s 203us/sample - loss: 0.0877 - accuracy: 0.9735 - val_loss: 0.0866 - val_accuracy: 0.9734\n",
      "Epoch 3/10000\n",
      "50000/50000 [==============================] - 10s 204us/sample - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0850 - val_accuracy: 0.9743\n",
      "Epoch 4/10000\n",
      "50000/50000 [==============================] - 10s 203us/sample - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0897 - val_accuracy: 0.9763\n",
      "Epoch 5/10000\n",
      "50000/50000 [==============================] - 10s 205us/sample - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0871 - val_accuracy: 0.9757\n",
      "Epoch 6/10000\n",
      "50000/50000 [==============================] - 10s 205us/sample - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0997 - val_accuracy: 0.9747\n",
      "Epoch 7/10000\n",
      "50000/50000 [==============================] - 10s 205us/sample - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0967 - val_accuracy: 0.9783\n",
      "Epoch 8/10000\n",
      "50000/50000 [==============================] - 10s 209us/sample - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0820 - val_accuracy: 0.9807\n",
      "Epoch 9/10000\n",
      "50000/50000 [==============================] - 10s 208us/sample - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.1178 - val_accuracy: 0.9763\n",
      "Epoch 10/10000\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.1055 - val_accuracy: 0.9793\n",
      "Epoch 11/10000\n",
      "50000/50000 [==============================] - 10s 205us/sample - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.1015 - val_accuracy: 0.9780\n",
      "Epoch 12/10000\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1245 - val_accuracy: 0.9762\n",
      "Epoch 13/10000\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1069 - val_accuracy: 0.9819\n",
      "Epoch 14/10000\n",
      "50000/50000 [==============================] - 10s 206us/sample - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.1446 - val_accuracy: 0.9768\n",
      "Epoch 15/10000\n",
      "50000/50000 [==============================] - 10s 206us/sample - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1194 - val_accuracy: 0.9772\n",
      "Epoch 16/10000\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9769\n",
      "Epoch 17/10000\n",
      "50000/50000 [==============================] - 10s 206us/sample - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1274 - val_accuracy: 0.9784\n",
      "Epoch 18/10000\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f256c39e110>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10000,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1183 - accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11829665097946376, 0.9809]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f\"\\nval/trian {logs['val_loss'] / logs['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10000\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9360\n",
      "val/trian 0.5205386753156831\n",
      "50000/50000 [==============================] - 11s 212us/sample - loss: 0.2160 - accuracy: 0.9361 - val_loss: 0.1124 - val_accuracy: 0.9661\n",
      "Epoch 2/10000\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9726\n",
      "val/trian 0.9743186004086393\n",
      "50000/50000 [==============================] - 10s 199us/sample - loss: 0.0895 - accuracy: 0.9726 - val_loss: 0.0872 - val_accuracy: 0.9737\n",
      "Epoch 3/10000\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9811\n",
      "val/trian 1.4671190980306639\n",
      "50000/50000 [==============================] - 10s 199us/sample - loss: 0.0599 - accuracy: 0.9812 - val_loss: 0.0879 - val_accuracy: 0.9763\n",
      "Epoch 4/10000\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9856\n",
      "val/trian 2.065752887661169\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.0923 - val_accuracy: 0.9749\n",
      "Epoch 5/10000\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9892\n",
      "val/trian 2.4334097900957596\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0811 - val_accuracy: 0.9771\n",
      "Epoch 6/10000\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9906\n",
      "val/trian 3.073947244953572\n",
      "50000/50000 [==============================] - 10s 199us/sample - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0877 - val_accuracy: 0.9771\n",
      "Epoch 7/10000\n",
      "49952/50000 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9918\n",
      "val/trian 3.6879851760075977\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0902 - val_accuracy: 0.9766\n",
      "Epoch 8/10000\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9926\n",
      "val/trian 5.699210410984133\n",
      "50000/50000 [==============================] - 10s 201us/sample - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9746\n",
      "Epoch 9/10000\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933\n",
      "val/trian 4.5346261043580425\n",
      "50000/50000 [==============================] - 10s 202us/sample - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.0865 - val_accuracy: 0.9799\n",
      "Epoch 10/10000\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9954\n",
      "val/trian 7.809648789670413\n",
      "50000/50000 [==============================] - 10s 202us/sample - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.1095 - val_accuracy: 0.9781\n",
      "Epoch 11/10000\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9949\n",
      "val/trian 7.0878512580633855\n",
      "50000/50000 [==============================] - 10s 201us/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.1081 - val_accuracy: 0.9774\n",
      "Epoch 12/10000\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9947\n",
      "val/trian 7.3976124716009295\n",
      "50000/50000 [==============================] - 10s 201us/sample - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.1201 - val_accuracy: 0.9761\n",
      "Epoch 13/10000\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9958\n",
      "val/trian 10.650256206991733\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.1257 - val_accuracy: 0.9758\n",
      "Epoch 14/10000\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9958\n",
      "val/trian 9.18963916010893\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1234 - val_accuracy: 0.9791\n",
      "Epoch 15/10000\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9957\n",
      "val/trian 7.578356139435786\n",
      "50000/50000 [==============================] - 10s 200us/sample - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1062 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f256eaf4ad0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10000,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                     PrintValTrainRatioCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "X_train = pipe.fit_transform(X_train)\n",
    "X_valid = pipe.transform(X_valid)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 1.4190\n",
      "val/trian 0.4760054685459678\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 1.3969 - val_loss: 0.6649\n",
      "Epoch 2/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.5816\n",
      "val/trian 0.9123390275069773\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.5789 - val_loss: 0.5282\n",
      "Epoch 3/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.4792\n",
      "val/trian 0.9662231038149565\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.4818 - val_loss: 0.4655\n",
      "Epoch 4/10000\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.4380\n",
      "val/trian 0.9940947819163022\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.4376 - val_loss: 0.4350\n",
      "Epoch 5/10000\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.4154\n",
      "val/trian 1.0067924236140857\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.4154 - val_loss: 0.4182\n",
      "Epoch 6/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.4017\n",
      "val/trian 1.0143393021949223\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.4019 - val_loss: 0.4077\n",
      "Epoch 7/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3943\n",
      "val/trian 1.0117876111418527\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3926 - val_loss: 0.3973\n",
      "Epoch 8/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.3847\n",
      "val/trian 1.0102623682015703\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3859 - val_loss: 0.3899\n",
      "Epoch 9/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3803\n",
      "val/trian 1.0285430945315832\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3803 - val_loss: 0.3912\n",
      "Epoch 10/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3771\n",
      "val/trian 1.011337936314977\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3770 - val_loss: 0.3813\n",
      "Epoch 11/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3736\n",
      "val/trian 1.0226702225764472\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3739 - val_loss: 0.3824\n",
      "Epoch 12/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3723\n",
      "val/trian 1.0193914908086967\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3707 - val_loss: 0.3779\n",
      "Epoch 13/10000\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.3683\n",
      "val/trian 1.0204996215528002\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3684 - val_loss: 0.3759\n",
      "Epoch 14/10000\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.3643\n",
      "val/trian 1.0166201311188185\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3662 - val_loss: 0.3722\n",
      "Epoch 15/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3670\n",
      "val/trian 1.0097229658039217\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3657 - val_loss: 0.3693\n",
      "Epoch 16/10000\n",
      "11392/11610 [============================>.] - ETA: 0s - loss: 0.3620\n",
      "val/trian 1.0105221482235085\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3623 - val_loss: 0.3661\n",
      "Epoch 17/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3597\n",
      "val/trian 1.0188787770469703\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3611 - val_loss: 0.3680\n",
      "Epoch 18/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3583\n",
      "val/trian 1.005645037590792\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3579 - val_loss: 0.3599\n",
      "Epoch 19/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.3548\n",
      "val/trian 1.0170282200954872\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3534 - val_loss: 0.3595\n",
      "Epoch 20/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3557\n",
      "val/trian 1.0135518935767416\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3536 - val_loss: 0.3584\n",
      "Epoch 21/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3526\n",
      "val/trian 1.0134424594844855\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3513 - val_loss: 0.3560\n",
      "Epoch 22/10000\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.3486\n",
      "val/trian 1.025604818379138\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3485 - val_loss: 0.3574\n",
      "Epoch 23/10000\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.3468\n",
      "val/trian 1.0048059221033836\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.3514 - val_loss: 0.3531\n",
      "Epoch 24/10000\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.3466\n",
      "val/trian 1.0255715935122223\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3458 - val_loss: 0.3547\n",
      "Epoch 25/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.3474\n",
      "val/trian 1.0146109598623543\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3462 - val_loss: 0.3513\n",
      "Epoch 26/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.3484\n",
      "val/trian 1.0002201865450502\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3470 - val_loss: 0.3471\n",
      "Epoch 27/10000\n",
      "10624/11610 [==========================>...] - ETA: 0s - loss: 0.3368\n",
      "val/trian 1.0174982871265952\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3406 - val_loss: 0.3466\n",
      "Epoch 28/10000\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.3424\n",
      "val/trian 1.0147052043280933\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3425 - val_loss: 0.3475\n",
      "Epoch 29/10000\n",
      "10720/11610 [==========================>...] - ETA: 0s - loss: 0.3396\n",
      "val/trian 1.0179768033139895\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3416 - val_loss: 0.3477\n",
      "Epoch 30/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3383\n",
      "val/trian 1.0115195364419274\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3389 - val_loss: 0.3428\n",
      "Epoch 31/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.3382\n",
      "val/trian 1.009878306712519\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3356 - val_loss: 0.3389\n",
      "Epoch 32/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3344\n",
      "val/trian 1.0127851751124177\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3352 - val_loss: 0.3395\n",
      "Epoch 33/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3322\n",
      "val/trian 1.0220365712310149\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3311 - val_loss: 0.3384\n",
      "Epoch 34/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.3328\n",
      "val/trian 1.0057699582471435\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3328 - val_loss: 0.3347\n",
      "Epoch 35/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3246\n",
      "val/trian 1.0256190437453683\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3276 - val_loss: 0.3360\n",
      "Epoch 36/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3287\n",
      "val/trian 1.0104726485621618\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3282 - val_loss: 0.3317\n",
      "Epoch 37/10000\n",
      "10976/11610 [===========================>..] - ETA: 0s - loss: 0.3276\n",
      "val/trian 1.0332680279419355\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3259 - val_loss: 0.3367\n",
      "Epoch 38/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.3256\n",
      "val/trian 1.0156948145502427\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3255 - val_loss: 0.3306\n",
      "Epoch 39/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3259\n",
      "val/trian 1.0328817860497084\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3255 - val_loss: 0.3362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.3253\n",
      "val/trian 1.0093698539531804\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3251 - val_loss: 0.3281\n",
      "Epoch 41/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3202\n",
      "val/trian 1.0263299510435209\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3228 - val_loss: 0.3313\n",
      "Epoch 42/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3210\n",
      "val/trian 1.0093816664667539\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3204 - val_loss: 0.3234\n",
      "Epoch 43/10000\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.3183\n",
      "val/trian 1.016339808485378\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3185 - val_loss: 0.3237\n",
      "Epoch 44/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.3168\n",
      "val/trian 1.0397265507919162\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3175 - val_loss: 0.3301\n",
      "Epoch 45/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.3142\n",
      "val/trian 1.0202266398184061\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3163 - val_loss: 0.3227\n",
      "Epoch 46/10000\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.3171\n",
      "val/trian 1.0312788771575006\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3157 - val_loss: 0.3256\n",
      "Epoch 47/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.3151\n",
      "val/trian 1.0128401267758933\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3158 - val_loss: 0.3198\n",
      "Epoch 48/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3128\n",
      "val/trian 1.0328271342924513\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3126 - val_loss: 0.3228\n",
      "Epoch 49/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.3141\n",
      "val/trian 1.0386491850025985\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3130 - val_loss: 0.3251\n",
      "Epoch 50/10000\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.3123\n",
      "val/trian 1.0214132380125596\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3133 - val_loss: 0.3200\n",
      "Epoch 51/10000\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.3108\n",
      "val/trian 1.0245558063436135\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3103 - val_loss: 0.3180\n",
      "Epoch 52/10000\n",
      "10784/11610 [==========================>...] - ETA: 0s - loss: 0.3124\n",
      "val/trian 1.0428917288518622\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.3103 - val_loss: 0.3236\n",
      "Epoch 53/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3089\n",
      "val/trian 1.0296491259086997\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3095 - val_loss: 0.3187\n",
      "Epoch 54/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.3104\n",
      "val/trian 1.028251640083195\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3087 - val_loss: 0.3174\n",
      "Epoch 55/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3115\n",
      "val/trian 1.0321520043422194\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3102 - val_loss: 0.3202\n",
      "Epoch 56/10000\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.3091\n",
      "val/trian 1.011985529606082\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.3095 - val_loss: 0.3132\n",
      "Epoch 57/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.3064\n",
      "val/trian 1.018840449558387\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3076 - val_loss: 0.3134\n",
      "Epoch 58/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.3066\n",
      "val/trian 1.041455319175041\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3053 - val_loss: 0.3179\n",
      "Epoch 59/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3053\n",
      "val/trian 1.0465720850307312\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3058 - val_loss: 0.3200\n",
      "Epoch 60/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3092\n",
      "val/trian 1.0439248937107632\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3089 - val_loss: 0.3225\n",
      "Epoch 61/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3106\n",
      "val/trian 1.0123851726868878\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3095 - val_loss: 0.3133\n",
      "Epoch 62/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3018\n",
      "val/trian 1.0448097637994882\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3025 - val_loss: 0.3160\n",
      "Epoch 63/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3060\n",
      "val/trian 1.0327263575044368\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3048 - val_loss: 0.3148\n",
      "Epoch 64/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.3033\n",
      "val/trian 1.031381955717007\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3021 - val_loss: 0.3116\n",
      "Epoch 65/10000\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.3052\n",
      "val/trian 1.0231607059760763\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3021 - val_loss: 0.3091\n",
      "Epoch 66/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3013\n",
      "val/trian 1.039312027200253\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3012 - val_loss: 0.3130\n",
      "Epoch 67/10000\n",
      "11488/11610 [============================>.] - ETA: 0s - loss: 0.3037\n",
      "val/trian 1.0609068816073435\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3030 - val_loss: 0.3215\n",
      "Epoch 68/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.3023\n",
      "val/trian 1.0323626636356067\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3021 - val_loss: 0.3119\n",
      "Epoch 69/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.3017\n",
      "val/trian 1.0455094835748409\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3006 - val_loss: 0.3143\n",
      "Epoch 70/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3056\n",
      "val/trian 1.0272104396090298\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3024 - val_loss: 0.3107\n",
      "Epoch 71/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.3028\n",
      "val/trian 1.0214467103066978\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3035 - val_loss: 0.3101\n",
      "Epoch 72/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.2968\n",
      "val/trian 1.0421958224438201\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2975 - val_loss: 0.3100\n",
      "Epoch 73/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2997\n",
      "val/trian 1.0568730945649123\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2987 - val_loss: 0.3157\n",
      "Epoch 74/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2974\n",
      "val/trian 1.0359092177968598\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2976 - val_loss: 0.3083\n",
      "Epoch 75/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.3002\n",
      "val/trian 1.0325360451112495\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2995 - val_loss: 0.3092\n",
      "Epoch 76/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.3011\n",
      "val/trian 1.020945062358502\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3017 - val_loss: 0.3080\n",
      "Epoch 77/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2999\n",
      "val/trian 1.0314359751328919\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2990 - val_loss: 0.3084\n",
      "Epoch 78/10000\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.3015\n",
      "val/trian 1.0249071578370659\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2998 - val_loss: 0.3073\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.3024\n",
      "val/trian 1.021632240892369\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2991 - val_loss: 0.3055\n",
      "Epoch 80/10000\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.2941\n",
      "val/trian 1.0381041711571877\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2954 - val_loss: 0.3066\n",
      "Epoch 81/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2986\n",
      "val/trian 1.0413237711268277\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2968 - val_loss: 0.3090\n",
      "Epoch 82/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2987\n",
      "val/trian 1.0386647246878995\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2977 - val_loss: 0.3092\n",
      "Epoch 83/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2989\n",
      "val/trian 1.01745676082557\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2993 - val_loss: 0.3045\n",
      "Epoch 84/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2953\n",
      "val/trian 1.0248234755537875\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2953 - val_loss: 0.3026\n",
      "Epoch 85/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2950\n",
      "val/trian 1.0481632536146241\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2936 - val_loss: 0.3078\n",
      "Epoch 86/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2955\n",
      "val/trian 1.0343822065580537\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2942 - val_loss: 0.3043\n",
      "Epoch 87/10000\n",
      "11584/11610 [============================>.] - ETA: 0s - loss: 0.2945\n",
      "val/trian 1.0352359056481366\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.2943 - val_loss: 0.3046\n",
      "Epoch 88/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2965\n",
      "val/trian 1.021644105367739\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2972 - val_loss: 0.3036\n",
      "Epoch 89/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2927\n",
      "val/trian 1.0395139659465154\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2932 - val_loss: 0.3048\n",
      "Epoch 90/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2961\n",
      "val/trian 1.0368328387303893\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2942 - val_loss: 0.3050\n",
      "Epoch 91/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2994\n",
      "val/trian 1.029563390212904\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2979 - val_loss: 0.3067\n",
      "Epoch 92/10000\n",
      "11584/11610 [============================>.] - ETA: 0s - loss: 0.2958\n",
      "val/trian 1.0207144295828012\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2961 - val_loss: 0.3022\n",
      "Epoch 93/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2937\n",
      "val/trian 1.0344422907492254\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2943 - val_loss: 0.3044\n",
      "Epoch 94/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2919\n",
      "val/trian 1.0362723365347302\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2923 - val_loss: 0.3029\n",
      "Epoch 95/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2932\n",
      "val/trian 1.027780064436411\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2948 - val_loss: 0.3030\n",
      "Epoch 96/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2980\n",
      "val/trian 1.0471006267493739\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2964 - val_loss: 0.3104\n",
      "Epoch 97/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2939\n",
      "val/trian 1.0393093404943123\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2932 - val_loss: 0.3048\n",
      "Epoch 98/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2903\n",
      "val/trian 1.0395211726543285\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2908 - val_loss: 0.3023\n",
      "Epoch 99/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2921\n",
      "val/trian 1.0390296437626385\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2906 - val_loss: 0.3019\n",
      "Epoch 100/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2890\n",
      "val/trian 1.056531056972409\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2899 - val_loss: 0.3063\n",
      "Epoch 101/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.2911\n",
      "val/trian 1.0278891328098552\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2940 - val_loss: 0.3022\n",
      "Epoch 102/10000\n",
      "10656/11610 [==========================>...] - ETA: 0s - loss: 0.2944\n",
      "val/trian 1.0440110867509873\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2902 - val_loss: 0.3030\n",
      "Epoch 103/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2939\n",
      "val/trian 1.0393131408421385\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2918 - val_loss: 0.3032\n",
      "Epoch 104/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2907\n",
      "val/trian 1.0665092608223994\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2902 - val_loss: 0.3095\n",
      "Epoch 105/10000\n",
      "10976/11610 [===========================>..] - ETA: 0s - loss: 0.2963\n",
      "val/trian 1.0329184946170689\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2963 - val_loss: 0.3061\n",
      "Epoch 106/10000\n",
      "11520/11610 [============================>.] - ETA: 0s - loss: 0.2967\n",
      "val/trian 1.0188711848468865\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2966 - val_loss: 0.3022\n",
      "Epoch 107/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2901\n",
      "val/trian 1.0438977817338666\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2890 - val_loss: 0.3017\n",
      "Epoch 108/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.2916\n",
      "val/trian 1.044689446744282\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2906 - val_loss: 0.3036\n",
      "Epoch 109/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2889\n",
      "val/trian 1.037960085781876\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2883 - val_loss: 0.2992\n",
      "Epoch 110/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2894\n",
      "val/trian 1.0468216212977883\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2887 - val_loss: 0.3022\n",
      "Epoch 111/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2872\n",
      "val/trian 1.03849941621337\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2879 - val_loss: 0.2990\n",
      "Epoch 112/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2875\n",
      "val/trian 1.0644578841064847\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2883 - val_loss: 0.3069\n",
      "Epoch 113/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2965\n",
      "val/trian 1.0279920781482712\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2947 - val_loss: 0.3030\n",
      "Epoch 114/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2901\n",
      "val/trian 1.0495968824973383\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2904 - val_loss: 0.3049\n",
      "Epoch 115/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2893\n",
      "val/trian 1.0518303660222645\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2900 - val_loss: 0.3050\n",
      "Epoch 116/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2879\n",
      "val/trian 1.058196050736069\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2874 - val_loss: 0.3042\n",
      "Epoch 117/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.2879\n",
      "val/trian 1.0725822561855893\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2871 - val_loss: 0.3079\n",
      "Epoch 118/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.2892\n",
      "val/trian 1.0416099397130891\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.2901 - val_loss: 0.3022\n",
      "Epoch 119/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.2851\n",
      "val/trian 1.041418544266525\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2867 - val_loss: 0.2986\n",
      "Epoch 120/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2902\n",
      "val/trian 1.0335650621913446\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2904 - val_loss: 0.3001\n",
      "Epoch 121/10000\n",
      "10944/11610 [===========================>..] - ETA: 0s - loss: 0.2842\n",
      "val/trian 1.0659597179361662\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.2870 - val_loss: 0.3059\n",
      "Epoch 122/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2904\n",
      "val/trian 1.0480775273407523\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2896 - val_loss: 0.3036\n",
      "Epoch 123/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2867\n",
      "val/trian 1.0605230852778122\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2858 - val_loss: 0.3031\n",
      "Epoch 124/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2897\n",
      "val/trian 1.0318647946588149\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2885 - val_loss: 0.2977\n",
      "Epoch 125/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2852\n",
      "val/trian 1.0672123988103843\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2863 - val_loss: 0.3056\n",
      "Epoch 126/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.2933\n",
      "val/trian 1.0428623683203633\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2944 - val_loss: 0.3070\n",
      "Epoch 127/10000\n",
      "10656/11610 [==========================>...] - ETA: 0s - loss: 0.2897\n",
      "val/trian 1.0390466078451492\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2894 - val_loss: 0.3007\n",
      "Epoch 128/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2874\n",
      "val/trian 1.0490448671567478\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2881 - val_loss: 0.3022\n",
      "Epoch 129/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2831\n",
      "val/trian 1.0517502400340282\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2853 - val_loss: 0.3001\n",
      "Epoch 130/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2896\n",
      "val/trian 1.0503685354761072\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2890 - val_loss: 0.3036\n",
      "Epoch 131/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2915\n",
      "val/trian 1.03668871230805\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2910 - val_loss: 0.3017\n",
      "Epoch 132/10000\n",
      "11136/11610 [===========================>..] - ETA: 0s - loss: 0.2885\n",
      "val/trian 1.0523573901305006\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2861 - val_loss: 0.3010\n",
      "Epoch 133/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2852\n",
      "val/trian 1.0486366529286688\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2859 - val_loss: 0.2998\n",
      "Epoch 134/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2871\n",
      "val/trian 1.048184306580363\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2857 - val_loss: 0.2995\n",
      "Epoch 135/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2838\n",
      "val/trian 1.0582384383963417\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2845 - val_loss: 0.3011\n",
      "Epoch 136/10000\n",
      "11040/11610 [===========================>..] - ETA: 0s - loss: 0.2861\n",
      "val/trian 1.0470744311317879\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2848 - val_loss: 0.2982\n",
      "Epoch 137/10000\n",
      "11008/11610 [===========================>..] - ETA: 0s - loss: 0.2854\n",
      "val/trian 1.0492489846361033\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2847 - val_loss: 0.2988\n",
      "Epoch 138/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2861\n",
      "val/trian 1.0546152747664082\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2852 - val_loss: 0.3008\n",
      "Epoch 139/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2874\n",
      "val/trian 1.0377568242441024\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2859 - val_loss: 0.2967\n",
      "Epoch 140/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2843\n",
      "val/trian 1.0512454725293057\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2861 - val_loss: 0.3008\n",
      "Epoch 141/10000\n",
      "10880/11610 [===========================>..] - ETA: 0s - loss: 0.2838\n",
      "val/trian 1.0841207925817902\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2856 - val_loss: 0.3096\n",
      "Epoch 142/10000\n",
      "11232/11610 [============================>.] - ETA: 0s - loss: 0.2859\n",
      "val/trian 1.0572170765191582\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2858 - val_loss: 0.3021\n",
      "Epoch 143/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2884\n",
      "val/trian 1.0241833961967495\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2891 - val_loss: 0.2961\n",
      "Epoch 144/10000\n",
      "11584/11610 [============================>.] - ETA: 0s - loss: 0.2856\n",
      "val/trian 1.0466982822781303\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2854 - val_loss: 0.2988\n",
      "Epoch 145/10000\n",
      "11072/11610 [===========================>..] - ETA: 0s - loss: 0.2860\n",
      "val/trian 1.0580137107824752\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2857 - val_loss: 0.3023\n",
      "Epoch 146/10000\n",
      "11264/11610 [============================>.] - ETA: 0s - loss: 0.2863\n",
      "val/trian 1.0459353872455743\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2879 - val_loss: 0.3011\n",
      "Epoch 147/10000\n",
      "10784/11610 [==========================>...] - ETA: 0s - loss: 0.2914\n",
      "val/trian 1.0328067359884883\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.2909 - val_loss: 0.3004\n",
      "Epoch 148/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2842\n",
      "val/trian 1.051989086583772\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2848 - val_loss: 0.2996\n",
      "Epoch 149/10000\n",
      "11296/11610 [============================>.] - ETA: 0s - loss: 0.2820\n",
      "val/trian 1.0602815208049317\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2830 - val_loss: 0.3000\n",
      "Epoch 150/10000\n",
      "11456/11610 [============================>.] - ETA: 0s - loss: 0.2894\n",
      "val/trian 1.0350869650386916\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2892 - val_loss: 0.2993\n",
      "Epoch 151/10000\n",
      "11328/11610 [============================>.] - ETA: 0s - loss: 0.2889\n",
      "val/trian 1.029774165068929\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2888 - val_loss: 0.2974\n",
      "Epoch 152/10000\n",
      "11360/11610 [============================>.] - ETA: 0s - loss: 0.2837\n",
      "val/trian 1.0547819885769871\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2843 - val_loss: 0.2999\n",
      "Epoch 153/10000\n",
      "11424/11610 [============================>.] - ETA: 0s - loss: 0.2854\n",
      "val/trian 1.043647812703585\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.2849 - val_loss: 0.2974\n",
      "Epoch 154/10000\n",
      "11392/11610 [============================>.] - ETA: 0s - loss: 0.2834\n",
      "val/trian 1.0529245471880089\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2831 - val_loss: 0.2981\n",
      "Epoch 155/10000\n",
      "11200/11610 [===========================>..] - ETA: 0s - loss: 0.2827\n",
      "val/trian 1.0581523898731888\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2839 - val_loss: 0.3005\n",
      "Epoch 156/10000\n",
      "11168/11610 [===========================>..] - ETA: 0s - loss: 0.2924\n",
      "val/trian 1.030973363225624\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.2892 - val_loss: 0.2981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/10000\n",
      "11104/11610 [===========================>..] - ETA: 0s - loss: 0.2851\n",
      "val/trian 1.0431480842438792\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.2858 - val_loss: 0.2981\n",
      "Epoch 158/10000\n",
      "10976/11610 [===========================>..] - ETA: 0s - loss: 0.2887\n",
      "val/trian 1.051067980247514\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.2873 - val_loss: 0.3020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f255119ecd0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10000, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n",
    "                     PrintValTrainRatioCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.3161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3161145052937574"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot(figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.4299262],\n",
       "        [4.3882833],\n",
       "        [2.1958513]], dtype=float32), array([2.004, 3.97 , 1.964]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred, y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning ANN hyperparameters - sklearn grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 92us/sample - loss: 1.9140 - val_loss: 0.7491\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6823 - val_loss: 0.6428\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6328 - val_loss: 0.6227\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.6104 - val_loss: 0.6005\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6425 - val_loss: 0.6817\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7543 - val_loss: 0.9062\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.3794 - val_loss: 2.0011\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 3.5236 - val_loss: 5.8277\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 12.3551 - val_loss: 20.6580\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 41.6728 - val_loss: 77.6448\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 161.4891 - val_loss: 286.1953\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 596.2399 - val_loss: 1091.8439\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 2270.6556 - val_loss: 4101.1278\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 8454.2557 - val_loss: 15837.5126\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 11216.4286\n",
      "[CV]  learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9, total=   7.4s\n",
      "[CV] learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 87us/sample - loss: 2.6047 - val_loss: 1.1097\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9809 - val_loss: 0.9996\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9843 - val_loss: 0.9968\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.9175 - val_loss: 0.9351\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.9113 - val_loss: 0.9552\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8907 - val_loss: 0.9279\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8980 - val_loss: 0.9247\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.8723 - val_loss: 0.8957\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8781 - val_loss: 0.8984\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8403 - val_loss: 0.8821\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 1.7715 - val_loss: 0.8823\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8432 - val_loss: 0.9451\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.9236 - val_loss: 0.9075\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.8038 - val_loss: 0.8685\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8415 - val_loss: 0.8917\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8319 - val_loss: 0.8930\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.7755 - val_loss: 0.8911\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8464 - val_loss: 0.9527\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9110 - val_loss: 0.9361\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8695 - val_loss: 0.9424\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9047 - val_loss: 0.9125\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 1.8656 - val_loss: 0.8867\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.8006 - val_loss: 0.9280\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.8749 - val_loss: 0.9569\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.5014\n",
      "[CV]  learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9, total=  11.8s\n",
      "[CV] learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 1.7860 - val_loss: 0.6197\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5653 - val_loss: 0.5446\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5399 - val_loss: 0.5349\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5310 - val_loss: 0.5286\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5258 - val_loss: 0.5253\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5219 - val_loss: 0.5231\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5190 - val_loss: 0.5213\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5173 - val_loss: 0.5220\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5164 - val_loss: 0.5214\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5152 - val_loss: 0.5205\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5149 - val_loss: 0.5198\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5139 - val_loss: 0.5230\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5141 - val_loss: 0.5193\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5134 - val_loss: 0.5205\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5139 - val_loss: 0.5188\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5135 - val_loss: 0.5192\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5139 - val_loss: 0.5189\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5138 - val_loss: 0.5199\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5128 - val_loss: 0.5195\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5140 - val_loss: 0.5200\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5133 - val_loss: 0.5194\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5133 - val_loss: 0.5194\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5126 - val_loss: 0.5200\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5132 - val_loss: 0.5188\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5129 - val_loss: 0.5197\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5133 - val_loss: 0.5209\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5132 - val_loss: 0.5194\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5132 - val_loss: 0.5191\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5132 - val_loss: 0.5190\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5135 - val_loss: 0.5188\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5135 - val_loss: 0.5192\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5134 - val_loss: 0.5194\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5130 - val_loss: 0.5195\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5126 - val_loss: 0.5208\n",
      "3870/3870 [==============================] - 0s 28us/sample - loss: 0.5206\n",
      "[CV]  learning_rate=0.0048041052445756145, n_hidden=0, n_neurons=9, total=  16.7s\n",
      "[CV] learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 1.9604 - val_loss: 0.8571\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7756 - val_loss: 0.7197\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6928 - val_loss: 0.6635\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6528 - val_loss: 0.6330\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6158 - val_loss: 0.6015\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5892 - val_loss: 0.5803\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5655 - val_loss: 0.5610\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5493 - val_loss: 0.5496\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5349 - val_loss: 0.5341\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5278 - val_loss: 0.5241\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5121 - val_loss: 0.5120\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5034 - val_loss: 0.5046\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4930 - val_loss: 0.4969\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4900 - val_loss: 0.4907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4802 - val_loss: 0.4834\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4749 - val_loss: 0.4790\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4694 - val_loss: 0.4743\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4670 - val_loss: 0.4710\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4616 - val_loss: 0.4665\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4592 - val_loss: 0.4655\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4557 - val_loss: 0.4617\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4570 - val_loss: 0.4633\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4537 - val_loss: 0.4582\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4535 - val_loss: 0.4582\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4506 - val_loss: 0.4557\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4560 - val_loss: 0.4577\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4510 - val_loss: 0.4546\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4543 - val_loss: 0.4551\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4493 - val_loss: 0.4514\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4517 - val_loss: 0.4503\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4441 - val_loss: 0.4479\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4502 - val_loss: 0.4487\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4430 - val_loss: 0.4478\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4525 - val_loss: 0.4532\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4536 - val_loss: 0.4471\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4573 - val_loss: 0.4617\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4462 - val_loss: 0.4355\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4286 - val_loss: 0.4343\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4212 - val_loss: 0.4319\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4193 - val_loss: 0.4320\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4180 - val_loss: 0.4301\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4167 - val_loss: 0.4291\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4155 - val_loss: 0.4281\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4144 - val_loss: 0.4275\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4130 - val_loss: 0.4260\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4123 - val_loss: 0.4252\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4109 - val_loss: 0.4238\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4102 - val_loss: 0.4235\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4087 - val_loss: 0.4227\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4077 - val_loss: 0.4224\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4071 - val_loss: 0.4209\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4065 - val_loss: 0.4205\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4051 - val_loss: 0.4193\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4041 - val_loss: 0.4185\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4034 - val_loss: 0.4185\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4023 - val_loss: 0.4172\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4016 - val_loss: 0.4159\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4007 - val_loss: 0.4163\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3997 - val_loss: 0.4153\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3993 - val_loss: 0.4143\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3985 - val_loss: 0.4133\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3977 - val_loss: 0.4129\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3970 - val_loss: 0.4119\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3960 - val_loss: 0.4116\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3956 - val_loss: 0.4102\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3948 - val_loss: 0.4098\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3940 - val_loss: 0.4089\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3935 - val_loss: 0.4088\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3924 - val_loss: 0.4088\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3921 - val_loss: 0.4082\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3914 - val_loss: 0.4070\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3909 - val_loss: 0.4069\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3897 - val_loss: 0.4055\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3894 - val_loss: 0.4054\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3884 - val_loss: 0.4044\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3881 - val_loss: 0.4040\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3869 - val_loss: 0.4032\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3865 - val_loss: 0.4035\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3857 - val_loss: 0.4033\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3853 - val_loss: 0.4021\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3846 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3838 - val_loss: 0.4007\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3835 - val_loss: 0.4001\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3829 - val_loss: 0.4000\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3822 - val_loss: 0.3998\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3816 - val_loss: 0.3994\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3811 - val_loss: 0.3988\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3805 - val_loss: 0.3983\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3800 - val_loss: 0.3981\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3792 - val_loss: 0.3971\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3789 - val_loss: 0.3978\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3781 - val_loss: 0.3975\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3778 - val_loss: 0.3960\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3773 - val_loss: 0.3960\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3765 - val_loss: 0.3959\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3759 - val_loss: 0.3954\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3754 - val_loss: 0.3953\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3750 - val_loss: 0.3942\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3745 - val_loss: 0.3939\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3740 - val_loss: 0.3933\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.3970\n",
      "[CV]  learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30, total=  51.4s\n",
      "[CV] learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 2.0279 - val_loss: 0.8632\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.7961 - val_loss: 0.7166\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.6929 - val_loss: 0.6663\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6557 - val_loss: 0.6380\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6206 - val_loss: 0.6054\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5966 - val_loss: 0.5841\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5729 - val_loss: 0.5611\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5540 - val_loss: 0.5450\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5389 - val_loss: 0.5286\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5241 - val_loss: 0.5171\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5123 - val_loss: 0.5059\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5030 - val_loss: 0.4975\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4950 - val_loss: 0.4902\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4884 - val_loss: 0.4844\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4828 - val_loss: 0.4790\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4787 - val_loss: 0.4746\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4749 - val_loss: 0.4705\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4700 - val_loss: 0.4677\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4668 - val_loss: 0.4648\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4645 - val_loss: 0.4627\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4626 - val_loss: 0.4599\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4588 - val_loss: 0.4581\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4574 - val_loss: 0.4565\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4557 - val_loss: 0.4537\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4535 - val_loss: 0.4530\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4519 - val_loss: 0.4517\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4500 - val_loss: 0.4500\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4485 - val_loss: 0.4484\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4479 - val_loss: 0.4477\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4461 - val_loss: 0.4465\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4454 - val_loss: 0.4460\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4444 - val_loss: 0.4438\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4419 - val_loss: 0.4426\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4410 - val_loss: 0.4417\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4399 - val_loss: 0.4405\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4381 - val_loss: 0.4407\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4377 - val_loss: 0.4388\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4361 - val_loss: 0.4377\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4355 - val_loss: 0.4384\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4341 - val_loss: 0.4382\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4366 - val_loss: 0.4355\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4320 - val_loss: 0.4356\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4321 - val_loss: 0.4345\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4310 - val_loss: 0.4331\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4304 - val_loss: 0.4336\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4298 - val_loss: 0.4316\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4312 - val_loss: 0.4301\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4265 - val_loss: 0.4295\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4268 - val_loss: 0.4302\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4262 - val_loss: 0.4278\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4244 - val_loss: 0.4277\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4241 - val_loss: 0.4269\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4240 - val_loss: 0.4266\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4226 - val_loss: 0.4247\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4210 - val_loss: 0.4242\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4201 - val_loss: 0.4231\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4199 - val_loss: 0.4232\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4190 - val_loss: 0.4220\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4177 - val_loss: 0.4215\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4175 - val_loss: 0.4210\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4165 - val_loss: 0.4197\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4158 - val_loss: 0.4197\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4149 - val_loss: 0.4187\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4146 - val_loss: 0.4186\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4136 - val_loss: 0.4177\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4128 - val_loss: 0.4173\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4124 - val_loss: 0.4166\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4116 - val_loss: 0.4153\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4112 - val_loss: 0.4145\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4104 - val_loss: 0.4141\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4097 - val_loss: 0.4137\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4093 - val_loss: 0.4137\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4084 - val_loss: 0.4127\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4081 - val_loss: 0.4125\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4074 - val_loss: 0.4117\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4066 - val_loss: 0.4113\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4061 - val_loss: 0.4104\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4059 - val_loss: 0.4105\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4049 - val_loss: 0.4096\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4045 - val_loss: 0.4092\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4035 - val_loss: 0.4084\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4031 - val_loss: 0.4087\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4026 - val_loss: 0.4072\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4022 - val_loss: 0.4069\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4013 - val_loss: 0.4075\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4010 - val_loss: 0.4064\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4009 - val_loss: 0.4056\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3995 - val_loss: 0.4054\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3989 - val_loss: 0.4052\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3986 - val_loss: 0.4047\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3982 - val_loss: 0.4041\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3975 - val_loss: 0.4027\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3970 - val_loss: 0.4031\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3967 - val_loss: 0.4028\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3959 - val_loss: 0.4022\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3952 - val_loss: 0.4023\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3945 - val_loss: 0.4005\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3946 - val_loss: 0.3998\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3934 - val_loss: 0.3994\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3931 - val_loss: 0.3999\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.3899\n",
      "[CV]  learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30, total=  52.9s\n",
      "[CV] learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 2.3526 - val_loss: 1.0804\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.8406 - val_loss: 0.7657\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7048 - val_loss: 0.6806\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6519 - val_loss: 0.6348\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6179 - val_loss: 0.6038\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5922 - val_loss: 0.5799\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5715 - val_loss: 0.5619\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.5548 - val_loss: 0.5463\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5405 - val_loss: 0.5344\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5286 - val_loss: 0.5238\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5186 - val_loss: 0.5150\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5100 - val_loss: 0.5081\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5033 - val_loss: 0.5023\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4975 - val_loss: 0.4983\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4929 - val_loss: 0.4933\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4889 - val_loss: 0.4899\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4853 - val_loss: 0.4868\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4818 - val_loss: 0.4840\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4788 - val_loss: 0.4814\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4761 - val_loss: 0.4786\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4737 - val_loss: 0.4765\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4711 - val_loss: 0.4746\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4690 - val_loss: 0.4723\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4668 - val_loss: 0.4702\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4646 - val_loss: 0.4683\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4630 - val_loss: 0.4665\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4610 - val_loss: 0.4652\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4594 - val_loss: 0.4633\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4581 - val_loss: 0.4619\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4563 - val_loss: 0.4604\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4550 - val_loss: 0.4588\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4534 - val_loss: 0.4577\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4521 - val_loss: 0.4562\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4503 - val_loss: 0.4558\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4491 - val_loss: 0.4542\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4478 - val_loss: 0.4524\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4464 - val_loss: 0.4516\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4451 - val_loss: 0.4502\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4439 - val_loss: 0.4488\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4426 - val_loss: 0.4474\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4413 - val_loss: 0.4464\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4400 - val_loss: 0.4451\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4387 - val_loss: 0.4439\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4373 - val_loss: 0.4426\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4359 - val_loss: 0.4412\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4348 - val_loss: 0.4403\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4331 - val_loss: 0.4395\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4324 - val_loss: 0.4383\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4312 - val_loss: 0.4373\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4300 - val_loss: 0.4366\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4292 - val_loss: 0.4352\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4280 - val_loss: 0.4342\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4269 - val_loss: 0.4339\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4261 - val_loss: 0.4329\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4252 - val_loss: 0.4319\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4244 - val_loss: 0.4307\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4234 - val_loss: 0.4303\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4224 - val_loss: 0.4296\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4214 - val_loss: 0.4288\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4206 - val_loss: 0.4278\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4197 - val_loss: 0.4274\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4187 - val_loss: 0.4266\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4180 - val_loss: 0.4254\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4173 - val_loss: 0.4248\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4162 - val_loss: 0.4244\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4156 - val_loss: 0.4233\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4147 - val_loss: 0.4226\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4137 - val_loss: 0.4226\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4130 - val_loss: 0.4214\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4121 - val_loss: 0.4210\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4115 - val_loss: 0.4201\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4106 - val_loss: 0.4195\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4099 - val_loss: 0.4188\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4088 - val_loss: 0.4181\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4083 - val_loss: 0.4173\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4076 - val_loss: 0.4166\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4068 - val_loss: 0.4160\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4057 - val_loss: 0.4158\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4051 - val_loss: 0.4150\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4044 - val_loss: 0.4144\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4036 - val_loss: 0.4136\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4031 - val_loss: 0.4130\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4023 - val_loss: 0.4129\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4017 - val_loss: 0.4123\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4008 - val_loss: 0.4116\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4002 - val_loss: 0.4115\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3996 - val_loss: 0.4108\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3989 - val_loss: 0.4102\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3983 - val_loss: 0.4098\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3974 - val_loss: 0.4090\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3970 - val_loss: 0.4083\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3961 - val_loss: 0.4081\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3956 - val_loss: 0.4076\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3948 - val_loss: 0.4077\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3946 - val_loss: 0.4065\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3937 - val_loss: 0.4061\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3933 - val_loss: 0.4056\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3922 - val_loss: 0.4058\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3922 - val_loss: 0.4047\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3914 - val_loss: 0.4043\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.4029\n",
      "[CV]  learning_rate=0.001784602125046856, n_hidden=1, n_neurons=30, total=  49.9s\n",
      "[CV] learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 107us/sample - loss: 3.6569 - val_loss: 2.2630\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.9186 - val_loss: 1.4997\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.4955 - val_loss: 1.3176\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3921 - val_loss: 1.2760\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3665 - val_loss: 1.2667\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.3604 - val_loss: 1.2653\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 1.3589 - val_loss: 1.2653\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 1.3585 - val_loss: 1.2654\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3585 - val_loss: 1.2655\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3584 - val_loss: 1.2655\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3584 - val_loss: 1.2656\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 1.3584 - val_loss: 1.2657\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3584 - val_loss: 1.2657\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3584 - val_loss: 1.2657\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 1.3584 - val_loss: 1.2657\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3584 - val_loss: 1.2657\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.3584 - val_loss: 1.2656\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 1.3082\n",
      "[CV]  learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2, total=  10.0s\n",
      "[CV] learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 3.6588 - val_loss: 2.2532\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.9001 - val_loss: 1.4881\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.4734 - val_loss: 1.3118\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3712 - val_loss: 1.2741\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.3466 - val_loss: 1.2662\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3403 - val_loss: 1.2652\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3388 - val_loss: 1.2655\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.3384 - val_loss: 1.2658\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3383 - val_loss: 1.2659\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3383 - val_loss: 1.2661\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.3383 - val_loss: 1.2662\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.3383 - val_loss: 1.2663\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3383 - val_loss: 1.2662\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.3383 - val_loss: 1.2660\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.3383 - val_loss: 1.2662\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.3383 - val_loss: 1.2662\n",
      "3870/3870 [==============================] - 0s 32us/sample - loss: 1.3486\n",
      "[CV]  learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2, total=   9.4s\n",
      "[CV] learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 2.4715 - val_loss: 1.2966\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.3238 - val_loss: 1.2444\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 1.2908 - val_loss: 1.2170\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 1.2309 - val_loss: 1.1353\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.0828 - val_loss: 0.9694\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.8861 - val_loss: 0.8314\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.7858 - val_loss: 0.7749\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.7489 - val_loss: 0.7422\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.7256 - val_loss: 0.7193\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.7084 - val_loss: 0.7009\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.6925 - val_loss: 0.6852\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6796 - val_loss: 0.6707\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6650 - val_loss: 0.6575\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.6527 - val_loss: 0.6444\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.6403 - val_loss: 0.6315\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.6275 - val_loss: 0.6183\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6144 - val_loss: 0.6051\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6009 - val_loss: 0.5920\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5881 - val_loss: 0.5792\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.5753 - val_loss: 0.5664\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.5625 - val_loss: 0.5541\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5494 - val_loss: 0.5428\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5388 - val_loss: 0.5336\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5285 - val_loss: 0.5264\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5208 - val_loss: 0.5199\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.5142 - val_loss: 0.5148\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5085 - val_loss: 0.5109\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5040 - val_loss: 0.5083\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5007 - val_loss: 0.5039\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4976 - val_loss: 0.5019\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4949 - val_loss: 0.4990\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4924 - val_loss: 0.4966\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4899 - val_loss: 0.4956\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4883 - val_loss: 0.4932\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4867 - val_loss: 0.4912\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4846 - val_loss: 0.4902\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.4833 - val_loss: 0.4887\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4818 - val_loss: 0.4880\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4803 - val_loss: 0.4861\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.4783 - val_loss: 0.4861\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4778 - val_loss: 0.4828\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4764 - val_loss: 0.4815\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4749 - val_loss: 0.4801\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4735 - val_loss: 0.4793\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4724 - val_loss: 0.4782\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4717 - val_loss: 0.4765\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4704 - val_loss: 0.4749\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4692 - val_loss: 0.4740\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4678 - val_loss: 0.4731\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4671 - val_loss: 0.4718\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.4658 - val_loss: 0.4706\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4652 - val_loss: 0.4696\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4639 - val_loss: 0.4695\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4626 - val_loss: 0.4691\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.4623 - val_loss: 0.4670\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4614 - val_loss: 0.4668\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4606 - val_loss: 0.4654\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4594 - val_loss: 0.4640\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4586 - val_loss: 0.4623\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4574 - val_loss: 0.4631\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4569 - val_loss: 0.4610\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4558 - val_loss: 0.4605\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4548 - val_loss: 0.4608\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4541 - val_loss: 0.4579\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4528 - val_loss: 0.4570\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4522 - val_loss: 0.4559\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4510 - val_loss: 0.4555\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4504 - val_loss: 0.4546\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4495 - val_loss: 0.4556\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4485 - val_loss: 0.4530\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4479 - val_loss: 0.4518\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4471 - val_loss: 0.4507\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4459 - val_loss: 0.4503\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4452 - val_loss: 0.4497\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4445 - val_loss: 0.4481\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4435 - val_loss: 0.4481\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4424 - val_loss: 0.4465\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4420 - val_loss: 0.4467\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4408 - val_loss: 0.4479\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4400 - val_loss: 0.4463\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4403 - val_loss: 0.4439\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4393 - val_loss: 0.4438\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4384 - val_loss: 0.4423\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4380 - val_loss: 0.4418\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4366 - val_loss: 0.4413\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4361 - val_loss: 0.4418\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4357 - val_loss: 0.4400\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4346 - val_loss: 0.4410\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4346 - val_loss: 0.4388\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.4337 - val_loss: 0.4387\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4336 - val_loss: 0.4380\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4324 - val_loss: 0.4368\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4321 - val_loss: 0.4373\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4317 - val_loss: 0.4362\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4312 - val_loss: 0.4349\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4305 - val_loss: 0.4349\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4297 - val_loss: 0.4353\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4297 - val_loss: 0.4330\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4290 - val_loss: 0.4350\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4281 - val_loss: 0.4342\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4228\n",
      "[CV]  learning_rate=0.0014614453041823787, n_hidden=3, n_neurons=2, total=  56.9s\n",
      "[CV] learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 1.5083 - val_loss: 1.1312\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 1.8380 - val_loss: 3.3970\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: nan - val_loss: nan\n",
      "3870/3870 [==============================] - 0s 28us/sample - loss: nan\n",
      "[CV]  learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4, total=   5.9s\n",
      "[CV] learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 1.1760 - val_loss: 1.4854\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.3543 - val_loss: 0.6548\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6155 - val_loss: 0.5568\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5366 - val_loss: 0.5430\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5154 - val_loss: 0.5164\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5001 - val_loss: 0.5099\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4927 - val_loss: 0.4963\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4862 - val_loss: 0.4999\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4775 - val_loss: 0.4708\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4653 - val_loss: 0.4666\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4630 - val_loss: 0.4640\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4591 - val_loss: 0.4622\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4576 - val_loss: 0.4602\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4539 - val_loss: 0.4552\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4514 - val_loss: 0.4571\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4475 - val_loss: 0.4502\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4442 - val_loss: 0.4512\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4406 - val_loss: 0.4428\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4373 - val_loss: 0.4445\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4338 - val_loss: 0.4364\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4305 - val_loss: 0.4358\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4275 - val_loss: 0.4369\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4232 - val_loss: 0.4334\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4233 - val_loss: 0.4257\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4193 - val_loss: 0.4219\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4164 - val_loss: 0.4237\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4143 - val_loss: 0.4286\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4128 - val_loss: 0.4189\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4112 - val_loss: 0.4229\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4099 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4094 - val_loss: 0.4134\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4070 - val_loss: 0.4078\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4061 - val_loss: 0.4093\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4032 - val_loss: 0.4133\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4023 - val_loss: 0.4074\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4013 - val_loss: 0.4151\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4012 - val_loss: 0.4217\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3998 - val_loss: 0.4133\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4000 - val_loss: 0.4089\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3976 - val_loss: 0.4086\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3972 - val_loss: 0.4083\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3970 - val_loss: 0.4050\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3968 - val_loss: 0.4015\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3957 - val_loss: 0.4045\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3956 - val_loss: 0.4066\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3954 - val_loss: 0.4005\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3950 - val_loss: 0.3968\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3939 - val_loss: 0.4035\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3932 - val_loss: 0.3942\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3927 - val_loss: 0.3973\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3937 - val_loss: 0.3933\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3921 - val_loss: 0.3928\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3935 - val_loss: 0.3929\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3913 - val_loss: 0.3953\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3900 - val_loss: 0.3980\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3904 - val_loss: 0.3963\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3904 - val_loss: 0.3901\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3898 - val_loss: 0.3906\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3887 - val_loss: 0.3959\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3880 - val_loss: 0.3929\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3870 - val_loss: 0.4077\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3886 - val_loss: 0.3885\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3887 - val_loss: 0.3874\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3854 - val_loss: 0.3994\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3861 - val_loss: 0.3915\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3874 - val_loss: 0.3879\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3849 - val_loss: 0.3842\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3854 - val_loss: 0.3919\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3847 - val_loss: 0.3979\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3856 - val_loss: 0.3948\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3847 - val_loss: 0.3920\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3843 - val_loss: 0.3897\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3839 - val_loss: 0.3928\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3834 - val_loss: 0.3915\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3848 - val_loss: 0.3964\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3844 - val_loss: 0.3891\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3828 - val_loss: 0.4031\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.3830\n",
      "[CV]  learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4, total=  39.5s\n",
      "[CV] learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 1.1120 - val_loss: 0.6422\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5602 - val_loss: 0.5211\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4970 - val_loss: 0.4867\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4761 - val_loss: 0.4704\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4623 - val_loss: 0.4597\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4523 - val_loss: 0.4611\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4469 - val_loss: 0.4528\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4421 - val_loss: 0.4444\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4391 - val_loss: 0.4544\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4359 - val_loss: 0.4620\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4329 - val_loss: 0.4393\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4313 - val_loss: 0.4287\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4270 - val_loss: 0.4290\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4253 - val_loss: 0.4278\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4244 - val_loss: 0.4232\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4221 - val_loss: 0.4192\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4200 - val_loss: 0.4334\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4159 - val_loss: 0.4161\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4130 - val_loss: 0.4164\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4129 - val_loss: 0.4164\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4117 - val_loss: 0.4143\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4114 - val_loss: 0.4089\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4084 - val_loss: 0.4125\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4049 - val_loss: 0.4060\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4063 - val_loss: 0.4078\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4045 - val_loss: 0.4281\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4042 - val_loss: 0.4133\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4031 - val_loss: 0.4249\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4020 - val_loss: 0.4076\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4013 - val_loss: 0.4084\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4016 - val_loss: 0.4778\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4068 - val_loss: 0.4050\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3993 - val_loss: 0.4020\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3968 - val_loss: 0.4032\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3999 - val_loss: 0.4042\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3937 - val_loss: 0.4080\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3948 - val_loss: 0.4196\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3961 - val_loss: 0.4025\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3927 - val_loss: 0.3951\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3923 - val_loss: 0.3966\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3939 - val_loss: 0.3930\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3914 - val_loss: 0.3970\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3912 - val_loss: 0.3965\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3877 - val_loss: 0.3928\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3882 - val_loss: 0.4064\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3887 - val_loss: 0.4005\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3891 - val_loss: 0.3965\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3876 - val_loss: 0.3962\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3864 - val_loss: 0.3914\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3875 - val_loss: 0.4019\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3865 - val_loss: 0.3955\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3866 - val_loss: 0.3974\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3873 - val_loss: 0.4041\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3859 - val_loss: 0.3915\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3862 - val_loss: 0.3909\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3869 - val_loss: 0.3897\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3868 - val_loss: 0.4048\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3866 - val_loss: 0.3933\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3864 - val_loss: 0.3950\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3855 - val_loss: 0.3906\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3863 - val_loss: 0.3923\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3837 - val_loss: 0.3887\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3848 - val_loss: 0.3929\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3853 - val_loss: 0.3896\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3851 - val_loss: 0.3869\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3834 - val_loss: 0.3884\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3857 - val_loss: 0.3913\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3850 - val_loss: 0.3937\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3845 - val_loss: 0.3860\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3839 - val_loss: 0.3990\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3844 - val_loss: 0.3856\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3842 - val_loss: 0.3921\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3830 - val_loss: 0.3906\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3849 - val_loss: 0.3911\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3835 - val_loss: 0.3845\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3835 - val_loss: 0.3864\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3845 - val_loss: 0.3878\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3831 - val_loss: 0.3840\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3828 - val_loss: 0.3883\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3836 - val_loss: 0.3855\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3830 - val_loss: 0.3975\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3843 - val_loss: 0.3892\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3840 - val_loss: 0.3892\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3842 - val_loss: 0.3882\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3838 - val_loss: 0.3928\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3823 - val_loss: 0.3846\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3815 - val_loss: 0.3864\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3827 - val_loss: 0.3955\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3890\n",
      "[CV]  learning_rate=0.013205529067164243, n_hidden=1, n_neurons=4, total=  44.7s\n",
      "[CV] learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 1.6824 - val_loss: 0.7988\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.8364 - val_loss: 0.7131\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.6921 - val_loss: 0.6433\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6182 - val_loss: 0.5945\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5705 - val_loss: 0.5514\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5295 - val_loss: 0.5186\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4985 - val_loss: 0.4935\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4757 - val_loss: 0.4725\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4606 - val_loss: 0.4636\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4488 - val_loss: 0.4515\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4390 - val_loss: 0.4405\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4311 - val_loss: 0.4361\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4252 - val_loss: 0.4274\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4186 - val_loss: 0.4226\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4133 - val_loss: 0.4200\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4080 - val_loss: 0.4131\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4046 - val_loss: 0.4130\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4003 - val_loss: 0.4133\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3961 - val_loss: 0.4054\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3938 - val_loss: 0.3994\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3901 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3882 - val_loss: 0.3965\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3850 - val_loss: 0.3937\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3814 - val_loss: 0.3908\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3795 - val_loss: 0.3885\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3773 - val_loss: 0.3893\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3752 - val_loss: 0.3840\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3729 - val_loss: 0.3844\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3714 - val_loss: 0.3860\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3685 - val_loss: 0.3795\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3670 - val_loss: 0.3770\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3633 - val_loss: 0.3770\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3627 - val_loss: 0.3757\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3602 - val_loss: 0.3731\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3593 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3583 - val_loss: 0.3713\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3551 - val_loss: 0.3757\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3534 - val_loss: 0.3780\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3535 - val_loss: 0.3744\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3511 - val_loss: 0.3673\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3508 - val_loss: 0.3630\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3500 - val_loss: 0.3674\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3471 - val_loss: 0.3620\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3465 - val_loss: 0.3710\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3458 - val_loss: 0.3624\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3436 - val_loss: 0.3593\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3434 - val_loss: 0.3590\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3430 - val_loss: 0.3561\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3419 - val_loss: 0.3538\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3404 - val_loss: 0.3573\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3390 - val_loss: 0.3504\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3383 - val_loss: 0.3541\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3373 - val_loss: 0.3540\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3370 - val_loss: 0.3474\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3347 - val_loss: 0.3575\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3345 - val_loss: 0.3524\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3325 - val_loss: 0.3526\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3335 - val_loss: 0.3519\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3322 - val_loss: 0.3525\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3299 - val_loss: 0.3479\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3294 - val_loss: 0.3476\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3293 - val_loss: 0.3447\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3283 - val_loss: 0.3463\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3285 - val_loss: 0.3432\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3284 - val_loss: 0.3461\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3284 - val_loss: 0.3419\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3295 - val_loss: 0.3466\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3304 - val_loss: 0.3404\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3318 - val_loss: 0.3399\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3255 - val_loss: 0.3372\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3228 - val_loss: 0.3376\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3220 - val_loss: 0.3400\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3209 - val_loss: 0.3414\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3201 - val_loss: 0.3315\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3195 - val_loss: 0.3324\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3195 - val_loss: 0.3364\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3195 - val_loss: 0.3318\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3175 - val_loss: 0.3324\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3178 - val_loss: 0.3357\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3160 - val_loss: 0.3378\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3160 - val_loss: 0.3328\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3151 - val_loss: 0.3294\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3148 - val_loss: 0.3326\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3135 - val_loss: 0.3336\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3137 - val_loss: 0.3323\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3128 - val_loss: 0.3367\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3139 - val_loss: 0.3262\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3125 - val_loss: 0.3297\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3117 - val_loss: 0.3334\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3111 - val_loss: 0.3283\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3107 - val_loss: 0.3246\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3096 - val_loss: 0.3258\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3084 - val_loss: 0.3275\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3096 - val_loss: 0.3248\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3076 - val_loss: 0.3282\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3068 - val_loss: 0.3231\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3086 - val_loss: 0.3298\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3078 - val_loss: 0.3309\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3068 - val_loss: 0.3178\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3058 - val_loss: 0.3208\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.3294\n",
      "[CV]  learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16, total=  54.1s\n",
      "[CV] learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 102us/sample - loss: 2.6281 - val_loss: 0.7519\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6956 - val_loss: 0.7237\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.6083 - val_loss: 0.5703\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5739 - val_loss: 0.5363\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5113 - val_loss: 0.4911\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4723 - val_loss: 0.4644\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4489 - val_loss: 0.4465\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4326 - val_loss: 0.4337\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4214 - val_loss: 0.4263\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4126 - val_loss: 0.4166\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4059 - val_loss: 0.4122\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3998 - val_loss: 0.4056\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3946 - val_loss: 0.4017\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3902 - val_loss: 0.3977\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3860 - val_loss: 0.3981\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3823 - val_loss: 0.3974\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3810 - val_loss: 0.3896\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3773 - val_loss: 0.3943\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3750 - val_loss: 0.3848\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3742 - val_loss: 0.3854\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3713 - val_loss: 0.3829\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3702 - val_loss: 0.3846\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3681 - val_loss: 0.3785\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3672 - val_loss: 0.3760\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3645 - val_loss: 0.3777\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3632 - val_loss: 0.3770\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3621 - val_loss: 0.3731\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3607 - val_loss: 0.3740\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3593 - val_loss: 0.3724\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3591 - val_loss: 0.3673\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3572 - val_loss: 0.3698\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3563 - val_loss: 0.3665\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3559 - val_loss: 0.3652\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3539 - val_loss: 0.3671\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3536 - val_loss: 0.3650\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3526 - val_loss: 0.3627\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3523 - val_loss: 0.3620\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3512 - val_loss: 0.3616\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3501 - val_loss: 0.3638\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3498 - val_loss: 0.3621\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3487 - val_loss: 0.3602\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3483 - val_loss: 0.3639\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3475 - val_loss: 0.3586\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3460 - val_loss: 0.3674\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3466 - val_loss: 0.3600\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3457 - val_loss: 0.3554\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3449 - val_loss: 0.3567\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3447 - val_loss: 0.3551\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3440 - val_loss: 0.3571\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3435 - val_loss: 0.3573\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3427 - val_loss: 0.3533\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3416 - val_loss: 0.3561\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3407 - val_loss: 0.3559\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3415 - val_loss: 0.3518\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3407 - val_loss: 0.3516\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3384 - val_loss: 0.3503\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3379 - val_loss: 0.3534\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3381 - val_loss: 0.3493\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3378 - val_loss: 0.3508\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3372 - val_loss: 0.3530\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3367 - val_loss: 0.3528\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3364 - val_loss: 0.3484\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3356 - val_loss: 0.3469\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3348 - val_loss: 0.3463\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3341 - val_loss: 0.3455\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3330 - val_loss: 0.3488\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3322 - val_loss: 0.3458\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3321 - val_loss: 0.3452\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3312 - val_loss: 0.3467\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3309 - val_loss: 0.3466\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3309 - val_loss: 0.3449\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3296 - val_loss: 0.3466\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3293 - val_loss: 0.3440\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3283 - val_loss: 0.3443\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3285 - val_loss: 0.3385\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3277 - val_loss: 0.3427\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3271 - val_loss: 0.3379\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3258 - val_loss: 0.3384\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3261 - val_loss: 0.3385\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3249 - val_loss: 0.3424\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3244 - val_loss: 0.3339\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3240 - val_loss: 0.3342\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3228 - val_loss: 0.3348\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3225 - val_loss: 0.3353\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3220 - val_loss: 0.3347\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3210 - val_loss: 0.3377\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3211 - val_loss: 0.3328\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3197 - val_loss: 0.3323\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3187 - val_loss: 0.3374\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3181 - val_loss: 0.3338\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3170 - val_loss: 0.3316\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3172 - val_loss: 0.3277\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3163 - val_loss: 0.3282\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3150 - val_loss: 0.3304\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3149 - val_loss: 0.3250\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3132 - val_loss: 0.3309\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3135 - val_loss: 0.3258\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3120 - val_loss: 0.3282\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3121 - val_loss: 0.3263\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3114 - val_loss: 0.3227\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.3033\n",
      "[CV]  learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16, total=  54.9s\n",
      "[CV] learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 1.1086 - val_loss: 0.6333\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5796 - val_loss: 0.5425\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5170 - val_loss: 0.5018\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4854 - val_loss: 0.4756\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4641 - val_loss: 0.4634\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4505 - val_loss: 0.4539\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4411 - val_loss: 0.4451\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4342 - val_loss: 0.4417\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4277 - val_loss: 0.4370\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4230 - val_loss: 0.4326\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4193 - val_loss: 0.4277\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4151 - val_loss: 0.4219\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4108 - val_loss: 0.4224\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4068 - val_loss: 0.4188\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4040 - val_loss: 0.4125\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4002 - val_loss: 0.4162\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3976 - val_loss: 0.4082\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3934 - val_loss: 0.4087\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3927 - val_loss: 0.4000\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3875 - val_loss: 0.4016\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3865 - val_loss: 0.3980\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3839 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3808 - val_loss: 0.3965\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3788 - val_loss: 0.3907\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3756 - val_loss: 0.3922\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3742 - val_loss: 0.3872\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3725 - val_loss: 0.3871\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3710 - val_loss: 0.3884\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3694 - val_loss: 0.3837\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3681 - val_loss: 0.3850\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3660 - val_loss: 0.3838\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3654 - val_loss: 0.3826\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3628 - val_loss: 0.3849\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3632 - val_loss: 0.3802\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3606 - val_loss: 0.3797\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3603 - val_loss: 0.3814\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3582 - val_loss: 0.3813\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3583 - val_loss: 0.3734\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3567 - val_loss: 0.3763\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3556 - val_loss: 0.3759\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3538 - val_loss: 0.3736\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3542 - val_loss: 0.3699\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3534 - val_loss: 0.3769\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3522 - val_loss: 0.3695\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3513 - val_loss: 0.3692\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3503 - val_loss: 0.3687\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3492 - val_loss: 0.3698\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3490 - val_loss: 0.3729\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3489 - val_loss: 0.3674\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3473 - val_loss: 0.3670\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3469 - val_loss: 0.3693\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3473 - val_loss: 0.3674\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3450 - val_loss: 0.3658\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3447 - val_loss: 0.3653\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3457 - val_loss: 0.3731\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3446 - val_loss: 0.3617\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3431 - val_loss: 0.3721\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3438 - val_loss: 0.3675\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3420 - val_loss: 0.3672\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3404 - val_loss: 0.3615\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3405 - val_loss: 0.3632\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3403 - val_loss: 0.3650\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3391 - val_loss: 0.3639\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3394 - val_loss: 0.3659\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3386 - val_loss: 0.3625\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3388 - val_loss: 0.3643\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3381 - val_loss: 0.3623\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3359 - val_loss: 0.3771\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3378 - val_loss: 0.3522\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3367 - val_loss: 0.3892\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3388 - val_loss: 0.3522\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3382 - val_loss: 0.3715\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3360 - val_loss: 0.3530\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3361 - val_loss: 0.3711\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3341 - val_loss: 0.3668\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3344 - val_loss: 0.3629\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3327 - val_loss: 0.3550\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3318 - val_loss: 0.3606\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3316 - val_loss: 0.3511\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3310 - val_loss: 0.3733\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3307 - val_loss: 0.3543\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3289 - val_loss: 0.3538\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3298 - val_loss: 0.3531\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3300 - val_loss: 0.3518\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3293 - val_loss: 0.3589\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3281 - val_loss: 0.3524\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3290 - val_loss: 0.3490\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3273 - val_loss: 0.3516\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3266 - val_loss: 0.3485\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3271 - val_loss: 0.3632\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3253 - val_loss: 0.3507\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3248 - val_loss: 0.3522\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3251 - val_loss: 0.3465\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3253 - val_loss: 0.3493\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3237 - val_loss: 0.3452\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3218 - val_loss: 0.3534\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3232 - val_loss: 0.3464\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3233 - val_loss: 0.3472\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3235 - val_loss: 0.3462\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3222 - val_loss: 0.3499\n",
      "3870/3870 [==============================] - 0s 36us/sample - loss: 0.3657\n",
      "[CV]  learning_rate=0.005498448400786033, n_hidden=2, n_neurons=16, total=  53.7s\n",
      "[CV] learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 1.8123 - val_loss: 0.9856\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.8589 - val_loss: 0.7701\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7439 - val_loss: 0.7101\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6965 - val_loss: 0.6757\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6627 - val_loss: 0.6495\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6344 - val_loss: 0.6263\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6108 - val_loss: 0.6058\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5906 - val_loss: 0.5888\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5736 - val_loss: 0.5740\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5587 - val_loss: 0.5612\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5461 - val_loss: 0.5498\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5348 - val_loss: 0.5400\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5250 - val_loss: 0.5311\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5161 - val_loss: 0.5235\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5084 - val_loss: 0.5163\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5015 - val_loss: 0.5105\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4953 - val_loss: 0.5038\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4899 - val_loss: 0.4991\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4845 - val_loss: 0.4950\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4797 - val_loss: 0.4901\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4757 - val_loss: 0.4850\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4715 - val_loss: 0.4810\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4676 - val_loss: 0.4781\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4643 - val_loss: 0.4749\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4611 - val_loss: 0.4713\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4579 - val_loss: 0.4687\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4553 - val_loss: 0.4660\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4527 - val_loss: 0.4636\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4503 - val_loss: 0.4609\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4476 - val_loss: 0.4589\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4454 - val_loss: 0.4573\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4436 - val_loss: 0.4544\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4413 - val_loss: 0.4529\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4393 - val_loss: 0.4507\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4374 - val_loss: 0.4492\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4354 - val_loss: 0.4478\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4336 - val_loss: 0.4460\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4321 - val_loss: 0.4444\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4306 - val_loss: 0.4430\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4286 - val_loss: 0.4424\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4275 - val_loss: 0.4406\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4260 - val_loss: 0.4394\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4245 - val_loss: 0.4381\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4232 - val_loss: 0.4372\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4222 - val_loss: 0.4361\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4208 - val_loss: 0.4351\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4197 - val_loss: 0.4340\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4186 - val_loss: 0.4326\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4175 - val_loss: 0.4317\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4168 - val_loss: 0.4310\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4156 - val_loss: 0.4301\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4148 - val_loss: 0.4300\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4137 - val_loss: 0.4290\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4128 - val_loss: 0.4288\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4118 - val_loss: 0.4271\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4115 - val_loss: 0.4265\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4106 - val_loss: 0.4262\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4101 - val_loss: 0.4249\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4090 - val_loss: 0.4247\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4083 - val_loss: 0.4237\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4078 - val_loss: 0.4228\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4068 - val_loss: 0.4227\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4064 - val_loss: 0.4221\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4055 - val_loss: 0.4216\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4051 - val_loss: 0.4208\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4042 - val_loss: 0.4194\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4038 - val_loss: 0.4192\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4031 - val_loss: 0.4184\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4024 - val_loss: 0.4185\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4019 - val_loss: 0.4175\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4010 - val_loss: 0.4171\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4005 - val_loss: 0.4162\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4000 - val_loss: 0.4158\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3991 - val_loss: 0.4162\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3991 - val_loss: 0.4151\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3982 - val_loss: 0.4142\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3977 - val_loss: 0.4142\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3972 - val_loss: 0.4136\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3965 - val_loss: 0.4130\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3962 - val_loss: 0.4121\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3955 - val_loss: 0.4122\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3949 - val_loss: 0.4111\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3942 - val_loss: 0.4110\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3938 - val_loss: 0.4103\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3931 - val_loss: 0.4100\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3928 - val_loss: 0.4098\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3923 - val_loss: 0.4091\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3918 - val_loss: 0.4090\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3912 - val_loss: 0.4083\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3907 - val_loss: 0.4085\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3903 - val_loss: 0.4074\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3897 - val_loss: 0.4065\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3890 - val_loss: 0.4077\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3887 - val_loss: 0.4068\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3884 - val_loss: 0.4057\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3878 - val_loss: 0.4053\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3873 - val_loss: 0.4046\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3871 - val_loss: 0.4049\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3866 - val_loss: 0.4043\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3859 - val_loss: 0.4035\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4075\n",
      "[CV]  learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18, total=  50.7s\n",
      "[CV] learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 1.8148 - val_loss: 0.9220\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.8017 - val_loss: 0.7246\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6975 - val_loss: 0.6680\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6496 - val_loss: 0.6324\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6155 - val_loss: 0.6044\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5898 - val_loss: 0.5825\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5689 - val_loss: 0.5650\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5528 - val_loss: 0.5511\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5393 - val_loss: 0.5385\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5277 - val_loss: 0.5288\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5183 - val_loss: 0.5199\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5099 - val_loss: 0.5128\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5031 - val_loss: 0.5052\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4977 - val_loss: 0.5000\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4922 - val_loss: 0.4946\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4883 - val_loss: 0.4901\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4836 - val_loss: 0.4864\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4792 - val_loss: 0.4824\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4760 - val_loss: 0.4784\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4722 - val_loss: 0.4764\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4693 - val_loss: 0.4725\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4671 - val_loss: 0.4703\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4642 - val_loss: 0.4684\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4619 - val_loss: 0.4658\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4627 - val_loss: 0.4645\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4583 - val_loss: 0.4628\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4568 - val_loss: 0.4599\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4544 - val_loss: 0.4586\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4546 - val_loss: 0.4588\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4540 - val_loss: 0.4565\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4541 - val_loss: 0.4577\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4539 - val_loss: 0.4541\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4516 - val_loss: 0.4556\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4504 - val_loss: 0.4503\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4472 - val_loss: 0.4516\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4474 - val_loss: 0.4487\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4450 - val_loss: 0.4470\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4444 - val_loss: 0.4464\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4430 - val_loss: 0.4456\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4430 - val_loss: 0.4458\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4421 - val_loss: 0.4443\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4423 - val_loss: 0.4463\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4426 - val_loss: 0.4423\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4400 - val_loss: 0.4432\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4393 - val_loss: 0.4409\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4395 - val_loss: 0.4432\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4398 - val_loss: 0.4401\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4387 - val_loss: 0.4422\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4387 - val_loss: 0.4387\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4377 - val_loss: 0.4416\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4370 - val_loss: 0.4367\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4339 - val_loss: 0.4381\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4337 - val_loss: 0.4358\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4323 - val_loss: 0.4351\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4320 - val_loss: 0.4341\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4312 - val_loss: 0.4334\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4305 - val_loss: 0.4329\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4298 - val_loss: 0.4335\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4293 - val_loss: 0.4322\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4285 - val_loss: 0.4322\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4278 - val_loss: 0.4320\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4274 - val_loss: 0.4302\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4293 - val_loss: 0.4296\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4250 - val_loss: 0.4289\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4267 - val_loss: 0.4285\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4239 - val_loss: 0.4277\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4251 - val_loss: 0.4275\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4233 - val_loss: 0.4278\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4228 - val_loss: 0.4260\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4227 - val_loss: 0.4254\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4214 - val_loss: 0.4251\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4216 - val_loss: 0.4244\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4206 - val_loss: 0.4246\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4192 - val_loss: 0.4232\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4206 - val_loss: 0.4248\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4200 - val_loss: 0.4226\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4182 - val_loss: 0.4222\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4180 - val_loss: 0.4215\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4173 - val_loss: 0.4219\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4171 - val_loss: 0.4207\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4158 - val_loss: 0.4197\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4167 - val_loss: 0.4195\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4147 - val_loss: 0.4185\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4151 - val_loss: 0.4185\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4139 - val_loss: 0.4177\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4136 - val_loss: 0.4195\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4138 - val_loss: 0.4171\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4116 - val_loss: 0.4170\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4119 - val_loss: 0.4167\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4118 - val_loss: 0.4170\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4112 - val_loss: 0.4156\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4134 - val_loss: 0.4147\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4096 - val_loss: 0.4142\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4097 - val_loss: 0.4151\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4093 - val_loss: 0.4131\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4075 - val_loss: 0.4133\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4084 - val_loss: 0.4121\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4072 - val_loss: 0.4133\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4067 - val_loss: 0.4109\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4067 - val_loss: 0.4127\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3996\n",
      "[CV]  learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18, total=  50.9s\n",
      "[CV] learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 1.6767 - val_loss: 0.8803\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.7969 - val_loss: 0.7625\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7292 - val_loss: 0.7140\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6906 - val_loss: 0.6788\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6603 - val_loss: 0.6498\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6354 - val_loss: 0.6252\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6139 - val_loss: 0.6046\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5952 - val_loss: 0.5858\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5783 - val_loss: 0.5695\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5640 - val_loss: 0.5552\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5504 - val_loss: 0.5425\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5383 - val_loss: 0.5314\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5274 - val_loss: 0.5219\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5176 - val_loss: 0.5139\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5090 - val_loss: 0.5066\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5013 - val_loss: 0.5003\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4946 - val_loss: 0.4945\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4885 - val_loss: 0.4894\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4829 - val_loss: 0.4847\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4778 - val_loss: 0.4801\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4736 - val_loss: 0.4764\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4695 - val_loss: 0.4732\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4657 - val_loss: 0.4708\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4630 - val_loss: 0.4683\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4602 - val_loss: 0.4664\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4573 - val_loss: 0.4650\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4552 - val_loss: 0.4620\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4528 - val_loss: 0.4605\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4507 - val_loss: 0.4591\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4487 - val_loss: 0.4574\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4468 - val_loss: 0.4559\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4447 - val_loss: 0.4544\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4429 - val_loss: 0.4526\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4412 - val_loss: 0.4519\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4396 - val_loss: 0.4511\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4382 - val_loss: 0.4491\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4368 - val_loss: 0.4479\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4351 - val_loss: 0.4463\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4337 - val_loss: 0.4454\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4325 - val_loss: 0.4442\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4310 - val_loss: 0.4433\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4297 - val_loss: 0.4428\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4287 - val_loss: 0.4407\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4274 - val_loss: 0.4397\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4263 - val_loss: 0.4394\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4246 - val_loss: 0.4383\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4241 - val_loss: 0.4371\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4229 - val_loss: 0.4363\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4215 - val_loss: 0.4348\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4207 - val_loss: 0.4343\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4195 - val_loss: 0.4329\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4185 - val_loss: 0.4335\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4177 - val_loss: 0.4313\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4167 - val_loss: 0.4307\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4154 - val_loss: 0.4297\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4146 - val_loss: 0.4287\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4133 - val_loss: 0.4277\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4126 - val_loss: 0.4270\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4117 - val_loss: 0.4258\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4110 - val_loss: 0.4247\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4099 - val_loss: 0.4243\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4091 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4083 - val_loss: 0.4229\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4073 - val_loss: 0.4218\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4065 - val_loss: 0.4209\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4057 - val_loss: 0.4209\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4051 - val_loss: 0.4197\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4040 - val_loss: 0.4197\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4034 - val_loss: 0.4184\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4028 - val_loss: 0.4175\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4019 - val_loss: 0.4167\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4013 - val_loss: 0.4162\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4006 - val_loss: 0.4159\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3999 - val_loss: 0.4149\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3992 - val_loss: 0.4141\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3983 - val_loss: 0.4130\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3980 - val_loss: 0.4126\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3971 - val_loss: 0.4118\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3965 - val_loss: 0.4114\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3959 - val_loss: 0.4117\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3952 - val_loss: 0.4099\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3947 - val_loss: 0.4088\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3940 - val_loss: 0.4093\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3937 - val_loss: 0.4081\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3929 - val_loss: 0.4079\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3920 - val_loss: 0.4071\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3919 - val_loss: 0.4068\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3913 - val_loss: 0.4066\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3907 - val_loss: 0.4057\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3902 - val_loss: 0.4044\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3896 - val_loss: 0.4042\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3891 - val_loss: 0.4045\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3885 - val_loss: 0.4034\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3880 - val_loss: 0.4035\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3876 - val_loss: 0.4025\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3869 - val_loss: 0.4021\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3865 - val_loss: 0.4013\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3859 - val_loss: 0.4007\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3854 - val_loss: 0.4006\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3850 - val_loss: 0.4003\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.4001\n",
      "[CV]  learning_rate=0.0017350102969173717, n_hidden=1, n_neurons=18, total=  51.5s\n",
      "[CV] learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4 ......\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 1.8304 - val_loss: 8.9362\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 21.7914 - val_loss: 291.4289\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 756.4719 - val_loss: 9845.6731\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 25500.2070 - val_loss: 333714.9240\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 871335.7823 - val_loss: 11302815.3165\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 22681560.4912 - val_loss: 389971239.5917\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 948232602.1165 - val_loss: 13015742150.5158\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 26754039938.9023 - val_loss: 443588738674.0424\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 886977688609.3396 - val_loss: 15112342329812.8711\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 35610584195042.3672 - val_loss: 506849201063429.0000\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1078909098741973.8750 - val_loss: 17192049683662256.0000\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 12041951321315576.0000\n",
      "[CV]  learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4, total=   5.7s\n",
      "[CV] learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4 ......\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 1.0987 - val_loss: 0.5668\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5689 - val_loss: 0.5447\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5501 - val_loss: 0.5348\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5334 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5865 - val_loss: 0.5276\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5224 - val_loss: 0.6328\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5811 - val_loss: 0.8421\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 5.2050 - val_loss: 0.7732\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 3.5130 - val_loss: 0.6679\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5925 - val_loss: 0.7979\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6552 - val_loss: 0.9540\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 7.3523 - val_loss: 1.2860\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 5.1421 - val_loss: 0.7501\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6373 - val_loss: 1.0153\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7582 - val_loss: 1.4156\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.4874\n",
      "[CV]  learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4, total=   7.6s\n",
      "[CV] learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4 ......\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 1.0433 - val_loss: 0.5376\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5307 - val_loss: 0.5248\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5191 - val_loss: 0.5220\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5179 - val_loss: 0.5198\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5166 - val_loss: 0.5211\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5158 - val_loss: 0.5208\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5140 - val_loss: 0.5193\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5165 - val_loss: 0.5226\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5160 - val_loss: 0.5282\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5155 - val_loss: 0.5200\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5168 - val_loss: 0.5224\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5163 - val_loss: 0.5214\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5141 - val_loss: 0.5191\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5154 - val_loss: 0.5209\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5167 - val_loss: 0.5219\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5171 - val_loss: 0.5210\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5144 - val_loss: 0.5204\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5161 - val_loss: 0.5201\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5163 - val_loss: 0.5204\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5163 - val_loss: 0.5193\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5143 - val_loss: 0.5193\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5165 - val_loss: 0.5229\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5143 - val_loss: 0.5230\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.5219\n",
      "[CV]  learning_rate=0.01141416132433509, n_hidden=0, n_neurons=4, total=  11.3s\n",
      "[CV] learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 6.8258 - val_loss: 5.4333\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 4.8369 - val_loss: 3.9197\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 3.5093 - val_loss: 2.9041\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 2.6187 - val_loss: 2.2186\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 2.0176 - val_loss: 1.7535\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.6101 - val_loss: 1.4356\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.3320 - val_loss: 1.2170\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.1409 - val_loss: 1.0653\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.0086 - val_loss: 0.9591\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.9161 - val_loss: 0.8839\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8507 - val_loss: 0.8298\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8037 - val_loss: 0.7903\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7693 - val_loss: 0.7607\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7436 - val_loss: 0.7382\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7239 - val_loss: 0.7205\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7084 - val_loss: 0.7063\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6959 - val_loss: 0.6946\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6855 - val_loss: 0.6847\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6766 - val_loss: 0.6760\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6688 - val_loss: 0.6684\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6619 - val_loss: 0.6616\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6556 - val_loss: 0.6553\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6498 - val_loss: 0.6495\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6444 - val_loss: 0.6441\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6394 - val_loss: 0.6390\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6346 - val_loss: 0.6342\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6301 - val_loss: 0.6297\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6258 - val_loss: 0.6254\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6217 - val_loss: 0.6213\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6178 - val_loss: 0.6173\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6140 - val_loss: 0.6135\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6104 - val_loss: 0.6099\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6069 - val_loss: 0.6065\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6035 - val_loss: 0.6031\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6003 - val_loss: 0.5999\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5972 - val_loss: 0.5969\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5942 - val_loss: 0.5939\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5914 - val_loss: 0.5911\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5886 - val_loss: 0.5884\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5859 - val_loss: 0.5857\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5833 - val_loss: 0.5832\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5809 - val_loss: 0.5808\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5785 - val_loss: 0.5785\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5762 - val_loss: 0.5762\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5739 - val_loss: 0.5740\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5718 - val_loss: 0.5720\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5697 - val_loss: 0.5699\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5677 - val_loss: 0.5680\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5658 - val_loss: 0.5662\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5640 - val_loss: 0.5644\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5622 - val_loss: 0.5626\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5605 - val_loss: 0.5610\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5588 - val_loss: 0.5594\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5572 - val_loss: 0.5579\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5557 - val_loss: 0.5564\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5542 - val_loss: 0.5550\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5527 - val_loss: 0.5536\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5514 - val_loss: 0.5523\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5500 - val_loss: 0.5510\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5487 - val_loss: 0.5497\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5475 - val_loss: 0.5486\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5463 - val_loss: 0.5474\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5451 - val_loss: 0.5463\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5440 - val_loss: 0.5453\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5429 - val_loss: 0.5443\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5419 - val_loss: 0.5433\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5409 - val_loss: 0.5424\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5399 - val_loss: 0.5415\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5390 - val_loss: 0.5406\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5381 - val_loss: 0.5397\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5372 - val_loss: 0.5389\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5364 - val_loss: 0.5381\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5356 - val_loss: 0.5374\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5348 - val_loss: 0.5367\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5340 - val_loss: 0.5360\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5333 - val_loss: 0.5353\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5326 - val_loss: 0.5347\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5320 - val_loss: 0.5340\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5313 - val_loss: 0.5334\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5307 - val_loss: 0.5329\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5301 - val_loss: 0.5323\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5295 - val_loss: 0.5318\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5289 - val_loss: 0.5312\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5284 - val_loss: 0.5308\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5278 - val_loss: 0.5303\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5273 - val_loss: 0.5298\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5268 - val_loss: 0.5294\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5263 - val_loss: 0.5290\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5259 - val_loss: 0.5285\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5254 - val_loss: 0.5281\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5250 - val_loss: 0.5278\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5246 - val_loss: 0.5274\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5242 - val_loss: 0.5270\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5238 - val_loss: 0.5267\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5234 - val_loss: 0.5264\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5231 - val_loss: 0.5260\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5227 - val_loss: 0.5257\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5224 - val_loss: 0.5255\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5221 - val_loss: 0.5252\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5218 - val_loss: 0.5249\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.5292\n",
      "[CV]  learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8, total=  47.9s\n",
      "[CV] learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 6.7047 - val_loss: 5.5946\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 4.7885 - val_loss: 4.0344\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 3.4870 - val_loss: 2.9712\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 2.5972 - val_loss: 2.2431\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.9861 - val_loss: 1.7416\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.5647 - val_loss: 1.3950\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.2730 - val_loss: 1.1543\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.0703 - val_loss: 0.9866\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.9288 - val_loss: 0.8689\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8296 - val_loss: 0.7861\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7596 - val_loss: 0.7273\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7098 - val_loss: 0.6851\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6742 - val_loss: 0.6548\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6484 - val_loss: 0.6326\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6295 - val_loss: 0.6162\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6154 - val_loss: 0.6039\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6048 - val_loss: 0.5945\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5967 - val_loss: 0.5872\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5904 - val_loss: 0.5814\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5853 - val_loss: 0.5767\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5811 - val_loss: 0.5729\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5776 - val_loss: 0.5696\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5746 - val_loss: 0.5668\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5719 - val_loss: 0.5643\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5696 - val_loss: 0.5621\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5675 - val_loss: 0.5601\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5655 - val_loss: 0.5583\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5637 - val_loss: 0.5567\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5621 - val_loss: 0.5551\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5605 - val_loss: 0.5537\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5590 - val_loss: 0.5523\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5576 - val_loss: 0.5510\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5562 - val_loss: 0.5498\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5549 - val_loss: 0.5486\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5537 - val_loss: 0.5475\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5525 - val_loss: 0.5465\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5513 - val_loss: 0.5455\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5502 - val_loss: 0.5445\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5492 - val_loss: 0.5436\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5482 - val_loss: 0.5427\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5471 - val_loss: 0.5418\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5462 - val_loss: 0.5410\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5453 - val_loss: 0.5402\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5444 - val_loss: 0.5395\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5435 - val_loss: 0.5387\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5427 - val_loss: 0.5380\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5418 - val_loss: 0.5374\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5411 - val_loss: 0.5367\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5403 - val_loss: 0.5361\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5396 - val_loss: 0.5355\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5388 - val_loss: 0.5349\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5382 - val_loss: 0.5344\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5375 - val_loss: 0.5338\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5369 - val_loss: 0.5333\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5362 - val_loss: 0.5328\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5356 - val_loss: 0.5324\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5350 - val_loss: 0.5319\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5345 - val_loss: 0.5315\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5339 - val_loss: 0.5311\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5334 - val_loss: 0.5307\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5329 - val_loss: 0.5302\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5324 - val_loss: 0.5299\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5319 - val_loss: 0.5295\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5314 - val_loss: 0.5291\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5310 - val_loss: 0.5288\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5305 - val_loss: 0.5285\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5301 - val_loss: 0.5282\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5297 - val_loss: 0.5278\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5293 - val_loss: 0.5276\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5289 - val_loss: 0.5273\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5285 - val_loss: 0.5270\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5282 - val_loss: 0.5267\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5278 - val_loss: 0.5265\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5274 - val_loss: 0.5263\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5271 - val_loss: 0.5260\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5268 - val_loss: 0.5258\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5265 - val_loss: 0.5256\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5262 - val_loss: 0.5254\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5259 - val_loss: 0.5252\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5256 - val_loss: 0.5250\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5253 - val_loss: 0.5248\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5250 - val_loss: 0.5246\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5248 - val_loss: 0.5244\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5245 - val_loss: 0.5243\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5243 - val_loss: 0.5241\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5240 - val_loss: 0.5240\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5238 - val_loss: 0.5239\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5236 - val_loss: 0.5237\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5234 - val_loss: 0.5236\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5232 - val_loss: 0.5234\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5230 - val_loss: 0.5233\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5227 - val_loss: 0.5232\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5226 - val_loss: 0.5231\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5224 - val_loss: 0.5230\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5222 - val_loss: 0.5229\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5220 - val_loss: 0.5228\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5218 - val_loss: 0.5226\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5217 - val_loss: 0.5225\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5215 - val_loss: 0.5224\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5214 - val_loss: 0.5223\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.5153\n",
      "[CV]  learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8, total=  48.0s\n",
      "[CV] learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 5.8907 - val_loss: 4.7211\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 4.0403 - val_loss: 3.3097\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 2.8695 - val_loss: 2.4087\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 2.1146 - val_loss: 1.8225\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.6209 - val_loss: 1.4361\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.2942 - val_loss: 1.1778\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 1.0759 - val_loss: 1.0042\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9291 - val_loss: 0.8857\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8293 - val_loss: 0.8044\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7610 - val_loss: 0.7480\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7139 - val_loss: 0.7084\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6811 - val_loss: 0.6804\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6580 - val_loss: 0.6602\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6415 - val_loss: 0.6453\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6294 - val_loss: 0.6341\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6203 - val_loss: 0.6255\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6134 - val_loss: 0.6187\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6079 - val_loss: 0.6132\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6035 - val_loss: 0.6086\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5998 - val_loss: 0.6047\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5965 - val_loss: 0.6012\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5937 - val_loss: 0.5981\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5911 - val_loss: 0.5953\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5887 - val_loss: 0.5927\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5865 - val_loss: 0.5902\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5844 - val_loss: 0.5879\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5824 - val_loss: 0.5858\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5805 - val_loss: 0.5837\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5787 - val_loss: 0.5818\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5769 - val_loss: 0.5799\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5752 - val_loss: 0.5782\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5736 - val_loss: 0.5764\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5720 - val_loss: 0.5748\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5705 - val_loss: 0.5732\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5690 - val_loss: 0.5717\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5676 - val_loss: 0.5702\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5662 - val_loss: 0.5688\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5648 - val_loss: 0.5675\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5635 - val_loss: 0.5662\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5622 - val_loss: 0.5649\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5610 - val_loss: 0.5636\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5598 - val_loss: 0.5625\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5587 - val_loss: 0.5613\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5575 - val_loss: 0.5602\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5564 - val_loss: 0.5591\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5554 - val_loss: 0.5581\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5543 - val_loss: 0.5571\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5533 - val_loss: 0.5561\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5523 - val_loss: 0.5552\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5514 - val_loss: 0.5542\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5504 - val_loss: 0.5533\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5495 - val_loss: 0.5525\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5487 - val_loss: 0.5517\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5478 - val_loss: 0.5508\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5470 - val_loss: 0.5500\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5461 - val_loss: 0.5493\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5454 - val_loss: 0.5486\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5446 - val_loss: 0.5479\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5438 - val_loss: 0.5471\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5431 - val_loss: 0.5464\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5424 - val_loss: 0.5458\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5417 - val_loss: 0.5451\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5410 - val_loss: 0.5445\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5404 - val_loss: 0.5439\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5397 - val_loss: 0.5433\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5391 - val_loss: 0.5428\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5385 - val_loss: 0.5422\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5379 - val_loss: 0.5417\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5373 - val_loss: 0.5411\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5367 - val_loss: 0.5406\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5362 - val_loss: 0.5401\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5357 - val_loss: 0.5396\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5351 - val_loss: 0.5391\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5346 - val_loss: 0.5387\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5341 - val_loss: 0.5382\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5336 - val_loss: 0.5378\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5331 - val_loss: 0.5374\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5327 - val_loss: 0.5370\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5322 - val_loss: 0.5366\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5318 - val_loss: 0.5362\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5314 - val_loss: 0.5358\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5309 - val_loss: 0.5354\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5305 - val_loss: 0.5351\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5301 - val_loss: 0.5347\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5297 - val_loss: 0.5343\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5293 - val_loss: 0.5340\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5290 - val_loss: 0.5337\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5286 - val_loss: 0.5333\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5282 - val_loss: 0.5330\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5279 - val_loss: 0.5327\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5276 - val_loss: 0.5324\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5272 - val_loss: 0.5321\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5269 - val_loss: 0.5318\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5266 - val_loss: 0.5316\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5262 - val_loss: 0.5313\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5259 - val_loss: 0.5311\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5256 - val_loss: 0.5308\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5253 - val_loss: 0.5305\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5251 - val_loss: 0.5303\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5248 - val_loss: 0.5301\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.5315\n",
      "[CV]  learning_rate=0.00039560079493476777, n_hidden=0, n_neurons=8, total=  48.3s\n",
      "[CV] learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 3.7899 - val_loss: 1.8038\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.3130 - val_loss: 1.0777\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.9166 - val_loss: 0.8640\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7838 - val_loss: 0.7764\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.7239 - val_loss: 0.7307\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6897 - val_loss: 0.7014\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6657 - val_loss: 0.6799\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6473 - val_loss: 0.6626\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6319 - val_loss: 0.6478\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6185 - val_loss: 0.6348\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6067 - val_loss: 0.6231\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5961 - val_loss: 0.6124\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5865 - val_loss: 0.6027\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5777 - val_loss: 0.5937\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5695 - val_loss: 0.5855\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5620 - val_loss: 0.5777\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5551 - val_loss: 0.5706\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5486 - val_loss: 0.5638\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5425 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5368 - val_loss: 0.5517\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5317 - val_loss: 0.5463\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5269 - val_loss: 0.5410\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5224 - val_loss: 0.5364\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5182 - val_loss: 0.5317\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5142 - val_loss: 0.5275\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5104 - val_loss: 0.5234\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5069 - val_loss: 0.5196\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5035 - val_loss: 0.5161\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5004 - val_loss: 0.5126\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4974 - val_loss: 0.5094\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4946 - val_loss: 0.5063\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4920 - val_loss: 0.5036\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4896 - val_loss: 0.5010\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4873 - val_loss: 0.4985\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4851 - val_loss: 0.4962\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4830 - val_loss: 0.4939\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4811 - val_loss: 0.4918\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4792 - val_loss: 0.4898\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4774 - val_loss: 0.4879\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4758 - val_loss: 0.4860\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4741 - val_loss: 0.4842\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4726 - val_loss: 0.4826\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4711 - val_loss: 0.4809\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4696 - val_loss: 0.4794\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4683 - val_loss: 0.4780\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4669 - val_loss: 0.4767\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4657 - val_loss: 0.4754\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4645 - val_loss: 0.4740\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4633 - val_loss: 0.4728\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4622 - val_loss: 0.4715\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4612 - val_loss: 0.4704\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4601 - val_loss: 0.4694\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4590 - val_loss: 0.4683\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4580 - val_loss: 0.4672\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4570 - val_loss: 0.4662\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4561 - val_loss: 0.4652\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4551 - val_loss: 0.4641\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4542 - val_loss: 0.4633\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4533 - val_loss: 0.4624\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4524 - val_loss: 0.4615\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4516 - val_loss: 0.4605\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4507 - val_loss: 0.4597\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4500 - val_loss: 0.4589\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4492 - val_loss: 0.4580\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4484 - val_loss: 0.4572\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4476 - val_loss: 0.4563\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4469 - val_loss: 0.4555\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4462 - val_loss: 0.4548\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4454 - val_loss: 0.4541\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4448 - val_loss: 0.4534\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4440 - val_loss: 0.4526\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4433 - val_loss: 0.4519\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4426 - val_loss: 0.4513\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4421 - val_loss: 0.4507\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4414 - val_loss: 0.4501\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4407 - val_loss: 0.4494\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4401 - val_loss: 0.4487\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4395 - val_loss: 0.4482\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4389 - val_loss: 0.4476\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4382 - val_loss: 0.4469\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4376 - val_loss: 0.4464\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4370 - val_loss: 0.4458\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4364 - val_loss: 0.4454\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4358 - val_loss: 0.4446\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4352 - val_loss: 0.4441\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4345 - val_loss: 0.4435\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4340 - val_loss: 0.4428\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4335 - val_loss: 0.4423\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4328 - val_loss: 0.4419\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4323 - val_loss: 0.4413\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4317 - val_loss: 0.4409\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4311 - val_loss: 0.4404\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4306 - val_loss: 0.4399\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4301 - val_loss: 0.4395\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4294 - val_loss: 0.4391\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4291 - val_loss: 0.4386\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4285 - val_loss: 0.4382\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4280 - val_loss: 0.4377\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4275 - val_loss: 0.4373\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4270 - val_loss: 0.4368\n",
      "3870/3870 [==============================] - 0s 32us/sample - loss: 0.4414\n",
      "[CV]  learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26, total=  51.9s\n",
      "[CV] learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 3.1901 - val_loss: 2.0166\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.3886 - val_loss: 1.1109\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.9320 - val_loss: 0.8213\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7771 - val_loss: 0.7248\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7166 - val_loss: 0.6858\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.6859 - val_loss: 0.6638\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6652 - val_loss: 0.6479\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6488 - val_loss: 0.6340\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6346 - val_loss: 0.6213\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6217 - val_loss: 0.6094\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6097 - val_loss: 0.5986\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5987 - val_loss: 0.5883\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5884 - val_loss: 0.5787\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5789 - val_loss: 0.5693\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5699 - val_loss: 0.5610\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5616 - val_loss: 0.5532\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5538 - val_loss: 0.5459\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5466 - val_loss: 0.5394\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5399 - val_loss: 0.5329\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5337 - val_loss: 0.5271\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5278 - val_loss: 0.5221\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5225 - val_loss: 0.5169\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5176 - val_loss: 0.5122\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5130 - val_loss: 0.5078\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5087 - val_loss: 0.5037\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5048 - val_loss: 0.5000\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5011 - val_loss: 0.4968\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4978 - val_loss: 0.4937\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4947 - val_loss: 0.4910\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4917 - val_loss: 0.4885\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4890 - val_loss: 0.4861\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4865 - val_loss: 0.4835\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4841 - val_loss: 0.4814\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4818 - val_loss: 0.4796\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4797 - val_loss: 0.4774\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4777 - val_loss: 0.4756\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4757 - val_loss: 0.4740\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4739 - val_loss: 0.4727\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4722 - val_loss: 0.4709\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4705 - val_loss: 0.4695\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4689 - val_loss: 0.4682\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4675 - val_loss: 0.4669\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4660 - val_loss: 0.4659\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4646 - val_loss: 0.4644\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4633 - val_loss: 0.4633\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4618 - val_loss: 0.4626\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4608 - val_loss: 0.4614\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4596 - val_loss: 0.4602\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4584 - val_loss: 0.4593\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4574 - val_loss: 0.4581\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4562 - val_loss: 0.4574\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4553 - val_loss: 0.4563\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4542 - val_loss: 0.4554\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4533 - val_loss: 0.4545\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4523 - val_loss: 0.4535\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4514 - val_loss: 0.4526\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4505 - val_loss: 0.4517\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4496 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4485 - val_loss: 0.4501\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4479 - val_loss: 0.4495\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4471 - val_loss: 0.4490\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4463 - val_loss: 0.4478\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4455 - val_loss: 0.4472\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4448 - val_loss: 0.4462\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4440 - val_loss: 0.4456\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4432 - val_loss: 0.4449\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4427 - val_loss: 0.4442\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4418 - val_loss: 0.4438\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4412 - val_loss: 0.4430\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4405 - val_loss: 0.4423\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4399 - val_loss: 0.4417\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4392 - val_loss: 0.4411\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4386 - val_loss: 0.4404\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4380 - val_loss: 0.4398\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4374 - val_loss: 0.4392\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4366 - val_loss: 0.4387\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4362 - val_loss: 0.4380\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4350 - val_loss: 0.4369\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4344 - val_loss: 0.4364\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4338 - val_loss: 0.4359\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4333 - val_loss: 0.4353\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4327 - val_loss: 0.4347\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4321 - val_loss: 0.4344\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4316 - val_loss: 0.4337\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4311 - val_loss: 0.4332\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4306 - val_loss: 0.4327\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4300 - val_loss: 0.4322\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4295 - val_loss: 0.4317\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4291 - val_loss: 0.4312\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4285 - val_loss: 0.4308\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4280 - val_loss: 0.4303\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4276 - val_loss: 0.4300\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4271 - val_loss: 0.4297\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4267 - val_loss: 0.4291\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4262 - val_loss: 0.4285\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4256 - val_loss: 0.4283\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4253 - val_loss: 0.4276\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4248 - val_loss: 0.4273\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4244 - val_loss: 0.4271\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4157\n",
      "[CV]  learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26, total=  51.5s\n",
      "[CV] learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 3.0436 - val_loss: 1.4944\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.0997 - val_loss: 0.9372\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.8185 - val_loss: 0.8022\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7441 - val_loss: 0.7454\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.7087 - val_loss: 0.7092\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6835 - val_loss: 0.6817\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6622 - val_loss: 0.6591\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6439 - val_loss: 0.6400\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6277 - val_loss: 0.6236\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6135 - val_loss: 0.6093\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6007 - val_loss: 0.5969\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5893 - val_loss: 0.5858\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5788 - val_loss: 0.5761\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5692 - val_loss: 0.5674\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5606 - val_loss: 0.5593\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5529 - val_loss: 0.5519\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5456 - val_loss: 0.5451\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5388 - val_loss: 0.5390\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5325 - val_loss: 0.5332\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5267 - val_loss: 0.5277\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5212 - val_loss: 0.5227\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5160 - val_loss: 0.5182\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5110 - val_loss: 0.5142\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5071 - val_loss: 0.5101\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5030 - val_loss: 0.5065\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4993 - val_loss: 0.5031\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4959 - val_loss: 0.5001\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4926 - val_loss: 0.4972\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4898 - val_loss: 0.4948\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4871 - val_loss: 0.4924\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4846 - val_loss: 0.4900\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4824 - val_loss: 0.4880\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4802 - val_loss: 0.4861\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4782 - val_loss: 0.4843\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4763 - val_loss: 0.4827\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4746 - val_loss: 0.4811\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4729 - val_loss: 0.4797\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4714 - val_loss: 0.4783\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4700 - val_loss: 0.4770\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4685 - val_loss: 0.4759\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4674 - val_loss: 0.4746\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4661 - val_loss: 0.4735\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4649 - val_loss: 0.4725\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4638 - val_loss: 0.4715\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4627 - val_loss: 0.4706\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4617 - val_loss: 0.4697\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4607 - val_loss: 0.4687\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4596 - val_loss: 0.4678\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4587 - val_loss: 0.4669\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4577 - val_loss: 0.4662\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4568 - val_loss: 0.4653\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4560 - val_loss: 0.4646\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4551 - val_loss: 0.4636\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4544 - val_loss: 0.4629\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4535 - val_loss: 0.4626\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4529 - val_loss: 0.4616\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4521 - val_loss: 0.4610\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4514 - val_loss: 0.4603\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4507 - val_loss: 0.4598\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4500 - val_loss: 0.4591\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4494 - val_loss: 0.4584\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4487 - val_loss: 0.4577\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4480 - val_loss: 0.4571\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4474 - val_loss: 0.4566\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4468 - val_loss: 0.4562\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4464 - val_loss: 0.4554\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4457 - val_loss: 0.4550\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4451 - val_loss: 0.4544\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4445 - val_loss: 0.4540\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4440 - val_loss: 0.4531\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4434 - val_loss: 0.4528\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4428 - val_loss: 0.4522\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4423 - val_loss: 0.4516\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4418 - val_loss: 0.4510\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4412 - val_loss: 0.4506\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4408 - val_loss: 0.4501\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4403 - val_loss: 0.4495\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4396 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4391 - val_loss: 0.4486\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4387 - val_loss: 0.4483\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4382 - val_loss: 0.4477\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4377 - val_loss: 0.4471\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4371 - val_loss: 0.4470\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4367 - val_loss: 0.4461\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4361 - val_loss: 0.4457\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4356 - val_loss: 0.4452\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4351 - val_loss: 0.4446\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4345 - val_loss: 0.4441\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4340 - val_loss: 0.4439\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4336 - val_loss: 0.4432\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4330 - val_loss: 0.4428\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4325 - val_loss: 0.4421\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4320 - val_loss: 0.4418\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4315 - val_loss: 0.4414\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4310 - val_loss: 0.4407\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4306 - val_loss: 0.4404\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4301 - val_loss: 0.4400\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4296 - val_loss: 0.4396\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4291 - val_loss: 0.4390\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4286 - val_loss: 0.4386\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.4353\n",
      "[CV]  learning_rate=0.000708414703451485, n_hidden=1, n_neurons=26, total=  51.8s\n",
      "[CV] learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 1.3911 - val_loss: 0.6851\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6581 - val_loss: 0.6825\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7760 - val_loss: 0.9942\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.6673 - val_loss: 0.5530\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5214 - val_loss: 0.5133\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4921 - val_loss: 0.4909\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4724 - val_loss: 0.4772\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4590 - val_loss: 0.4640\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4496 - val_loss: 0.4553\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4403 - val_loss: 0.4482\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4328 - val_loss: 0.4397\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4255 - val_loss: 0.4349\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4190 - val_loss: 0.4256\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4134 - val_loss: 0.4230\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4089 - val_loss: 0.4174\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4049 - val_loss: 0.4128\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4010 - val_loss: 0.4085\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3984 - val_loss: 0.4080\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3952 - val_loss: 0.4049\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3921 - val_loss: 0.4037\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3903 - val_loss: 0.4013\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3879 - val_loss: 0.3969\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3850 - val_loss: 0.3943\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3838 - val_loss: 0.3938\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3819 - val_loss: 0.3909\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3791 - val_loss: 0.3942\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3773 - val_loss: 0.3893\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3759 - val_loss: 0.3892\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3751 - val_loss: 0.3873\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3743 - val_loss: 0.3885\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3716 - val_loss: 0.3870\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3716 - val_loss: 0.3867\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3703 - val_loss: 0.3826\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3688 - val_loss: 0.3838\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3682 - val_loss: 0.3808\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3672 - val_loss: 0.3809\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3661 - val_loss: 0.3804\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3657 - val_loss: 0.3785\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3637 - val_loss: 0.3762\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3636 - val_loss: 0.3743\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3622 - val_loss: 0.3764\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3611 - val_loss: 0.3774\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3610 - val_loss: 0.3726\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3591 - val_loss: 0.3724\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3585 - val_loss: 0.3754\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3581 - val_loss: 0.3719\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3568 - val_loss: 0.3713\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3562 - val_loss: 0.3706\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3557 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3552 - val_loss: 0.3700\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3543 - val_loss: 0.3673\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3526 - val_loss: 0.3713\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3524 - val_loss: 0.3656\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3524 - val_loss: 0.3661\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3515 - val_loss: 0.3667\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3506 - val_loss: 0.3655\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3501 - val_loss: 0.3651\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3499 - val_loss: 0.3646\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3502 - val_loss: 0.3628\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3491 - val_loss: 0.3641\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3486 - val_loss: 0.3617\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3475 - val_loss: 0.3633\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3477 - val_loss: 0.3611\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3468 - val_loss: 0.3607\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3471 - val_loss: 0.3614\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3466 - val_loss: 0.3639\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3464 - val_loss: 0.3632\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3457 - val_loss: 0.3622\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3457 - val_loss: 0.3600\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3451 - val_loss: 0.3656\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3457 - val_loss: 0.3598\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3438 - val_loss: 0.3640\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3440 - val_loss: 0.3618\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3441 - val_loss: 0.3570\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3432 - val_loss: 0.3588\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3427 - val_loss: 0.3610\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3430 - val_loss: 0.3585\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3431 - val_loss: 0.3576\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3428 - val_loss: 0.3588\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3422 - val_loss: 0.3555\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3418 - val_loss: 0.3560\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3410 - val_loss: 0.3892\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3417 - val_loss: 0.3702\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3412 - val_loss: 0.3543\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3401 - val_loss: 0.3552\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3399 - val_loss: 0.3589\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3405 - val_loss: 0.3588\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3392 - val_loss: 0.3562\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3380 - val_loss: 0.3604\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3395 - val_loss: 0.3546\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3398 - val_loss: 0.3585\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3375 - val_loss: 0.3537\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3382 - val_loss: 0.3537\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3374 - val_loss: 0.3546\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3375 - val_loss: 0.3545\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3376 - val_loss: 0.3542\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3381 - val_loss: 0.3531\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3389 - val_loss: 0.3606\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3370 - val_loss: 0.3550\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3357 - val_loss: 0.3540\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3577\n",
      "[CV]  learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19, total=  50.5s\n",
      "[CV] learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 1.2172 - val_loss: 0.7315\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6625 - val_loss: 0.6150\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5732 - val_loss: 0.5475\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5320 - val_loss: 0.5246\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5062 - val_loss: 0.5018\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4951 - val_loss: 0.4958\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4815 - val_loss: 0.4854\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4783 - val_loss: 0.4850\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4772 - val_loss: 0.4728\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4657 - val_loss: 0.4679\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4597 - val_loss: 0.4646\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4573 - val_loss: 0.4642\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4524 - val_loss: 0.4587\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4520 - val_loss: 0.4540\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4474 - val_loss: 0.4524\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4437 - val_loss: 0.4489\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4405 - val_loss: 0.4443\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4382 - val_loss: 0.4497\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4383 - val_loss: 0.4403\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4340 - val_loss: 0.4399\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4314 - val_loss: 0.4373\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4304 - val_loss: 0.4333\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4295 - val_loss: 0.4339\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4307 - val_loss: 0.4345\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4241 - val_loss: 0.4301\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4232 - val_loss: 0.4263\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4200 - val_loss: 0.4242\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4183 - val_loss: 0.4218\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4163 - val_loss: 0.4203\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4153 - val_loss: 0.4219\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4136 - val_loss: 0.4203\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4115 - val_loss: 0.4146\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4102 - val_loss: 0.4142\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4115 - val_loss: 0.4164\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4115 - val_loss: 0.4146\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4139 - val_loss: 0.4167\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4104 - val_loss: 0.4175\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4113 - val_loss: 0.4070\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4007 - val_loss: 0.4052\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3984 - val_loss: 0.4038\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3968 - val_loss: 0.4039\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3961 - val_loss: 0.4020\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3946 - val_loss: 0.3998\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3930 - val_loss: 0.3962\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3922 - val_loss: 0.3972\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3910 - val_loss: 0.3956\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3894 - val_loss: 0.3956\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3880 - val_loss: 0.3946\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3876 - val_loss: 0.3941\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3865 - val_loss: 0.3901\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3844 - val_loss: 0.3936\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3844 - val_loss: 0.3893\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3832 - val_loss: 0.3870\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3816 - val_loss: 0.3910\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3816 - val_loss: 0.3851\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3803 - val_loss: 0.3839\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3788 - val_loss: 0.3846\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3782 - val_loss: 0.3819\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3775 - val_loss: 0.3864\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3774 - val_loss: 0.3833\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3766 - val_loss: 0.3824\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3755 - val_loss: 0.3821\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3755 - val_loss: 0.3804\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3746 - val_loss: 0.3791\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3738 - val_loss: 0.3793\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3725 - val_loss: 0.3800\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3723 - val_loss: 0.3761\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3717 - val_loss: 0.3771\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3713 - val_loss: 0.3748\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3700 - val_loss: 0.3773\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3702 - val_loss: 0.3743\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3691 - val_loss: 0.3746\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3682 - val_loss: 0.3758\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3689 - val_loss: 0.3721\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3678 - val_loss: 0.3723\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3676 - val_loss: 0.3715\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3673 - val_loss: 0.3737\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3659 - val_loss: 0.3700\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3654 - val_loss: 0.3726\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3653 - val_loss: 0.3712\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3638 - val_loss: 0.3719\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3640 - val_loss: 0.3698\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3636 - val_loss: 0.3680\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3630 - val_loss: 0.3677\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3629 - val_loss: 0.3661\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3626 - val_loss: 0.3672\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3625 - val_loss: 0.3664\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3615 - val_loss: 0.3674\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3610 - val_loss: 0.3658\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3608 - val_loss: 0.3646\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3605 - val_loss: 0.3660\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3595 - val_loss: 0.3649\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3594 - val_loss: 0.3642\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3590 - val_loss: 0.3650\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3584 - val_loss: 0.3636\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3570 - val_loss: 0.3640\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3583 - val_loss: 0.3625\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3573 - val_loss: 0.3629\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3567 - val_loss: 0.3607\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3564 - val_loss: 0.3622\n",
      "3870/3870 [==============================] - 0s 32us/sample - loss: 0.3492\n",
      "[CV]  learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19, total=  52.1s\n",
      "[CV] learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 1.2160 - val_loss: 0.6649\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.6101 - val_loss: 0.5795\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5511 - val_loss: 0.5348\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5135 - val_loss: 0.5034\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4899 - val_loss: 0.4865\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4739 - val_loss: 0.4750\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4623 - val_loss: 0.4669\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4551 - val_loss: 0.4648\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4499 - val_loss: 0.4575\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4453 - val_loss: 0.4531\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4410 - val_loss: 0.4501\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4382 - val_loss: 0.4464\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4346 - val_loss: 0.4429\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4315 - val_loss: 0.4400\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4291 - val_loss: 0.4374\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4266 - val_loss: 0.4352\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4239 - val_loss: 0.4321\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4217 - val_loss: 0.4308\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4196 - val_loss: 0.4284\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4171 - val_loss: 0.4260\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4152 - val_loss: 0.4262\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4132 - val_loss: 0.4218\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4115 - val_loss: 0.4207\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4093 - val_loss: 0.4207\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4079 - val_loss: 0.4190\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4063 - val_loss: 0.4171\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4039 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4027 - val_loss: 0.4156\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4015 - val_loss: 0.4157\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4001 - val_loss: 0.4132\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3989 - val_loss: 0.4106\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3976 - val_loss: 0.4087\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3959 - val_loss: 0.4094\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3940 - val_loss: 0.4102\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3935 - val_loss: 0.4080\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3917 - val_loss: 0.4064\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3908 - val_loss: 0.4028\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3893 - val_loss: 0.4025\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3881 - val_loss: 0.4014\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3861 - val_loss: 0.4024\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3853 - val_loss: 0.4032\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3842 - val_loss: 0.3988\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3834 - val_loss: 0.3976\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3817 - val_loss: 0.3986\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3807 - val_loss: 0.3998\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3796 - val_loss: 0.3955\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3782 - val_loss: 0.3934\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3771 - val_loss: 0.3930\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3766 - val_loss: 0.3947\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3747 - val_loss: 0.3897\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3753 - val_loss: 0.3885\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3735 - val_loss: 0.3890\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3729 - val_loss: 0.3878\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3716 - val_loss: 0.3874\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3705 - val_loss: 0.3879\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3694 - val_loss: 0.3857\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3691 - val_loss: 0.3852\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3688 - val_loss: 0.3832\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3679 - val_loss: 0.3849\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3655 - val_loss: 0.3874\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3659 - val_loss: 0.3835\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3638 - val_loss: 0.3823\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3642 - val_loss: 0.3793\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3635 - val_loss: 0.3808\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3619 - val_loss: 0.3794\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3618 - val_loss: 0.3788\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3606 - val_loss: 0.3764\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3598 - val_loss: 0.3766\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3586 - val_loss: 0.3782\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3588 - val_loss: 0.3764\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3567 - val_loss: 0.3736\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3572 - val_loss: 0.3741\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3561 - val_loss: 0.3751\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3552 - val_loss: 0.3742\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3535 - val_loss: 0.3760\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3533 - val_loss: 0.3743\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3537 - val_loss: 0.3741\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3526 - val_loss: 0.3682\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3521 - val_loss: 0.3729\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3502 - val_loss: 0.3659\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3498 - val_loss: 0.3672\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3484 - val_loss: 0.3654\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3492 - val_loss: 0.3657\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3488 - val_loss: 0.3639\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3482 - val_loss: 0.3655\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3461 - val_loss: 0.3605\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3467 - val_loss: 0.3627\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3460 - val_loss: 0.3646\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3453 - val_loss: 0.3595\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3459 - val_loss: 0.3603\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3443 - val_loss: 0.3791\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3434 - val_loss: 0.3567\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3439 - val_loss: 0.3588\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3428 - val_loss: 0.3558\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3421 - val_loss: 0.3569\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3429 - val_loss: 0.3576\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3422 - val_loss: 0.3547\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3395 - val_loss: 0.3618\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3404 - val_loss: 0.3538\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3398 - val_loss: 0.3548\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3524\n",
      "[CV]  learning_rate=0.00517648844134588, n_hidden=1, n_neurons=19, total=  51.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f256c972c90>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-5ae18773bdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m     12\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m~/documents/machine_learning/venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/machine_learning/venv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f256c972c90>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
