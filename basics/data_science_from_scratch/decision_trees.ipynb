{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, NamedTuple, Optional, Dict, TypeVar, Union\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy measure \n",
    "\n",
    "\\begin{equation}\n",
    "H(S) = -p_i * log_2p_i - ... -p_n * log_2p_n\n",
    "\\end{equation}\n",
    "* $S$ is a set of instances \n",
    "* $p_i$ is a probability that instance in this set belongs to class $c_i$\n",
    "* $n$ is the number of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_proba: List[float]) -> float:\n",
    "    '''\n",
    "    Given list of class probabilities for a given set S,\n",
    "    return the Entropy measure given by the equation:\n",
    "    H(S) = -p_i * log2 pi - ... - p_n * log2 p_n.\n",
    "    '''\n",
    "    return sum([-p * np.log2(p) for p in class_proba if p > 0])\n",
    "\n",
    "assert entropy([1.0]) == 0\n",
    "assert entropy([0.5, 0.5]) == 1\n",
    "assert 0.81 < entropy([0.25, 0.75]) < 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_proba(labels: List[Any]) -> List[float]:\n",
    "    '''\n",
    "    Given list of labels in a set S, return probability that an instance\n",
    "    of class c_i belongs to this set.\n",
    "    [count(c_i)/total_count, ...]\n",
    "    '''\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count for count in Counter(labels).values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_entropy(labels: List[Any]) -> float:\n",
    "    '''return entropy measure given list of labels'''\n",
    "    return entropy(class_proba(labels))\n",
    "\n",
    "assert data_entropy(['a']) == 0\n",
    "assert data_entropy([True, False]) == 1\n",
    "assert data_entropy([1, 2, 2, 2]) == entropy([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy of a partition\n",
    "\n",
    "\\begin{equation}\n",
    "H = q_1H(S_1) + ... + q_mH(S_m)\n",
    "\\end{equation}\n",
    "\n",
    "* entropy of a partition is computed as a weighted sum of entropies of each of its subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
    "    '''returns entrpy of a partition defined by the subset parameter'''\n",
    "    \n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidate(NamedTuple):\n",
    "    level: str\n",
    "    lang: str\n",
    "    tweets: bool\n",
    "    phd: bool\n",
    "    did_well: Optional[bool] = None # allowing unlabeled data\n",
    "\n",
    "inputs = [\n",
    "    Candidate('Senior', 'Java', False, False, False),\n",
    "    Candidate('Senior', 'Java', False, True, False),\n",
    "    Candidate('Mid', 'Python', False, False, True),\n",
    "    Candidate('Junior', 'Python', False, False, True),\n",
    "    Candidate('Junior', 'R', True, False, True),\n",
    "    Candidate('Junior', 'R', True, True, False),\n",
    "    Candidate('Mid', 'R', True, True, True),\n",
    "    Candidate('Senior', 'Python', False, False, False),\n",
    "    Candidate('Senior', 'R', True, False, True),\n",
    "    Candidate('Junior', 'Python', True, False, True),\n",
    "    Candidate('Senior', 'Python', True, True, True),\n",
    "    Candidate('Mid', 'Python', False, True, True),\n",
    "    Candidate('Mid', 'Java', True, False, True),\n",
    "    Candidate('Junior', 'Python', False, True, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3 Algorithm\n",
    "\n",
    "* if all the data has the same label, create a leaf node that predicts the data and stop\n",
    "* if the list of attributes is empty, create a leaf node that predicts the most common label \n",
    "and stop\n",
    "* otherwise, try partitioning data by each of the attributes\n",
    "* choose a partition with the lowest entropy\n",
    "* add a decision noded based on the chosen attribute\n",
    "* recurse on each partitioned subset using the remaining attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T') # generic type for inputs\n",
    "\n",
    "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
    "    '''Partition inputs into lists based on the attribute parameter'''\n",
    "    partitions: Dict[Any, List[T]] = defaultdict(list)\n",
    "    \n",
    "    for inp in inputs:\n",
    "        key = getattr(inp, attribute) # value of a specified attribute\n",
    "        partitions[key].append(inp)\n",
    "        \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy_by(inputs: List[Any], attribute: str, label_attribute: str) -> float:\n",
    "    '''Compute entropy corresponding to the given partition'''\n",
    "    \n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    \n",
    "    labels = [[getattr(inp, attribute) for inp in partition] for partition in partitions.values()]\n",
    "    \n",
    "    return partition_entropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf(NamedTuple):\n",
    "    value: Any\n",
    "        \n",
    "class Split(NamedTuple):\n",
    "    attribute: str\n",
    "    subtrees: dict\n",
    "    default_value: Any = None\n",
    "        \n",
    "DecisionTree = Union[Leaf, Split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree: DecisionTree, inp: Any) -> Any:\n",
    "    '''classify the input using the given decision tree'''\n",
    "    \n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.value\n",
    "    \n",
    "    subtree_key = getattr(inp.attribute)\n",
    "    if subtree_key not in tree.subtrees:\n",
    "        return tree.default_value\n",
    "    \n",
    "    subtree = tree.subtrees[subtree_key]\n",
    "    return classify(subtree, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_id3(inputs: List[Any], split_attributes: List[str], \n",
    "                   target_attribute: str) -> DecisionTree:\n",
    "    # count target labels\n",
    "    label_counts = Counter(getattr(inp, target_attribute) for inp in inputs)\n",
    "    most_common_label = label_counts.most_common(1)[0][0]\n",
    "    \n",
    "    # if there is a unique label, predict it\n",
    "    if len(label_counts) == 1:\n",
    "        return Leaf(most_common_label)\n",
    "    \n",
    "    # if no split attributes are left, return the majority label\n",
    "    if not split_attributes:\n",
    "        return Leaf(most_common_label)\n",
    "    \n",
    "    # split by the best attribute\n",
    "    def split_entropy(attribute: str) -> float:\n",
    "        '''helper to find the best attribute'''\n",
    "        return partition_entropy_by(inputs, attribute, target_attribute)\n",
    "    \n",
    "    best_attribute = min(split_attributes, key=split_entropy)\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_attributes = [a for a in split_attributes if a != best_attribute]\n",
    "    \n",
    "    # recursively build the subtree\n",
    "    subtrees = {attribute_value: build_tree_id3(subset,\n",
    "                                                new_attributes,\n",
    "                                                target_attribute)\n",
    "                for attribute_value, subset in partitions.items()}\n",
    "    \n",
    "    return Split(best_attribute, subtrees, default_value=most_common_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree_id3(inputs, ['level', 'lang', 'tweets', 'phd'], 'did_well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
